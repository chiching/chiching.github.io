[{"id":1,"title":"binary installation","content":"#\n\n\nDownload docker-xx.xx.xx.tgz from bellow#\n\nhttps://docs.docker.com/engine/install/binaries/\nhttps://download.docker.com/linux/static/stable/x86_64/\n\n\ntar -zxf docker-20.10.17.tgz && sudo cp docker/* /usr/local/bin/#\n\n\ncontainerd#\n\n\n配置文件#\n\n修改image\n\n\n\n\nservice file#\n\n\n\nsudo systemctl enable --now containerd.service\n\n\nDocker configure file#\n\nsudo groupadd docker to add a group, otherwise it will failed to start, with\nerrors 'ocker.socket: Control process exited, code=exited, status=216/GROUP'\n\nIf install k8s, not install docker, then following steps can be ignored.\n\nsudo mkdir -p /etc/docker\n\n\n\n\ndocker.socket#\n\n\n\nsystemctl enable --now docker.socket\n\n\ndockerd#\n\n\n\nsudo systemctl enable --now docker.service\n\n\ninstall docker-compose as plugin#\n\n * mkdir -p ~/.docker/cli-plugins, for all users on your system, replace\n   ~/.docker/cli-plugins with /usr/local/lib/docker/cli-plugins.\n * cp docker-compose /usr/local/lib/docker/cli-plugins/\n\nref:\n\n * https://cloud.tencent.com/developer/article/1942278\n * or docker envrionemnt","routePath":"/notes/01-Cloud Computing/Docker/binary_install","lang":"","toc":[{"text":"Download docker-xx.xx.xx.tgz from bellow","id":"download-docker-xxxxxxtgz-from-bellow","depth":2,"charIndex":3},{"text":"tar -zxf docker-20.10.17.tgz && sudo cp docker/* /usr/local/bin/","id":"tar--zxf-docker-201017tgz--sudo-cp-docker-usrlocalbin","depth":2,"charIndex":153},{"text":"containerd","id":"containerd","depth":2,"charIndex":221},{"text":"配置文件","id":"配置文件","depth":3,"charIndex":235},{"text":"service file","id":"service-file","depth":3,"charIndex":254},{"text":"Docker configure file","id":"docker-configure-file","depth":2,"charIndex":320},{"text":"docker.socket","id":"dockersocket","depth":3,"charIndex":603},{"text":"dockerd","id":"dockerd","depth":3,"charIndex":660},{"text":"install docker-compose as plugin","id":"install-docker-compose-as-plugin","depth":2,"charIndex":717}],"domain":"","frontmatter":{},"version":""},{"id":2,"title":"docker_cmd","content":"#\n\n\nclear a container log#\n\necho \"\" > $(docker inspect --format='{{.LogPath}}' )\n\ndocker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}'\ncontainer_name_or_id\n\nsudo usermod -aG docker $USER && newgrp docker\n\n\ninstall docker-compose#\n\nsudo curl -L\n\"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(una\nme -s)-$(uname -m)\" -o docker-compose\n\ndocker run -it -v /home/chiching/projects/spire/sensor:/app --name rust a47\n/bin/bash\n\ndocker save -o tdengine.tar tdengine/tdengine:3.0.1.3\n\ndocker load -i tdengine.tar","routePath":"/notes/01-Cloud Computing/Docker/docker_cmd","lang":"","toc":[{"text":"clear a container log","id":"clear-a-container-log","depth":2,"charIndex":3},{"text":"install docker-compose","id":"install-docker-compose","depth":2,"charIndex":229}],"domain":"","frontmatter":{},"version":""},{"id":3,"title":"","content":"","routePath":"/notes/01-Cloud Computing/Docker/etcdockerdaemon.yml","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":4,"title":"open port","content":"#\n\nopen port for existing contianer\n\n 1. stop docker\n\n 2. edit file vim\n    /var/lib/docker/containers/f42f92973a91371221b9349b2ab1d5818708ecb0b22822200\n    54c5ac9bb65b78a/hostconfig.json ` \"PortBindings\": {\n    \n    \n    \n    } `\n\n 3. edif file vim\n    /var/lib/docker/containers/f42f92973a91371221b9349b2ab1d5818708ecb0b22822200\n    54c5ac9bb65b78a/config.v2.json ` \"Config\": {\n    \n    \n    \n    }\n    \n    `\n\n 4. restart docker and container.","routePath":"/notes/01-Cloud Computing/Docker/open port","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":5,"title":"registry","content":"#\n\n\ndocker compose file#\n\n\n\n\nconfig file#\n\nonfig.yml, this file map to /etc/docker/registry/config.yml in container.\n\n\n\n\ngenerate account#\n\n\n\n\nError http: server gave HTTP response to HTTPS client#\n\nedit file /etc/docker/daemon.json\n\n","routePath":"/notes/01-Cloud Computing/Docker/registry","lang":"","toc":[{"text":"docker compose file","id":"docker-compose-file","depth":2,"charIndex":3},{"text":"config file","id":"config-file","depth":2,"charIndex":28},{"text":"generate account","id":"generate-account","depth":2,"charIndex":120},{"text":"Error  http: server gave HTTP response to HTTPS client","id":"error--http-server-gave-http-response-to-https-client","depth":2,"charIndex":-1}],"domain":"","frontmatter":{},"version":""},{"id":6,"title":"Cron schedule syntax","content":"#\n\n\n\nEntry Description Equivalent to @yearly (or @annually) Run once a year at\nmidnight of 1 January 0 0 1 1 * @monthly Run once a month at midnight of the\nfirst day of the month 0 0 1 * * @weekly Run once a week at midnight on Sunday\nmorning 0 0 * * 0 @daily (or @midnight) Run once a day at midnight 0 0 * * *\n@hourly Run once an hour at the beginning of the hour 0 * * * *\n\nFor example, the line below states that the task must be started every Friday at\nmidnight, as well as on the 13th of each month at midnight:\n\n0 0 13 * 5\n\nTo generate CronJob schedule expressions, you can also use web tools like\ncrontab.guru.\n\n * any value , value list separator\n\n * range of values / step values","routePath":"/notes/01-Cloud Computing/K8s/cronjob","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":7,"title":"Heml","content":"#\n\n** before operation, please make sure you are in the correct context. **\n\n * helm list the check the in instored chart.\n * helm package mosquitto to package a local chart.\n * helm upgrade mosquitto ./mosquitto-0.1.1.tgz to upgrade a chart.","routePath":"/notes/01-Cloud Computing/K8s/helm","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":8,"title":"配置参数","content":"K8s#\n\n\n一、集群规划#\n\n节点         主机名          IP               组件\nmaster节点   k8s-master   192.168.32.128   kube-apiserver, kube-controller-manager, kube-scheduler,\n                                         etcd\nnode节点     k8s-node1    192.168.32.129   kubelet, kube-proxy, docker, etcd\nnode节点     k8s-node2    192.168.32.130   kubelet, kube-proxy, docker, etcd\n\n> 注：\n> \n> 为了节省机器，etcd与 K8s 节点机器复用。\n\n\n二、初始化环境#\n\n\n安装操作系统及配置IP#\n\n> 注：\n> \n> 安装步骤略。CentOS, Ubuntu.\n\n\n修改必要配置#\n\nCentOS\n\n\n\nLinux\n\n\n\n\n三、准备证书#\n\n\n准备工具#\n\nwget\nhttps://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl-certinfo_1.6.\n1_linux_amd64 wget\nhttps://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_lin\nux_amd64 wget\nhttps://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_a\nmd64\n\nchmod +x cfssl* sudo mv cfssl_1.6.1_linux_amd64 /usr/local/bin/cfssl sudo mv\ncfssljson_1.6.1_linux_amd64 /usr/local/bin/cfssljson sudo mv\ncfssl-certinfo_1.6.1_linux_amd64 /usr/local/bin/cfssl-certinfo\n\n\n生成证书#\n\netcd\n\n/etc/kubernetes/pki/etcd/ca-key.pem /etc/kubernetes/pki/etcd/ca.pem\n/etc/kubernetes/pki/etcd/server-key.pem /etc/kubernetes/pki/etcd/server.pem\n/etc/kubernetes/pki/etcd/peer-key.pem /etc/kubernetes/pki/etcd/peer.pem\n/etc/kubernetes/pki/etcd/healthcheck-client-key.pem\n/etc/kubernetes/pki/etcd/healthcheck-client.pem\n\n\n\nk8s\n\n/etc/kubernetes/pki/ca-key.pem /etc/kubernetes/pki/ca.pem\n/etc/kubernetes/pki/apiserver-etcd-client-key.pem\n/etc/kubernetes/pki/apiserver-etcd-client.pem\n/etc/kubernetes/pki/apiserver-key.pem /etc/kubernetes/pki/apiserver.pem\n/etc/kubernetes/pki/apiserver-kubelet-client-key.pem\n/etc/kubernetes/pki/apiserver-kubelet-client.pem\n/etc/kubernetes/pki/front-proxy-ca-key.pem\n/etc/kubernetes/pki/front-proxy-ca.pem\n/etc/kubernetes/pki/front-proxy-client-key.pem\n/etc/kubernetes/pki/front-proxy-client.pem /etc/kubernetes/pki/sa-key.pem\n/etc/kubernetes/pki/sa.pub\n\n\n\n\n五、安装 Docker#\n\n\n安装cni插件#\n\nhttps://github.com/containernetworking/plugins/releases/download/v1.0.1/cni-plug\nins-linux-amd64-v1.0.1.tgz\n\n\n\n\n安装runc#\n\nhttps://github.com/opencontainers/runc/releases/download/v1.1.0/runc.amd64\n\n\n安装containerd#\n\nhttps://github.com/containerd/containerd/releases/download/v1.6.0/containerd-1.6\n.0-linux-amd64.tar.gz\n\n\n\n\n六、部署 Master#\n\nK8s文件 wget https://dl.k8s.io/v1.23.4/kubernetes-server-linux-amd64.tar.gz\n\n\nkube-apiserver#\n\n\n\n\n配置参数#\n\ncat > /opt/kubernetes/cfg/kube-apiserver.conf << EOF\nKUBE_APISERVER_OPTS=\"--advertise-address=192.168.32.128 --allow-privileged=true\n--authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.pem\n--enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true\n--etcd-cafile=/etc/kubernetes/pki/etcd/ca.pem\n--etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.pem\n--etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client-key.pem\n--etcd-servers=https://192.168.32.128:2379 --insecure-port=0\n--kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.pem\n--kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client-key.pem\n--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname,\n--proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem\n--proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem\n--requestheader-allowed-names=front-proxy-client\n--requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem\n--requestheader-extra-headers-prefix=X-Remote-Extra-\n--requestheader-group-headers=X-Remote-Group\n--requestheader-username-headers=X-Remote-User --secure-port=6443\n--service-account-issuer=https://kubernetes.default.svc.cluster.local\n--service-account-key-file=/etc/kubernetes/pki/admin.pem\n--service-account-signing-key-file=/etc/kubernetes/pki/admin-key.pem\n--service-cluster-ip-range=10.0.0.0/24\n--tls-cert-file=/etc/kubernetes/pki/apiserver.pem\n--tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem\" EOF\n\n#systemd的servie文件 cat > /etc/systemd/system/kube-apiserver.service << EOF [Unit]\nDescription=Kubernetes API Server\nDocumentation=https://github.com/kubernetes/kubernetes\n\n[Service] EnvironmentFile=/opt/kubernetes/cfg/kube-apiserver.conf\nExecStart=/opt/kubernetes/bin/kube-apiserver $KUBE_APISERVER_OPTS\nRestart=on-failure\n\n[Install] WantedBy=multi-user.target EOF\n\n$ systemctl daemon-reload $ systemctl start kube-apiserver $ systemctl enable\nkube-apiserver\n\n\n\n#生成证书请求文件 cat > kube-controller-manager-csr.json <https://127.0.0.1:6443\n--kubeconfig=kube-controller-manager.kubeconfig\n\nkubectl config set-credentials system:kube-controller-manager\n--client-certificate=kube-controller-manager.pem\n--client-key=kube-controller-manager-key.pem --embed-certs=true\n--kubeconfig=kube-controller-manager.kubeconfig\n\nkubectl config set-context default --cluster=kubernetes\n--user=system:kube-controller-manager\n--kubeconfig=kube-controller-manager.kubeconfig\n\nkubectl config use-context default\n--kubeconfig=kube-controller-manager.kubeconfig\n\ncat > /opt/kubernetes/cfg/kube-controller-manager.conf << EOF\nKUBE_CONTROLLER_MANAGER_OPTS=\"--allocate-node-cidrs=true\n--authentication-kubeconfig=/etc/kubernetes/controller-manager.conf\n--authorization-kubeconfig=/etc/kubernetes/controller-manager.conf\n--bind-address=127.0.0.1 --client-ca-file=/etc/kubernetes/pki/ca.pem\n--cluster-cidr=172.17.0.0/16 --cluster-name=kubernetes\n--cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem\n--cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem\n--controllers=*,bootstrapsigner,tokencleaner\n--kubeconfig=/etc/kubernetes/controller-manager.conf --leader-elect=true\n--port=0 --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem\n--root-ca-file=/etc/kubernetes/pki/ca.pem\n--service-account-private-key-file=/etc/kubernetes/pki/admin-key.pem\n--service-cluster-ip-range=10.0.0.0/24 --use-service-account-credentials=true\nEOF\n\ncat > /etc/systemd/system/kube-controller-manager.service << EOF [Unit]\nDescription=Kubernetes Controller Manager\nDocumentation=https://github.com/kubernetes/kubernetes\n\n[Service] EnvironmentFile=/opt/kubernetes/cfg/kube-controller-manager.conf\nExecStart=/opt/kubernetes/bin/kube-controller-manager\n$KUBE_CONTROLLER_MANAGER_OPTS Restart=on-failure\n\n[Install] WantedBy=multi-user.target EOF\n\n\n\n生成kube-scheduler证书文件\n\n#生成证书申请文件 cat > kube-scheduler-csr.json <https://127.0.0.1:6443\n--kubeconfig=scheduler.conf\n\nkubectl config set-credentials system:kube-scheduler\n--client-certificate=kube-scheduler.pem --client-key=kube-scheduler-key.pem\n--embed-certs=true --kubeconfig=scheduler.conf\n\nkubectl config set-context default --cluster=kubernetes\n--user=system:kube-scheduler --kubeconfig=scheduler.conf\n\nkubectl config use-context default --kubeconfig=scheduler.conf\n\n部署 kube-scheduler 创建配置文件 cat > /opt/kubernetes/cfg/kube-scheduler.conf << EOF\nKUBE_SCHEDULER_OPTS=\"--authentication-kubeconfig=/etc/kubernetes/scheduler.conf\n--authorization-kubeconfig=/etc/kubernetes/scheduler.conf\n--bind-address=127.0.0.1 --kubeconfig=/etc/kubernetes/scheduler.conf\n--leader-elect=true --port=0 EOF\n\n$ cat > /etc/systemd/system/kube-scheduler.service << EOF [Unit]\nDescription=Kubernetes Scheduler\nDocumentation=https://github.com/kubernetes/kubernetes\n\n[Service] EnvironmentFile=/opt/kubernetes/cfg/kube-scheduler.conf\nExecStart=/opt/kubernetes/bin/kube-scheduler $KUBE_SCHEDULER_OPTS\nRestart=on-failure\n\n[Install] WantedBy=multi-user.target EOF\n\n\n\nvim admin-csr.json { \"CN\": \"admin\", \"hosts\": [], \"key\": { \"algo\": \"rsa\", \"size\":\n2048 }, \"names\": [ { \"C\": \"CN\", \"ST\": \"Hubei\", \"L\": \"Wuhan\", \"O\":\n\"system:masters\", \"OU\": \"system\" } ] }\n\n[root@master1 work]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem\n-config=ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare\nadmin [root@master1 work]# cp admin*.pem /etc/kubernetes/ssl/\n\n设置集群参数 [root@master1 work]# kubectl config set-cluster kubernetes\n--certificate-authority=ca.pem --embed-certs=true\n--server=https://172.10.0.20:6443 --kubeconfig=kube.config 设置客户端认证参数\n[root@master1 work]# kubectl config set-credentials admin\n--client-certificate=admin.pem --client-key=admin-key.pem --embed-certs=true\n--kubeconfig=kube.config 设置上下文参数 [root@master1 work]# kubectl config set-context\nkubernetes --cluster=kubernetes --user=admin --kubeconfig=kube.config 设置默认上下文\n[root@master1 work]# kubectl config use-context kubernetes\n--kubeconfig=kube.config [root@master1 work]# mkdir ~/.kube [root@master1 work]#\ncp kube.config ~/.kube/config 授权kubernetes证书访问kubelet api权限 [root@master1 work]#\nkubectl create clusterrolebinding kube-apiserver:kubelet-apis\n--clusterrole=system:kubelet-api-admin --user kubernetes\n\n\n\n#下载客户端工具 wget\nhttps://github.com/cilium/cilium-cli/releases/download/v0.10.3/cilium-linux-amd6\n4.tar.gz\n\n#解压 sudo tar xf cilium-linux-amd64.tar.gz -C /usr/local/bin/\n\n#安装下载镜像 sudo ctr image pull\nregistry.hub.docker.com/cilium/operator-generic:v1.11.1 sudo ctr image pull\nregistry.hub.docker.com/cilium/cilium:v1.11.1\n\n#kubectl 可用\n\n#使用命令安装 cilium install\n--agent-image=registry.hub.docker.com/cilium/cilium:v1.11.1\n--operator-image=registry.hub.docker.com/cilium/operator-generic:v1.11.1\n--config=cluster-pool-ipv4-cidr=172.17.0.0/16\n\n#for troubleshoot kubectl -n kube-system exec -ti cilium-jw546 -- cilium-health\nstatus\n\n\n\nkubectl apply -f\nhttps://raw.githubusercontent.com/kubernetes/dashboard/v2.5.0/aio/deploy/recomme\nnded.yaml\n\nkubectl proxy\n\nhttp://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kube\nrnetes-dashboard:/proxy/\n\nkubectl proxy --address='0.0.0.0' --port=8002 --accept-hosts='.*'\n\napiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace:\nkubernetes-dashboard\n\n--------------------------------------------------------------------------------\n\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata:\nname: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole\nname: cluster-admin subjects:\n\n * kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard\n\nkubectl apply -f k8s-dashboard.yaml\n\n获取Bearer Token kubectl -n kubernetes-dashboard describe secret $(kubectl -n\nkubernetes-dashboard get secret | grep admin-user | awk '{print $1}')\n\n\n\n　修改root和state目录\n\n　　root = \"C:\\Program Files\\containerd\\root\" 　　state = \"C:\\Program\nFiles\\containerd\\state\"\n\n","routePath":"/notes/01-Cloud Computing/K8s/install2","lang":"","toc":[{"text":"一、集群规划","id":"一集群规划","depth":2,"charIndex":6},{"text":"二、初始化环境","id":"二初始化环境","depth":2,"charIndex":391},{"text":"安装操作系统及配置IP","id":"安装操作系统及配置ip","depth":3,"charIndex":402},{"text":"修改必要配置","id":"修改必要配置","depth":3,"charIndex":450},{"text":"三、准备证书","id":"三准备证书","depth":2,"charIndex":479},{"text":"准备工具","id":"准备工具","depth":3,"charIndex":489},{"text":"生成证书","id":"生成证书","depth":3,"charIndex":986},{"text":"五、安装 Docker","id":"五安装-docker","depth":2,"charIndex":1885},{"text":"安装cni插件","id":"安装cni插件","depth":3,"charIndex":1900},{"text":"安装runc","id":"安装runc","depth":3,"charIndex":2022},{"text":"安装containerd","id":"安装containerd","depth":3,"charIndex":2108},{"text":"六、部署 Master","id":"六部署-master","depth":2,"charIndex":2230},{"text":"kube-apiserver","id":"kube-apiserver","depth":3,"charIndex":2320}],"domain":"","frontmatter":{},"version":""},{"id":9,"title":"Open UI","content":"K8s#\n\n\n一、集群规划#\n\n节点         主机名          IP                组件\nleader节点   k8s-leader   192.168.110.200   kube-apiserver, kube-controller-manager, kube-scheduler,\n                                          etcd\nnode节点     k8s-node1    192.168.110.201   kubelet, kube-proxy, docker, etcd\nnode节点     k8s-node2    192.168.110.202   kubelet, kube-proxy, docker, etcd\n\n> 注：\n> \n> 为了节省机器，etcd与 K8s 节点机器复用。\n> \n> 实验环境:\n> \n>  * 操作系统：debian 11\n>  * 配置： 2G内存/2vCPU/40G硬盘\n>  * 网络：Vmware Bridge模式\n> \n> k8s网络环境规划：\n> \n>  * k8s版本：v1.24.1\n>  * Pod网段：10.0.0.0/8\n>  * Service网段：172.16.0.0/12\n\n\n二、初始化环境#\n\n\n安装操作系统及配置静态IP#\n\n\n\n\n修改必要配置#\n\n\n\n\n三、准备证书工具#\n\ncd /tmp\n\nwget\nhttps://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_lin\nux_amd64 wget\nhttps://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_a\nmd64\n\nchmod +x cfssl* sudo mv cfssl_1.6.1_linux_amd64 /usr/local/bin/cfssl sudo mv\ncfssljson_1.6.1_linux_amd64 /usr/local/bin/cfssljson\n\n\n四、部署Etcd (集群)#\n\n\n准备etcd文件#\n\netcd文件 mkdir ~/etcd && cd ~/etcd\n\nETCD_VER=v3.5.4 && wget\nhttps://github.com/etcd-io/etcd/releases/download/${ETCD_VER}/etcd-${ETCD_VER}-l\ninux-amd64.tar.gz\n\ntar -zxf etcd-${ETCD_VER}-linux-amd64.tar.gz sudo cp\netcd-${ETCD_VER}-linux-amd64/etcd* /usr/local/bin/\n\n\n生成证书#\n\netcd 需要一下证书\n\n\n\n配置ca请求文件#\n\n$ cat > ca-csr.json << EOF { \"CN\": \"etcd CA\", \"key\": { \"algo\": \"rsa\", \"size\":\n2048 }, \"names\": [ { \"C\": \"CN\", \"TS\": \"Beijing\", \"L\": \"Beijing\", \"O\":\n\"etcd-cluster\", \"OU\": \"System\" } ] } EOF\n\n生成CA证书#\n\ncfssl gencert -initca ca-csr.json | cfssljson -bare ca\n\n配置ca证书策略#\n\ncat > ca-config.json << EOF { \"signing\": { \"default\": { \"expiry\": \"87600h\" },\n\"profiles\": { \"etcd\": { \"expiry\": \"87600h\", \"usages\": [ \"signing\", \"key\nencipherment\", \"server auth\", \"client auth\" ] } } } } EOF\n\n生成etcd服务端证书#\n\ncat > etcd-server-csr.json << EOF { \"CN\": \"etcd-server\", \"hosts\": [\n\"192.168.110.200\", \"192.168.110.201\", \"192.168.110.202\", \"127.0.0.1\" ], \"key\": {\n\"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"TS\": \"Beijing\", \"L\":\n\"Beijing\", \"O\": \"etcd-server\", \"OU\": \"System\" } ] } EOF\n\n#生成证书 cfssl gencert\n\n-ca=ca.pem\n\n-ca-key=ca-key.pem\n\n-config=ca-config.json\n\n-profile=etcd\n\netcd-server-csr.json | cfssljson -bare etcd-server\n\n生成etcd客户端证书申请文件#\n\n\n\n\n配置文件以及服务#\n\n\n\n\n五、安装 Docker / Containerd#\n\n参考 [二进制安装docker],或者按以下步骤安装Containerd\n\n\n安装cni插件#\n\nwget\nhttps://github.com/containernetworking/plugins/releases/download/v1.1.1/cni-plug\nins-linux-amd64-v1.1.1.tgz\n\n\n\n\n安装runc#\n\nhttps://github.com/opencontainers/runc/releases/download/v1.1.0/runc.amd64\n\n\n安装containerd#\n\nhttps://github.com/containerd/containerd/releases/download/v1.6.0/containerd-1.6\n.0-linux-amd64.tar.gz\n\n\n\n\n六、部署 Master#\n\nk8s 需要以下证书\n\n\n\nK8s二进制文件。\n\nwget https://dl.k8s.io/v1.24.1/kubernetes-server-linux-amd64.tar.gz\n\ntar -zxf kubernetes-server-linux-amd64.tar.gz\n\nleader: sudo cp\nkubernetes/server/bin/{kube-apiserver,kube-scheduler,kube-controller-manager,kub\nectl} /usr/local/bin/ node: sudo cp\nkubernetes/server/bin/{kubelet,kube-proxy,kubectl} /usr/local/bin/\n\n\nkube-apiserver#\n\n\n\nsudo cp *.pem /etc/kubernetes/pki/\n\n\n配置参数#\n\nsudo mkdir -p /etc/kubernetes/cfg/\n\n\n\n\nkube-controller-manger#\n\n\n\nsudo systemctl daemon-reload && sudo systemctl enable --now\nkube-controller-manager\n\n\nkube-scheduler#\n\n\n\nsudo systemctl daemon-reload && sudo systemctl enable --now kube-scheduler\n\n\n部署kubectl#\n\n生成kubernetes集群管理员证书\n\n#生成证书申请文件 cat > admin-csr.json <\n\n#生成证书 cfssl gencert\n\n-ca=ca.pem\n\n-ca-key=ca-key.pem\n\n-config=ca-config.json\n\n-profile=kubernetes\n\nadmin-csr.json | cfssljson -bare admin\n\n#生成配置文件 kubectl config set-cluster kubernetes\n\n--certificate-authority=ca.pem\n\n--embed-certs=true\n\n--server=https://192.168.110.200:6443\n\n--kubeconfig=admin.kubeconfig\n\nkubectl config set-credentials admin\n\n--client-certificate=admin.pem\n\n--client-key=admin-key.pem\n\n--embed-certs=true\n\n--kubeconfig=admin.kubeconfig\n\nkubectl config set-context default\n\n--cluster=kubernetes\n\n--user=admin\n\n--kubeconfig=admin.kubeconfig\n\nkubectl config use-context default --kubeconfig=admin.kubeconfig\n\ncp admin.kubeconfig ~/.kube/config\n\n\n七、部署 Worker Node#\n\n$ mkdir k8s && scp debian@k8s-leader:~/k8s/kubernetes-server-linux-amd64.tar.gz\n. $ tar -zxf kubernetes-server-linux-amd64.tar.gz $ sudo cp\nkubernetes/server/bin/{kubelet,kubectl,kube-proxy} /usr/local/bin/\n\n$ sudo mkdir -p /etc/kubernetes/pki $ sudo mkdir -p /var/lib/kubelet\n\n$ mkdir ~/.kube\n\n$ scp debian@k8s-leader:~/k8s/admin.kubeconfig ~/.kube/config $ scp\ndebian@k8s-leader:~/k8s/ca.pem ~/k8s/ $ sudo cp ca.pem /etc/kubernetes/pki/\n\n$ sudo mkdir -p /etc/systemd/system/kubelet.service.d\n\n\n部署kubelet#\n\nkubelet配置文件生成 cat | sudo tee /var/lib/kubelet/config.yml << EOF apiVersion:\nkubelet.config.k8s.io/v1beta1 kind: KubeletConfiguration authentication:\nanonymous: enabled: false webhook: cacheTTL: 0s enabled: true x509:\nclientCAFile: /etc/kubernetes/pki/ca.pem authorization: mode: Webhook webhook:\ncacheAuthorizedTTL: 0s cacheUnauthorizedTTL: 0s cgroupDriver: systemd\nclusterDomain: cluster.local cpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s fileCheckFrequency: 0s healthzBindAddress:\n127.0.0.1 healthzPort: 10248 httpCheckFrequency: 0s imageMinimumGCAge: 0s\nlogging: {} nodeStatusReportFrequency: 0s nodeStatusUpdateFrequency: 0s\nrotateCertificates: true runtimeRequestTimeout: 0s shutdownGracePeriod: 0s EOF\n\nTLS Bootstrapping认证文件\n\n#生成随机认证key a=head -c 16 /dev/urandom | od -An -t x | tr -d ' ' | head -c6 b=head\n-c 16 /dev/urandom | od -An -t x | tr -d ' ' | head -c16\n\n\ncat > bootstrap.secret.yaml <#\n\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata:\nname: kubelet-bootstrap roleRef: apiGroup: rbac.authorization.k8s.io kind:\nClusterRole name: system:node-bootstrapper subjects:\n\n * apiGroup: rbac.authorization.k8s.io kind: Group name:\n   system:bootstrappers:default-node-token\n\n--------------------------------------------------------------------------------\n\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata:\nname: node-autoapprove-bootstrap roleRef: apiGroup: rbac.authorization.k8s.io\nkind: ClusterRole name:\nsystem:certificates.k8s.io:certificatesigningrequests:nodeclient subjects:\n\n * apiGroup: rbac.authorization.k8s.io kind: Group name:\n   system:bootstrappers:default-node-token\n\n--------------------------------------------------------------------------------\n\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata:\nname: node-autoapprove-certificate-rotation roleRef: apiGroup:\nrbac.authorization.k8s.io kind: ClusterRole name:\nsystem:certificates.k8s.io:certificatesigningrequests:selfnodeclient subjects:\n\n * apiGroup: rbac.authorization.k8s.io kind: Group name: system:nodes\n\n--------------------------------------------------------------------------------\n\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata:\nannotations: rbac.authorization.kubernetes.io/autoupdate: \"true\" labels:\nkubernetes.io/bootstrapping: rbac-defaults name:\nsystem:kube-apiserver-to-kubelet rules:\n\n * apiGroups:\n   * \"\" resources:\n   * nodes/proxy\n   * nodes/stats\n   * nodes/log\n   * nodes/spec\n   * nodes/metrics verbs:\n   * \"*\"\n\n--------------------------------------------------------------------------------\n\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata:\nname: system:kube-apiserver namespace: \"\" roleRef: apiGroup:\nrbac.authorization.k8s.io kind: ClusterRole name:\nsystem:kube-apiserver-to-kubelet subjects:\n\n * apiGroup: rbac.authorization.k8s.io kind: User name: kube-apiserver EOF\n\nkubectl create -f bootstrap.secret.yaml\n\n#生成配置文件 kubectl config set-cluster kubernetes\n\n--certificate-authority=ca.pem\n\n--embed-certs=true\n\n--server=https://192.168.110.200:6443\n\n--kubeconfig=bootstrap-kubelet.conf\n\nkubectl config set-credentials tls-bootstrap-token-user\n\n--token=$a.$b\n\n--kubeconfig=bootstrap-kubelet.conf\n\nkubectl config set-context tls-bootstrap-token-user@kubernetes\n\n--cluster=kubernetes\n\n--user=tls-bootstrap-token-user\n\n--kubeconfig=bootstrap-kubelet.conf\n\nkubectl config use-context tls-bootstrap-token-user@kubernetes\n\n--kubeconfig=bootstrap-kubelet.conf\n\nsudo cp bootstrap-kubelet.conf /etc/kubernetes/\n\n#生成service文件 cat | sudo tee /etc/systemd/system/kubelet.service\n<https://github.com/kubernetes/kubernetes After=containerd.service\nRequires=containerd.service\n\n[Service] ExecStart=/usr/local/bin/kubelet\n\nRestart=always StartLimitInterval=0 RestartSec=10\n\n[Install] WantedBy=multi-user.target EOF\n\n#生成service配置文件\n\nsudo mkdir /etc/systemd/system/kubelet.service.d/ -p cat | sudo tee\n/etc/systemd/system/kubelet.service.d/10-kubelet.conf <\n\nsudo systemctl daemon-reload && sudo systemctl enable --now kubelet\n\n\n部署kubeproxy#\n\n\n创建证书请求文件#\n\n$ cat > kube-proxy-csr.json << EOF { \"CN\": \"system:kube-proxy\", \"hosts\": [],\n\"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"BeiJing\",\n\"ST\": \"BeiJing\", \"O\": \"k8s\", \"OU\": \"System\" } ] } EOF\n\n\n生成证书#\n\ncfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json\n-profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy\n\nkubectl config set-cluster kubernetes\n\n--certificate-authority=/opt/kubernetes/ssl/ca.pem\n\n--embed-certs=true\n\n--server=https://192.168.32.128:6443\n\n--kubeconfig=kube-proxy.kubeconfig kubectl config set-credentials kube-proxy\n\n--client-certificate=./kube-proxy.pem\n\n--client-key=./kube-proxy-key.pem\n\n--embed-certs=true\n\n--kubeconfig=kube-proxy.kubeconfig kubectl config set-context default\n\n--cluster=kubernetes\n\n--user=kube-proxy\n\n--kubeconfig=kube-proxy.kubeconfig kubectl config use-context default\n--kubeconfig=kube-proxy.kubeconfig\n\n\n配置参数文件#\n\ncat > /etc/kubernetes/cfg/kube-proxy-config.yml << EOF kind:\nKubeProxyConfiguration apiVersion: kubeproxy.config.k8s.io/v1alpha1 bindAddress:\n0.0.0.0 metricsBindAddress: 0.0.0.0:10249 clientConnection: kubeconfig:\n/etc/kubernetes/kube-proxy.kubeconfig hostnameOverride: k8s-n1 clusterCIDR:\n172.17.0.0/16 EOF\n\n\n创建配置文件#\n\ncat > /etc/kubernetes/cfg/kube-proxy.conf << EOF\nKUBE_PROXY_OPTS=\"--logtostderr=false --v=2\n--config=/etc/kubernetes/cfg/kube-proxy-config.yml\" EOF\n\n\nsystemd 管理 kube-proxy#\n\ncat > /usr/lib/systemd/system/kube-proxy.service << EOF [Unit]\nDescription=Kubernetes Proxy After=network.target\n\n[Service] EnvironmentFile=/etc/kubernetes/cfg/kube-proxy.conf\nExecStart=/usr/local/bin/kube-proxy $KUBE_PROXY_OPTS Restart=on-failure\nLimitNOFILE=65536\n\n[Install] WantedBy=multi-user.target EOF\n\n\n部署网络组件#\n\n\n\n\n安装kubernets-dashboard#\n\nhttps://github.com/kubernetes/dashboard\n\n\n\n\n安装 Hubble#\n\ncilium hubble enable\n\n安装helm https://github.com/helm/helm\nhttps://get.helm.sh/helm-v3.8.0-linux-amd64.tar.gz unzip and move it to\n/usr/local/bin/\n\ncilium hubble enable\n\ncilium hubble enable --ui\n\n\nOpen UI#\n\ncilium hubble ui\n\nhttp://192.168.32.129:12000/\n\nValidate Hubble API Access#\n\ncilium hubble port-forward\n\nhubble status\n\nhubble observe\n\n\n八、部署 CoreDNS#\n\n\n九、高可用架构（扩容多 Master 架构）#\n\nhttps://kubernetes.io/docs/setup/best-practices/certificates/\n\nhttps://cloudmessage.top/archives/2kubernetes%E5%AE%89%E8%A3%85md#%E4%BA%8C%E6%9\n3%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%88%9D%E5%A7%8B%E5%8C%96%E9%85%8D%E7%BD%AE\n\nhttps://www.zhangzhuo.ltd/articles/2022/01/09/1641717241819.html\n\n\nWindows install cilium#\n\n\ninstall containerd#\n\n　wget\nhttps://github.com/containerd/containerd/releases/download/v1.6.0/cri-containerd\n-cni-1.6.0-windows-amd64.tar.gz\n\n\n生成containerd配置文件#\n\n.\\containerd.exe config default | Out-File config.toml -Encoding ascii\n\n\n生成containerd配置文件#\n\n\n\n","routePath":"/notes/01-Cloud Computing/K8s/install_debian","lang":"","toc":[{"text":"一、集群规划","id":"一集群规划","depth":2,"charIndex":6},{"text":"二、初始化环境","id":"二初始化环境","depth":2,"charIndex":569},{"text":"安装操作系统及配置静态IP","id":"安装操作系统及配置静态ip","depth":3,"charIndex":580},{"text":"修改必要配置","id":"修改必要配置","depth":3,"charIndex":599},{"text":"三、准备证书工具","id":"三准备证书工具","depth":2,"charIndex":611},{"text":"四、部署Etcd (集群)","id":"四部署etcd-集群","depth":2,"charIndex":950},{"text":"准备etcd文件","id":"准备etcd文件","depth":3,"charIndex":967},{"text":"生成证书","id":"生成证书","depth":3,"charIndex":1242},{"text":"配置ca请求文件","id":"配置ca请求文件","depth":4,"charIndex":1264},{"text":"生成CA证书","id":"生成ca证书","depth":4,"charIndex":1465},{"text":"配置ca证书策略","id":"配置ca证书策略","depth":4,"charIndex":1530},{"text":"生成etcd服务端证书","id":"生成etcd服务端证书","depth":4,"charIndex":1750},{"text":"生成etcd客户端证书申请文件","id":"生成etcd客户端证书申请文件","depth":4,"charIndex":2191},{"text":"配置文件以及服务","id":"配置文件以及服务","depth":3,"charIndex":2212},{"text":"五、安装 Docker / Containerd","id":"五安装-docker--containerd","depth":2,"charIndex":2226},{"text":"安装cni插件","id":"安装cni插件","depth":3,"charIndex":2292},{"text":"安装runc","id":"安装runc","depth":3,"charIndex":2419},{"text":"安装containerd","id":"安装containerd","depth":3,"charIndex":2505},{"text":"六、部署 Master","id":"六部署-master","depth":2,"charIndex":2627},{"text":"kube-apiserver","id":"kube-apiserver","depth":3,"charIndex":2984},{"text":"kube-controller-manger","id":"kube-controller-manger","depth":3,"charIndex":3086},{"text":"kube-scheduler","id":"kube-scheduler","depth":3,"charIndex":3199},{"text":"部署kubectl","id":"部署kubectl","depth":2,"charIndex":3295},{"text":"七、部署 Worker Node","id":"七部署-worker-node","depth":2,"charIndex":4024},{"text":"部署kubelet","id":"部署kubelet","depth":3,"charIndex":4539},{"text":"cat > bootstrap.secret.yaml <<EOF\r\napiVersion: v1\r\nkind: Secret\r\nmetadata:\r\nname: bootstrap-token-$a\r\nnamespace: kube-system\r\ntype: bootstrap.kubernetes.io/token\r\nstringData:\r\ndescription: \"The default bootstrap token generated by 'kubelet '.\"\r\ntoken-id: $a\r\ntoken-secret: $b\r\nusage-bootstrap-authentication: \"true\"\r\nusage-bootstrap-signing: \"true\"\r\nauth-extra-groups:  system:bootstrappers:default-node-token,system:bootstrappers:worker,system:bootstrappers:ingress","id":"cat--bootstrapsecretyaml-eofapiversion-v1kind-secretmetadataname-bootstrap-token-anamespace-kube-systemtype-bootstrapkubernetesiotokenstringdatadescription-the-default-bootstrap-token-generated-by-kubelet-token-id-atoken-secret-busage-bootstrap-authentication-trueusage-bootstrap-signing-trueauth-extra-groups--systembootstrappersdefault-node-tokensystembootstrappersworkersystembootstrappersingress","depth":2,"charIndex":-1},{"text":"部署kubeproxy","id":"部署kubeproxy","depth":3,"charIndex":8618},{"text":"部署网络组件","id":"部署网络组件","depth":3,"charIndex":10353},{"text":"安装kubernets-dashboard","id":"安装kubernets-dashboard","depth":3,"charIndex":10365},{"text":"安装 Hubble","id":"安装-hubble","depth":3,"charIndex":10433},{"text":"Validate Hubble API Access","id":"validate-hubble-api-access","depth":4,"charIndex":10700},{"text":"八、部署 CoreDNS","id":"八部署-coredns","depth":2,"charIndex":10789},{"text":"九、高可用架构（扩容多 Master 架构）","id":"九高可用架构扩容多-master-架构","depth":2,"charIndex":10805},{"text":"Windows install cilium","id":"windows-install-cilium","depth":2,"charIndex":11119},{"text":"install containerd","id":"install-containerd","depth":3,"charIndex":11145},{"text":"生成containerd配置文件","id":"生成containerd配置文件","depth":3,"charIndex":11287},{"text":"生成containerd配置文件","id":"生成containerd配置文件-1","depth":3,"charIndex":11379}],"domain":"","frontmatter":{},"version":""},{"id":10,"title":"Kube","content":"#\n\n\ncontext#\n\n * get all context : kubectl config get-contexts\n * change context: kubectl config use-context CXT_NAME\n * see current context: kubectl config current-context\n\n\nsteps#\n\n * skaffold dev\n\n\nPod#\n\n * get pods: kubectl get pod\n * get error: kubectl describe pod POD_NAME\n\n\nDeployment#\n\n * get deployments: kubectl get deployment\n * get logs: kubectl logs deployment/d_name\n\n\nCronjob#\n\n * get jobs: kubectl get cronjob\n * triiger cronjob: kubectl create job --from=cronjob/sensor sensor-manual-0428\n   --namespace=default\n\n\nLogs#\n\nkubectl logs\n\n\nRestart k8s#\n\n * kubectl rollout restart deployment [deployment_name]\n\n\nupdate cronjob schedule#\n\n * kubectl patch cronjob scheduler-cronjob-requester -p '{\"spec\":{\"schedule\":\n   \"0,15,30,45 * * * *\"}}' # old is \"0 3 1 1 *\"","routePath":"/notes/01-Cloud Computing/K8s/kube","lang":"","toc":[{"text":"context","id":"context","depth":2,"charIndex":3},{"text":"steps","id":"steps","depth":2,"charIndex":174},{"text":"Pod","id":"pod","depth":2,"charIndex":200},{"text":"Deployment","id":"deployment","depth":2,"charIndex":281},{"text":"Cronjob","id":"cronjob","depth":2,"charIndex":383},{"text":"Logs","id":"logs","depth":2,"charIndex":531},{"text":"Restart k8s","id":"restart-k8s","depth":2,"charIndex":553},{"text":"update cronjob schedule","id":"update-cronjob-schedule","depth":2,"charIndex":625}],"domain":"","frontmatter":{},"version":""},{"id":11,"title":"Debian","content":"#\n\n\ngrant sudo permission#\n\n\n\n\nIf vm, install vm tools#\n\nsudo apt install open-vm-tools-desktop also, you could add a shared folder for\ncoping big file. Add this line sudo vmhgfs-fuse .host:/ /mnt/hgfs -o\nsubtype=vmhgfs-fuse,allow_other,uid=1000,gid=1000 to file /etc/rc.local, then\ncheck the systemd service rc-local.service\n\n\nstatic ip#\n\nsudo vim /etc/network/interfaces\n\n\n\n\nupdate apt source#\n\nsudo vim /etc/apt/source.list\n\n\n\n\nsettings#\n\n * 使用命令行启用最小化和最大化按钮 gsettings set org.gnome.desktop.wm.preferences button-layout\n   \":minimize,maximize,close\", the default is \"appmenu:close\"\n\n\ngnome settings#\n\n\n\n\napp and tols#\n\n\nextenstions#\n\n * Dash to dock , https://micheleg.github.io/dash-to-dock/index.html\n * clipboard-indicator\n * blur-my-shell\n * coverflow-alt-tab\n * sudo apt install gnome-tweak\n\n\napps#\n\n * input method. sudo apt purge ibus* fcitx* && sudo apt autoremove sudo apt\n   install fcitx5 fcitx5-chinese-addons\n * wechat\n\n\nref#\n\n * ref","routePath":"/notes/01-Cloud Computing/Linux/Debian","lang":"","toc":[{"text":"grant sudo permission","id":"grant-sudo-permission","depth":2,"charIndex":3},{"text":"If vm, install vm tools","id":"if-vm-install-vm-tools","depth":2,"charIndex":30},{"text":"static ip","id":"static-ip","depth":2,"charIndex":327},{"text":"update apt source","id":"update-apt-source","depth":2,"charIndex":376},{"text":"settings","id":"settings","depth":2,"charIndex":430},{"text":"gnome settings","id":"gnome-settings","depth":3,"charIndex":586},{"text":"app and tols","id":"app-and-tols","depth":2,"charIndex":606},{"text":"extenstions","id":"extenstions","depth":3,"charIndex":622},{"text":"apps","id":"apps","depth":3,"charIndex":800},{"text":"ref","id":"ref","depth":3,"charIndex":936}],"domain":"","frontmatter":{},"version":""},{"id":12,"title":"Ubuntu beatiful","content":"#\n\n 1. sudo apt-get install gnome-tweak-tool\n 2. sudo apt install chrome-gnome-shell\n\n5.login screen sudo gedit /usr/share/gnome-shell/theme/ubuntu.css\n\n#lockDialogGroup { background: #2c001e\nurl(file:///usr/share/backgrounds/Ross_Jones_Rockpool_(Sydney)_by_Chris_Carignan\n.jpg); background-repeat: no-repeat; background-size: cover;\nbackground-position: center; }\n\n// this is the new method... https://github.com/thiggy01/change-gdm-background\n\nhttps://www.wallpaperflare.com/s\n\n 6. lock backgroud\n\n * install sudo apt install gir1.2-clutter-1.0\n\n * go to https://extensions.gnome.org/extension/1476/unlock-dialog-background/\n   Click on the toggle and confirm on the next pop-up to install the extension.\n\n * go to extentions to update it.\n\n 7. dock\n\ngsettings set org.gnome.shell.extensions.dash-to-dock click-action\nminimize-or-previews\n\ngsettings set org.gnome.shell.extensions.dash-to-dock background-opacity 0\n\ngsettings set org.gnome.shell.extensions.dash-to-dock extend-height false\ngsettings set org.gnome.shell.extensions.dash-to-dock dock-position BOTTOM\ngsettings set org.gnome.shell.extensions.dash-to-dock transparency-mode FIXED\ngsettings set org.gnome.shell.extensions.dash-to-dock dash-max-icon-size 40\ngsettings set org.gnome.shell.extensions.dash-to-dock unity-backlit-items true\n\nhttps//:linuxconfig.org/how-to-customize-dock-panel-on-ubuntu-20-04-focal-fossa-\nlinux\n\nhttps://linux.cn/article-11256-1.html","routePath":"/notes/01-Cloud Computing/Linux/Ubuntu beatiful","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":13,"title":"Apps","content":"#\n\nsudo apt install gnome-session to install pure gnome or maybe its gnome-core\n\n * flameshot for screenshot. settings -> keyboard -> shortcut -> ctl + alt + a\n   -> command (flameshot gui)\n * shotcut for video edting.\n * obs for Live screen recording tool or maybe SimpleScreenRecorder\n * smplayer for video player\n * wps for doc. fix font issue formula symbols might not be displayed correctly\n   due to missing fonts: https://github.com/BannedPatriot/ttf-wps-fonts\n * chrome\n * free download manager https://www.freedownloadmanager.org/\n * wechat\n   https://www.how2shout.com/linux/how-to-install-wechat-client-on-ubuntu-linux/\n * tmux\n * pip3 install tldr\n * marktext\n\n\ninstall DICT#\n\n * try to install it sudo dpkg -i youdao-dict_6.0.0-ubuntu-amd64.deb\n\n * if failed, install the dependency. sudo apt-get -f install\n\n * dependency again sudo apt-get install tesseract-ocr\n\n * install it again sudo dpkg -i youdao-dict_6.0.0-ubuntu-amd64.deb\n\n * sudo apt install goldendict\n   \n   \n   * 欧路 https://dict.eudic.net/dicts/en/%GDWORD%\n   \n   \n   * 有道 http://dict.youdao.com/search?q=%GDWORD%&ue=utf8\n   \n   \n   * Collins Online Dictionary\n     https://www.collinsdictionary.com/dictionary/english/%GDWORD%\n   \n   * 海词 http://dict.cn/%GDWORD%\n   * 金山词霸 http://www.iciba.com/%GDWORD%/\n   * 译典通 http://www.dreye.com.cn/ews/%GDWORD%–01–.html\n   * 汉典 http://www.zdic.net/sousuo/?q=%GDWORD%\n   \n   \n   * Bing 中国： http://cn.bing.com/search?q=%GDWORD%\n   \n   \n   * Bing 美国： http://www.bing.com/search?q=%GDWORD%\n   \n   \n   * 搜狗 http://www.sogou.com/web?query=%GDWORD%\n   \n   \n   * 百度搜索 http://www.baidu.com/s?wd=%GDWORD%\n   \n   \n   * Google https://google.com/search?q=%GDWORD%\n\nWine: https://wiki.winehq.org/Ubuntu\n\nhttps://www.huaweicloud.com/articles/12587927.html","routePath":"/notes/01-Cloud Computing/Linux/apps","lang":"","toc":[{"text":"install DICT","id":"install-dict","depth":2,"charIndex":673}],"domain":"","frontmatter":{},"version":""},{"id":14,"title":"apt-get","content":"#\n\n修改源：\n\nvim /etc/apt/sources.list\n\n:%s/archive.ubuntu.com/mirrors.aliyun.com/g\n\n下面总结一下有关apt-get的常用但容易混淆的指令:\n\n\napt-get autoclean#\n\n\n\n\napt-get clean#\n\n\n\n\napt-get autoremove#\n\n\n\n其它：\n\n\napt-get remove 软件包名称#\n\n\n\n\napt-get --purge remove 软件包名称#\n\n\n\nFrom http://blog.csdn.net/flydream0/article/details/8620396","routePath":"/notes/01-Cloud Computing/Linux/apt-get","lang":"","toc":[{"text":"apt-get autoclean","id":"apt-get-autoclean","depth":2,"charIndex":110},{"text":"apt-get clean","id":"apt-get-clean","depth":2,"charIndex":133},{"text":"apt-get autoremove","id":"apt-get-autoremove","depth":2,"charIndex":152},{"text":"apt-get remove 软件包名称","id":"apt-get-remove-软件包名称","depth":2,"charIndex":181},{"text":"apt-get --purge remove 软件包名称","id":"apt-get---purge-remove-软件包名称","depth":2,"charIndex":207}],"domain":"","frontmatter":{},"version":""},{"id":15,"title":"pacman  mirror list","content":"Arch#\n\n\nvmware tools#\n\npacman -S open-vm-tools\n\n\npacman mirror list#\n\nServer = http://mirrors.163.com/archlinux/$repo/os/$arch Server =\nhttps://mirrors.dgut.edu.cn/archlinux/$repo/os/$arch Server =\nhttps://mirrors.nju.edu.cn/archlinux/$repo/os/$arch Server =\nhttps://mirrors.tuna.tsinghua.edu.cn/archlinux/$repo/os/$arch Server =\nhttps://mirrors.bfsu.edu.cn/archlinux/$repo/os/$arch Server =\nhttp://mirrors.bfsu.edu.cn/archlinux/$repo/os/$arch Server =\nhttp://mirrors.zju.edu.cn/archlinux/$repo/os/$arch Server =\nhttp://mirrors.nju.edu.cn/archlinux/$repo/os/$arch Server =\nhttp://mirrors.tuna.tsinghua.edu.cn/archlinux/$repo/os/$arch Server =\nhttps://mirrors.sjtug.sjtu.edu.cn/archlinux/$repo/os/$arch Server =\nhttp://mirrors.dgut.edu.cn/archlinux/$repo/os/$arch Server =\nrsync://mirrors.bfsu.edu.cn/archlinux/$repo/os/$arch\n\npacman -S ttf-dejavu ttf-droid ttf-hack ttf-font-awesome otf-font-awesome\nttf-lato ttf-liberation ttf-linux-libertine ttf-opensans ttf-roboto\nttf-ubuntu-font-family\n\npacman -S ttf-hannom noto-fonts noto-fonts-extra noto-fonts-emoji noto-fonts-cjk\n\npacman -S adobe-source-code-pro-fonts adobe-source-sans-fonts\nadobe-source-serif-fonts adobe-source-han-sans-cn-fonts\nadobe-source-han-sans-hk-fonts adobe-source-han-sans-tw-fonts\nadobe-source-han-serif-cn-fonts\n\npacman -S wqy-zenhei wqy-microhei\n\nhttps://blog.csdn.net/ymz641/article/details/124146192\n\n\n\nhttps://www.itzgeek.com/how-tos/linux/arch-linux/how-to-install-arch-linux.html\n\nhttps://www.itzgeek.com/how-tos/linux/arch-linux/how-to-install-gnome-desktop-on\n-arch-linux.html","routePath":"/notes/01-Cloud Computing/Linux/arch","lang":"","toc":[{"text":"vmware tools","id":"vmware-tools","depth":2,"charIndex":7}],"domain":"","frontmatter":{},"version":""},{"id":16,"title":"CentOS cmd","content":"#\n\n\nadd port to firewall#\n\nsudo firewall-cmd --zone=public --add-port=5004/tcp --permanent\n\nsudo firewall-cmd --reload\n\nyum --enablerepo=extras install epel-release\n\n\nadd vpn#\n\n\ninstall application#\n\nyum -y install ppp pptp pptp-setup\n\n\nadd vpn connection#\n\npptpsetup --create pptpd --server 183.61.254.113 --username yanfa --password\nyanfa --encrypt --start\n\n\nstop it#\n\nkillall pppd\n\n\nadd network which need vpn#\n\nip route add 216.0.0.0/8 via 192.168.23.1 dev ppp0\n\n\nchang hostname#\n\n 1. 需要重启，永久生效\n\n修改 /etc/sysconfig/network 文件如下： NETWORKING=yes HOSTNAME=myhostname\n\n","routePath":"/notes/01-Cloud Computing/Linux/centos","lang":"","toc":[{"text":"add port to firewall","id":"add-port-to-firewall","depth":2,"charIndex":3},{"text":"add vpn","id":"add-vpn","depth":2,"charIndex":166},{"text":"install application","id":"install-application","depth":3,"charIndex":177},{"text":"add vpn connection","id":"add-vpn-connection","depth":3,"charIndex":236},{"text":"stop it","id":"stop-it","depth":3,"charIndex":360},{"text":"add network which need vpn","id":"add-network-which-need-vpn","depth":3,"charIndex":385},{"text":"chang hostname","id":"chang-hostname","depth":2,"charIndex":467}],"domain":"","frontmatter":{},"version":""},{"id":17,"title":"certificate","content":"#\n\nopenssl 命令： req: 生成证书请求文件和自签名证书。用于创建和处理 PKCS#10 格式的证书 x509 ： X.509\n证书管理，显示证书信息、转换证书格式、签名证书请求及改变证书信任设置。 证书工具 ca： 签发证书请求和生成CRL，维护一个已签发证书状态的文本数据库。证书中心\nverify：X.509证书验证。证书验证\n\n\n1. 创建根证书（Root CA）#\n\n * 1.1 生成私钥（.key）；openssl genrsa -out ca.key 1024\n * 1.2 生成证书请求文件（.csr），实际上就是把自身一些信息（国家、机构、域名、邮箱等）用第一步的私钥加密。openssl req -new -key\n   ca.key -out ca.csr\n * 1.3 自签名证书（.crt），用第一步的私钥给第二步的证书请求文件签名，根证书肯定是自签名的，CA 机构给自己发的证书。 openssl req\n   -x509 -days 3650 -key ca.key -in ca.csr -out ca.crt 或者 openssl x509 -req\n   -days 3650 -in ca.csr -signkey ca.key -out ca.crt [-x509]: req 中的 [-x509]\n   表示生成一个自签名的证书，而不是一个证书请求； [-req]: x509 中的 [-req] 表示 in 后面的输入文件为证书请求文件，默认是证书文件；\n   [-signkey]: 用于提供自签名时的私钥文件。\n\n\n2.创建中间证书（Intermediate CA），用根证书给中间证书签名，中间证书再给用户签名，提高安全性。#\n\n... 略\n\n\n3. 创建用户证书，用中间证书给用户签名，形成 用户证书–>中间证书–>根证书 的证书链#\n\n * 3.1 生成私钥（.key），用户自己拥有 openssl genrsa -out server.key 1024\n\n * 3.2\n   生成证书请求文件（.csr），由用户的私钥和用户自身的信息（国家、机构、域名、邮箱等）生成。其中用户的公钥和用户的信息是明文保存在证书请求文件中，而用户私\n   钥的作用是对用户公钥及用户自身信息做签名，私钥不包含在证书请求中；openssl req -new -key server.key -out\n   server.csr\n\n * 3.3 中间证书签名（.crt），用中间证书的私钥给用户证书的证书请求文件签名，签名之后意味着中间证书信任用户证书。 openssl ca -in\n   server.csr -out server.crt -cert ca.crt -keyfile ca.key [-cert]，指定 CA 证书；\n   [-keyfile]，指定私钥。\n\n生成服务端证书（根证书给服务端证书签名） $ openssl ca -days 3650 -md sha256 -in server.csr -out\nserver.crt -cert ca.crt -keyfile ca.key -policy policy_anything -config\nopenssl.cnf -extensions v3_req 生成服务端证书（效果等同上一句） $ openssl x509 -req -sha256\n-days 3650 -in server.csr -CA ca.crt -CAkey ca.key -out server.crt\n-CAcreateserial -extfile /usr/lib/ssl/openssl.cnf -extensions v3_req -- this\nline works\n\nmkdir ./demoCA/newcerts echo \"\" > ./demoCA/index.txt echo \"01\" > ./demoCA/serial\n\n取消 /etc/pki/tls/openssl.cnf or /usr/lib/ssh/openssl.cnf 中 [req] 节点下这句注释\nreq_extensions= v3_req，如果想使用自定义的配置文件，看 传送门 。 在 [v3_req ] 节点下新增属性 subjectAltName\n= @alt_names。 新增如下节点，如果没有 DNS 只填写 IP 即可： [ alt_names ] DNS.1 = localhost DNS.1 =\nwww.abc.com IP.1 = 192.168.1.1\n\n自签名证书 + Nginx 实现 HTTP 升级 HTTPS","routePath":"/notes/01-Cloud Computing/Linux/certificate","lang":"","toc":[{"text":"1. 创建根证书（Root CA）","id":"1-创建根证书root-ca","depth":2,"charIndex":174},{"text":"2.创建中间证书（Intermediate CA），用根证书给中间证书签名，中间证书再给用户签名，提高安全性。","id":"2创建中间证书intermediate-ca用根证书给中间证书签名中间证书再给用户签名提高安全性","depth":2,"charIndex":688},{"text":"3. 创建用户证书，用中间证书给用户签名，形成 *用户证书–>中间证书–>根证书* 的证书链","id":"3-创建用户证书用中间证书给用户签名形成-用户证书中间证书根证书-的证书链","depth":2,"charIndex":-1}],"domain":"","frontmatter":{},"version":""},{"id":18,"title":"dconf","content":"#\n\n\ncustome location#\n\n/etc/dconf/profile/user ~/.config/dconf/user\n\nuser at: ~/.config/dconf local and site at: /etc/dconf/db/\n\n\nreset it#\n\ndconf reset -f /org/gnome/","routePath":"/notes/01-Cloud Computing/Linux/dconf","lang":"","toc":[{"text":"custome location","id":"custome-location","depth":2,"charIndex":3},{"text":"reset it","id":"reset-it","depth":2,"charIndex":129}],"domain":"","frontmatter":{},"version":""},{"id":19,"title":"DNS","content":"#\n\nThere are serveral kinds of programs to manage the /etc/resolv.conf\n\n * NetworkManager: fedora and debain use it.\n * netconfig: penSUSE，SUSE use it.\n * resolvconf, rdnssd: mostly Debian and Ubuntu 15 before.\n * systemd-resolved: ubuntu after 15 or 16.\n\nto determine which program manage this file.\n\n * Check the file comments\n * Check the symblink of /etc/resolv.conf\n * Check if the service is runing\n\none /etc/resolv.conf name-resolution-issue-systemd-resolved\n\n\ndns#\n\n\ncheck dns server#\n\n 1. nslookup google.com, sudo nslookup google.com, host google.com, sudo host\n    www.google.com\n\n 2. sudo systemd-resolve --status\n\n 3. cat /etc/netplan/50-cloud-init.yaml sudo netplan apply\n\n 4. edit /etc/systemd/resolved.conf and then sudo service systemd-resolved\n    restart\n\n 5. systemctl status systemd-resolved use this file\n    /run/systemd/resolve/stub-resolv.conf\n\n 6. file link: /etc/resolve.conf linkt.....\n    /run/systemd/resolve/stub-resolv.conf\n\n 7. works: edit netplan first sudo ln -s /run/systemd/resolve/resolv.conf\n    /etc/resolv.conf\n    \n    https://unix.stackexchange.com/questions/548830/whats-the-difference-between\n    -run-systemd-resolve-stub-resolv-conf-and-run-sys\n\n10.16.8.201 10.16.130.201","routePath":"/notes/01-Cloud Computing/Linux/dns","lang":"","toc":[{"text":"dns","id":"dns-1","depth":2,"charIndex":-1},{"text":"check dns server","id":"check-dns-server","depth":3,"charIndex":474}],"domain":"","frontmatter":{},"version":""},{"id":20,"title":"General","content":"#\n\nexport ALL_PROXY=socks5://10.2.3.33:1080 set ALL_PROXY=socks5://127.0.0.1:1080\n\n\npartition#\n\n/boot 1g /boot/efi 500m /home swap 物理内存两倍 /\n\n\nkvm#\n\n\ncheck if cpu suport it.#\n\negrep -c '(svm|vmx)' /proc/cpuinfo\n\nit should > 0\n\n\ninstall kvm#\n\n * sudo apt update\n * sudo apt install virt-manager\n\nAdd your user to the kvm and libvirt groups:\n\n\n\n\nmanage#\n\n * virsh list\n * virt-manager\n\n\nvs code desktop#\n\n\ngo to#\n\n/usr/share/applications ~/.local/share/applications/code.desktop\n\n\ncreate a file#\n\n[Desktop Entry] Name=Visual Studio Code\nExec=/home/chiching/apps/VSCode-linux-x64/code\nIcon=/home/chiching/apps/VSCode-linux-x64/resources/app/resources/linux/code.png\nType=Application Categories=Utility;TextEditor;Development;IDE;\nMimeType=text/plain; Terminal=false","routePath":"/notes/01-Cloud Computing/Linux/general","lang":"","toc":[{"text":"partition","id":"partition","depth":2,"charIndex":83},{"text":"kvm","id":"kvm","depth":2,"charIndex":141},{"text":"check if cpu suport it.","id":"check-if-cpu-suport-it","depth":3,"charIndex":148},{"text":"install kvm","id":"install-kvm","depth":3,"charIndex":226},{"text":"manage","id":"manage","depth":3,"charIndex":342},{"text":"vs code desktop","id":"vs-code-desktop","depth":2,"charIndex":383},{"text":"go to","id":"go-to","depth":3,"charIndex":402},{"text":"create a file","id":"create-a-file","depth":3,"charIndex":477}],"domain":"","frontmatter":{},"version":""},{"id":21,"title":"Hub Hardening","content":"#\n\nThese hardening steps are in order to satisfy the requiment of MTR's server\nsecurity, more detailed requirments please refer to the Unix Server Security\nHardening Guide.pdf\n\n\n2. Account Policy#\n\n * edit file /etc/ssh/sshd_config, to make sure following configuration.\n   \n   \n\n * sudo systemctl restart sshd\n\n\n2.1 Privileged Accounts#\n\nRequirments: Automatic account lockout after consecutive login failures is not\nimplemented because it can be used as a form of denial of service. It may lock\nout the entire server if the root account is locked.\n\nAction: Root account was\n\n\n2.2.1 Administrative Accounts#\n\nWe use ssh key to login, no password managment.\n\n\n2.2.2 System Accounts#\n\nsudo usermod -L daemon sudo usermod -L bin sudo usermod -L sys sudo usermod -L\nuucp sudo usermod -L lp sudo usermod -L nobody sudo usermod -L games sudo\nusermod -L news sudo usermod -L www-data sudo usermod -L mail\n\n\n2.3 System Account Management Improvement#\n\nNot apply, we have and hub account exist.\n\n\n2.4 Privileged Account Controls#\n\nNot apply.\n\n\n3 Password Policy#\n\nNot Apply, We use ssh key to login, no password managment.\n\n\n4 System Logging Policy#\n\nif the client do not need to centralize the log, skip this step.\n\n * Edit /etc/rsyslog.conf file\n * Add *.info @syslog.corp.mtrc.com # different client may use different syslog\n   server, make sure change it.\n * sudo systemctl restart rsyslog.service\n\n\n5 Clock Synchronization#\n\nIf the client don't have ntp server, skip this step or just install ntp servie\nis fine.\n\n * sudo apt-get install ntp\n\n * sudo vim /etc/ntp.conf, remark all pool and restrict start lines, add\n   following lines to the end of file. Please take care of the server for\n   different clients.\n   \n   \n\n * sudo systemctl restart ntp\n\n\n6 Minimize inetd network services#\n\nWe don't have the listed servcies installed.\n\n\n7 Disable un-necessary services#\n\nWe don't have the listed servcies installed. If there is servie un-necessary.\nrun systemctl disable to disable it.\n\n\n8 Restrict File/ Directory Permissions to Authorized Users#\n\nDon't have this kind of files.\n\n\n9 Restrict System Access, Authentication, and Authorization#\n\n\n9.1 Enable Hidden Passwords#\n\nIt use shadow passwords by default, and we do't use password.\n\n\n9.2 Restrict at/cron to authorized users#\n\nsudo vim /etc/cron.d/cron.allow Add one user per line. If there are no users in\n/etc/cron.d/cron.allow, only root user will be allowed to use crontab. It's an\nempty file.\n\n\n9.3 Restrict crontab file permissions#\n\nWe don't have crotnab file\n\n\n9.4 Set retry limit for account lockout#\n\nIt seems this is not suitable for account.\n\n\n9.5 Session Timeout Policy#\n\n * edit /etc/profile\n * Add export TMOUT=1800\n\n\n10 Secure User Accounts and Environment#\n\n\n10.1 Verify that there are no accounts with empty password field#\n\nWe use ssh key to login, no password.\n\n\n10.2 Secure user home directories#\n\nsudo chmod 750 autotunnel sudo chmod 750 sudo chmod 750 hub\n\n\n10.3 No user dot-files should be group/world writable#\n\nsudo chmod g-w .* sudo chmod o-w .*\n\n\n10.4 Set default umask for users#\n\n * edit /etc/profile\n * Add umask 002, or maybe 027. MTR requested 002.\n\n\n10.5 Set \"mesg n\" as default for all users#\n\n * edit /etc/profile\n * Add mesg n\n\n\n11 Warning Banners#\n\n * sudo vim /etc/pam.d/sshd\n * remark this line. # session optional pam_motd.so motd=/run/motd.dynamic\n * sudo systemctl stop motd-news.timer\n * sudo systemctl disable motd-news.timer\n\n\n12 SNMP Setting#\n\nwe don't have SNMP installed.\n\n\n13 Security Patches#\n\nsudo apt-get update to install all updates.","routePath":"/notes/01-Cloud Computing/Linux/hub hardening","lang":"","toc":[{"text":"2. Account Policy","id":"2-account-policy","depth":2,"charIndex":177},{"text":"2.1 Privileged Accounts","id":"21-privileged-accounts","depth":3,"charIndex":312},{"text":"2.2.1 Administrative Accounts","id":"221-administrative-accounts","depth":3,"charIndex":577},{"text":"2.2.2 System Accounts","id":"222-system-accounts","depth":3,"charIndex":659},{"text":"2.3 System Account Management Improvement","id":"23-system-account-management-improvement","depth":2,"charIndex":900},{"text":"2.4 Privileged Account Controls","id":"24-privileged-account-controls","depth":2,"charIndex":988},{"text":"3 Password Policy","id":"3-password-policy","depth":2,"charIndex":1035},{"text":"4 System Logging Policy","id":"4-system-logging-policy","depth":2,"charIndex":1116},{"text":"5 Clock Synchronization","id":"5-clock-synchronization","depth":2,"charIndex":1395},{"text":"6 Minimize inetd network services","id":"6-minimize-inetd-network-services","depth":2,"charIndex":1749},{"text":"7 Disable un-necessary services","id":"7-disable-un-necessary-services","depth":2,"charIndex":1832},{"text":"8 Restrict File/ Directory Permissions to Authorized Users","id":"8-restrict-file-directory-permissions-to-authorized-users","depth":2,"charIndex":1983},{"text":"9 Restrict System Access, Authentication, and Authorization","id":"9-restrict-system-access-authentication-and-authorization","depth":2,"charIndex":2077},{"text":"9.1 Enable Hidden Passwords","id":"91-enable-hidden-passwords","depth":3,"charIndex":2140},{"text":"9.2 Restrict at/cron to authorized users","id":"92-restrict-atcron-to-authorized-users","depth":3,"charIndex":2234},{"text":"9.3 Restrict crontab file permissions","id":"93-restrict-crontab-file-permissions","depth":3,"charIndex":2450},{"text":"9.4 Set retry limit for account lockout","id":"94-set-retry-limit-for-account-lockout","depth":3,"charIndex":2519},{"text":"9.5 Session Timeout Policy","id":"95-session-timeout-policy","depth":3,"charIndex":2606},{"text":"10 Secure User Accounts and Environment","id":"10-secure-user-accounts-and-environment","depth":2,"charIndex":2683},{"text":"10.1 Verify that there are no accounts with empty password field","id":"101-verify-that-there-are-no-accounts-with-empty-password-field","depth":3,"charIndex":2726},{"text":"10.2 Secure user home directories","id":"102-secure-user-home-directories","depth":3,"charIndex":2833},{"text":"10.3 No user dot-files should be group/world writable","id":"103-no-user-dot-files-should-be-groupworld-writable","depth":3,"charIndex":2931},{"text":"10.4 Set default umask for users","id":"104-set-default-umask-for-users","depth":3,"charIndex":3025},{"text":"10.5 Set \"mesg n\" as default for all users","id":"105-set-mesg-n-as-default-for-all-users","depth":3,"charIndex":3134},{"text":"11 Warning Banners","id":"11-warning-banners","depth":2,"charIndex":3216},{"text":"12 SNMP Setting","id":"12-snmp-setting","depth":2,"charIndex":3423},{"text":"13 Security Patches","id":"13-security-patches","depth":2,"charIndex":3473}],"domain":"","frontmatter":{},"version":""},{"id":22,"title":"Hugepage","content":"#\n\n\nview hugepgage value#\n\ncat /proc/meminfo |grep Huge\n\n\nview mount status#\n\ncat /proc/mounts | grep huge\n\n\nview hugepage config#\n\ncat /proc/cmdline BOOT_IMAGE=/vmlinuz-3.10.0-957.1.3.el7.x86_64\nroot=/dev/mapper/VG_Root-root ro crashkernel=auto rhgb quiet\ndefault_hugepagesz=1G hugepagesz=1G hugepages=70 transparent_hugepage=never\nisolcpus=1-9,11-19,21-29,31-39\n\ncat /etc/default/grub GRUB_CMDLINE_LINUX=\"crashkernel=auto rhgb quiet\ndefault_hugepagesz=1G hugepagesz=1G hugepages=70 transparent_hugepage=never\nisolcpus=1-9,11-19,21-29,31-39\"\n\n\nconfig hugepage#\n\n\nedit grub#\n\n\n\n\nedit sysctl#\n\n/etc/sysctl.conf vm.nr_hugepages echo 10 > /proc/sys/vm/nr_hugepages\n\n\nmount device#\n\n#mkdir -p /mnt/huge #mkdir -p /mnt/huge_2mb\n\n#mount -t hugetlbfs none /mnt/huge_2mb -o pagesize=2MB（没有-o参数，挂载系统默认hugepage大小,\n-o参数指定挂载2M的hugepage大小）","routePath":"/notes/01-Cloud Computing/Linux/hugepage","lang":"","toc":[{"text":"view hugepgage value","id":"view-hugepgage-value","depth":2,"charIndex":3},{"text":"view mount status","id":"view-mount-status","depth":2,"charIndex":57},{"text":"view hugepage config","id":"view-hugepage-config","depth":2,"charIndex":108},{"text":"config hugepage","id":"config-hugepage","depth":2,"charIndex":544},{"text":"edit grub","id":"edit-grub","depth":3,"charIndex":563},{"text":"edit sysctl","id":"edit-sysctl","depth":2,"charIndex":578},{"text":"mount device","id":"mount-device","depth":2,"charIndex":663}],"domain":"","frontmatter":{},"version":""},{"id":23,"title":"","content":"ebtables/iptables interaction on a Linux-based bridge","routePath":"/notes/01-Cloud Computing/Linux/iptable","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":24,"title":"dnsmasq","content":"#\n\n","routePath":"/notes/01-Cloud Computing/Linux/ipxe/dnsmasq","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":25,"title":"ipxe","content":"#\n\n\nbios files#\n\nhttp://boot.ipxe.org/undionly.kpxe\n\n\nuefi files#\n\nhttp://boot.ipxe.org/ipxe.efi\n\n\n引用#\n\n * [1] ipxe\n\n * [2] boot ipxe\n\n:install_debian initrd\nhttp://cdn.debian.net/debian/dists/${release}/main/installer-${arch}/current/ima\nges/netboot/debian-installer/${arch}/initrd.gz chain\nhttp://cdn.debian.net/debian/dists/${release}/main/installer-${arch}/current/ima\nges/netboot/debian-installer/${arch}/linux\nurl=http://preseed.panticz.de/preseed/debian-minimal.seed auto=true\nnetcfg/choose_interface=${net0/mac} priority=critical ${autopart}\n\nkernel\nhttp://deb.debian.org/debian/dists/stretch/main/installer-amd64/current/images/n\netboot/debian-installer/amd64/linux initrd=initrd.gz initrd\nhttp://deb.debian.org/debian/dists/stretch/main/installer-amd64/current/images/n\netboot/debian-installer/amd64/initrd.gz","routePath":"/notes/01-Cloud Computing/Linux/ipxe/ipxe","lang":"","toc":[{"text":"bios files","id":"bios-files","depth":2,"charIndex":3},{"text":"uefi files","id":"uefi-files","depth":2,"charIndex":53},{"text":"引用","id":"引用","depth":2,"charIndex":98}],"domain":"","frontmatter":{},"version":""},{"id":26,"title":"tftp","content":"#\n\n\n\n\nstart it#\n\ndocker run -p 0.0.0.0:69:69/udp -v /opt/tftpd/data:/data -i -t 2b247bf931f7\n\n\nfiles#\n\n","routePath":"/notes/01-Cloud Computing/Linux/ipxe/tftp","lang":"","toc":[{"text":"start it","id":"start-it","depth":2,"charIndex":5},{"text":"files","id":"files","depth":2,"charIndex":94}],"domain":"","frontmatter":{},"version":""},{"id":27,"title":"LXC","content":"#\n\n\n更换源#\n\n\n\n\n特权容器#\n\n无特殊情况，首选特权容器。特权容器外挂pve的目录更方便，而且特权容器也是支持docker的。nano /etc/pve/lxc/容器id.conf\n添加下面几行\n\nlxc.apparmor.profile: unconfined lxc.cgroup.devices.allow: a lxc.cap.drop:\n\n\n安装docker#\n\nsed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories\n\n\n安装时区设置#\n\napk add tzdata cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime echo\n\"Asia/Shanghai\" > /etc/timezone\n\n\n卸载时区#\n\napk del tzdata rm -rf /var/cache/apk/*\n\n\n安装docker#\n\napk add docker #nano rm -rf /var/cache/apk/*\n\n\n开机启动启动docker#\n\nrc-update add docker boot\n\n\n手动启动docker#\n\nservice docker start\n\n\n查看docker版本#\n\ndocker version\n\n\n直通显卡#\n\nvim /etc/pve/lxc/102.conf\n\n需要添加以下内容\n\n\n\n\n引用#\n\n 1. 容器 https://dev.leiyanhui.com/pve/docker-mini/\n 2. 换源 https://mirrors.tuna.tsinghua.edu.cn/help/proxmox/\n 3. 扩容 https://post.smzdm.com/p/ad9dngwx/\n 4. 直通显卡\n    https://blog.hellowood.dev/posts/%E5%9C%A8pve%E7%9A%84lxc%E5%AE%B9%E5%99%A8%\n    E4%B8%AD%E7%9B%B4%E9%80%9A%E6%A0%B8%E5%BF%83%E6%98%BE%E5%8D%A1/","routePath":"/notes/01-Cloud Computing/Linux/lxc","lang":"","toc":[{"text":"更换源","id":"更换源","depth":2,"charIndex":3},{"text":"特权容器","id":"特权容器","depth":2,"charIndex":12},{"text":"安装docker","id":"安装docker","depth":2,"charIndex":179},{"text":"安装时区设置","id":"安装时区设置","depth":3,"charIndex":270},{"text":"卸载时区","id":"卸载时区","depth":3,"charIndex":385},{"text":"安装docker","id":"安装docker-1","depth":3,"charIndex":433},{"text":"开机启动启动docker","id":"开机启动启动docker","depth":3,"charIndex":491},{"text":"手动启动docker","id":"手动启动docker","depth":3,"charIndex":534},{"text":"查看docker版本","id":"查看docker版本","depth":3,"charIndex":570},{"text":"直通显卡","id":"直通显卡","depth":2,"charIndex":600},{"text":"引用","id":"引用","depth":2,"charIndex":647}],"domain":"","frontmatter":{},"version":""},{"id":28,"title":"Macchanger","content":"#\n\n\ninstall#\n\nsudo apt-get install macchanger\n\n\nuninstall#\n\nsudo apt-get purge --auto-remove macchanger\n\n\nchange it#\n\nsudo ip link set eth0 down && sudo macchanger -r eth0&& sudo ip link set eth0 up\n\nsudo ip link set eth0 down && sudo macchanger -r eth0&& sudo shutdown -r now\n\nchange to a rundom mac: macchanger -r enp0s3 return to default: macchanger -p\nenp0s3\n\nsudo macchanger -m b2:aa:0e:56:ed:f7 enp0s3\n\n\nmethod 2: Using iproute2#\n\nFirst, turn off the Network card using command: sudo ip link set dev enp0s3 down\n\nNext, set the new MAC is using command: sudo ip link set dev enp0s3 address\nXX:XX:XX:XX:XX:XX\n\nFinally, turn it on back with command: sudo ip link set dev enp0s3 up\n\nNow, verify new MAC id using command: ip link show enp0s3\n\nsudo ip link set eth0 down && sudo ip link set eth0 address b8:27:eb:d6:28:33 &&\nsudo shutdown -r now","routePath":"/notes/01-Cloud Computing/Linux/mac changer","lang":"","toc":[{"text":"install","id":"install","depth":2,"charIndex":3},{"text":"uninstall","id":"uninstall","depth":2,"charIndex":47},{"text":"change it","id":"change-it","depth":2,"charIndex":105},{"text":"method 2: Using iproute2","id":"method-2-using-iproute2","depth":2,"charIndex":409}],"domain":"","frontmatter":{},"version":""},{"id":29,"title":"Network","content":"#\n\n\ntools#\n\n\nset up nic#\n\nip link set eth0 up\n\n\naddroute#\n\n * ip route add 192.168.121.0/24 dev enp7s0\n * ip route add 192.168.121.0/24 via 10.2.6.116\n\n\nadd ip#\n\nip addr add 10.2.3.110/24 dev ens33\n\n\ndel route#\n\n * sudo ip route del 192.168.192.0/24\n\n\nadd route#\n\n * sudo ip route add 192.168.192.0/24 via 192.168.136.200\n * sudo ip route add 192.168.190.0/24 via 192.168.136.200\n * sudo ip route add 192.168.70.0/24 via 192.168.136.200\n\n\nsub ip#\n\nip addr add 10.2.3.110/24 dev ens33 label ens33:1\n\n\nss#\n\nss -nat | awk '{print $5}'| awk -F: '{print $1}'|sort|uniq -c|sort -nr|head -20\n\nhexdump core.25867 | awk '{printf \"%s%s%s%s\\n%s%s%s%s\\n\",\n$5,$4,$3,$2,$9,$8,$7,$6}' | sort | uniq -c | sort -nr | head\n\nnetstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'","routePath":"/notes/01-Cloud Computing/Linux/network","lang":"","toc":[{"text":"tools","id":"tools","depth":2,"charIndex":3},{"text":"set up nic","id":"set-up-nic","depth":2,"charIndex":12},{"text":"addroute","id":"addroute","depth":2,"charIndex":47},{"text":"add ip","id":"add-ip","depth":2,"charIndex":152},{"text":"del route","id":"del-route","depth":2,"charIndex":199},{"text":"add route","id":"add-route","depth":2,"charIndex":251},{"text":"sub ip","id":"sub-ip","depth":3,"charIndex":438},{"text":"ss","id":"ss","depth":2,"charIndex":499}],"domain":"","frontmatter":{},"version":""},{"id":30,"title":"Security","content":"#\n\n * Check the current installed version apt show libuv1\n * Download the package to local apt download libuv1\n * Install on hub or other server that don't have internet dpkg -i\n   libuv1_1.34.2-1ubuntu1.3_amd64.deb\n\nneed to take care of the processor (machine architecture).\n\nThis time we have following pacakges need to upgrade. details can be fond in the\nattached file. libuv1 libnss-systemd libpam-systemd libsystemd0 libudev1 systemd\nsystemd-sysv udev curl libcurl3 libcurl4","routePath":"/notes/01-Cloud Computing/Linux/package","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":31,"title":"服务器系统磁盘管理之parted","content":"#\n\n\n查看新增数据盘 lsblk#\n\n\n对新增数据盘进行分区 parted /dev/vdc#\n\n * parted /dev/vdc mklabel gpt\n * parted /dev/vdc mkpart xfs 0GB ?GB\n\n\n对磁盘分区进行格式化#\n\nmkfs.xfs /dev/vdc1\n\n\n挂载磁盘分区#\n\n * mkdir /data\n * mount /dev/vdc1 /data\n * blkid 查看磁盘分区id 将 UUID=xxxx /data xfs defaults 0 0 写入 /etc/fstab\n * 或者 /dev/vdc1 /data xfs defaults 0 0","routePath":"/notes/01-Cloud Computing/Linux/parted","lang":"","toc":[{"text":"查看新增数据盘  lsblk","id":"查看新增数据盘--lsblk","depth":2,"charIndex":-1},{"text":"对新增数据盘进行分区 `parted /dev/vdc`","id":"对新增数据盘进行分区-parted-devvdc","depth":2,"charIndex":-1},{"text":"对磁盘分区进行格式化","id":"对磁盘分区进行格式化","depth":2,"charIndex":120},{"text":"挂载磁盘分区","id":"挂载磁盘分区","depth":2,"charIndex":154}],"domain":"","frontmatter":{},"version":""},{"id":32,"title":"performance","content":"#\n\n\n\n 1.  uptime\n 2.  dmesg | tail\n 3.  vmstat 1\n 4.  mpstat -P ALL 1\n 5.  pidstat 1\n 6.  iostat -xz 1\n 7.  free -m\n 8.  sar -n DEV 1\n 9.  sar -n TCP,ETCP 1\n 10. top\n\nhttps://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-ac\ncc10403c55","routePath":"/notes/01-Cloud Computing/Linux/performance","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":33,"title":"PVE","content":"#\n\n\n网卡直通#\n\n\n打开直通#\n\n * 编辑 vim /etc/default/grub。\n * 注释并添加\n\n> \n\n * 更新配置 update-grub\n\n\n安装模块#\n\n * 编辑 vim /etc/modules\n * 添加\n\n> \n\n * 更新配置 update-initramfs -u -k all\n\n然后重启PVE节点\n\n\n扩容#\n\ndd if=/dev/zero bs=1G count=2 >> openwrt.img\n\n\n\n\nimport disk#\n\nqm disk import 100 /var/lib/vz/template/iso/openwrt.img local-lvm\n\n\nopenwrt config#\n\nvim /etc/config/network\n\n\n\nservice network restart\n\nThe installed version of package kernel is not compatible, require 5.15.137-1-1\nwhile 5.15.137-1-47964456… is installed.\nhttps://hamy.io/post/0015/how-to-compile-openwrt-and-still-use-the-official-repo\nsitory/","routePath":"/notes/01-Cloud Computing/Linux/pve","lang":"","toc":[{"text":"网卡直通","id":"网卡直通","depth":2,"charIndex":3},{"text":"打开直通","id":"打开直通","depth":3,"charIndex":11},{"text":"安装模块","id":"安装模块","depth":3,"charIndex":83},{"text":"扩容","id":"扩容","depth":2,"charIndex":172},{"text":"import disk","id":"import-disk","depth":2,"charIndex":226},{"text":"openwrt config","id":"openwrt-config","depth":2,"charIndex":308}],"domain":"","frontmatter":{},"version":""},{"id":34,"title":"set ip","content":"#\n\nsudo vim /etc/dhcpcd.conf\n\ninterface eth0 static ip_address=192.168.0.5/24 static routers=192.168.0.1\nstatic domain_name_servers=192.168.0.1","routePath":"/notes/01-Cloud Computing/Linux/raspberry_pi","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":35,"title":"Client","content":"RDP#\n\n\nServer#\n\n\nInstallation#\n\n\n\n\nConfiguration#\n\nsudo adduser UserName\n\necho xfce4-session > ~/.xsession\n\necho gnome-session > ~/.xsession\n\n关闭用户图形界面，使用tty登录。\n\nsudo systemctl set-default multi-user.target sudo reboot\n\n开启用户图形界面。\n\nsudo systemctl set-default graphical.target sudo reboot\n\n\nClient#\n\n","routePath":"/notes/01-Cloud Computing/Linux/rdp","lang":"","toc":[{"text":"Server","id":"server","depth":2,"charIndex":6},{"text":"Installation","id":"installation","depth":3,"charIndex":16},{"text":"Configuration","id":"configuration","depth":3,"charIndex":34}],"domain":"","frontmatter":{},"version":""},{"id":36,"title":"Serivce structure","content":"#\n\n","routePath":"/notes/01-Cloud Computing/Linux/service","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":37,"title":"Netplan static ip","content":"#\n\nsudo vim /etc/netplan/01-network-manager-all.yaml\n\n\n\nsudo netplan --debug apply\n\nRef\n\n\nnew routes#\n\nThis is the network config written by 'subiquity' network: ethernets: ens160:\ndhcp4: no dhcp6: no addresses: [10.230.168.111/24] routes: - to: default via:\n10.230.168.1 nameservers: addresses: [8.8.8.8, 8.8.4.4] version: 2","routePath":"/notes/01-Cloud Computing/Linux/staticip","lang":"","toc":[{"text":"new routes","id":"new-routes","depth":2,"charIndex":89}],"domain":"","frontmatter":{},"version":""},{"id":38,"title":"Wechat","content":"#\n\n\n允许所有用户访问X11服务,运行命令:#\n\n\n\n\n查看系统audio gid#\n\ncat /etc/group | grep audio\n\n\ndocker-compose.yml#\n\n","routePath":"/notes/01-Cloud Computing/Linux/wechat","lang":"","toc":[{"text":"允许所有用户访问X11服务,运行命令:","id":"允许所有用户访问x11服务运行命令","depth":2,"charIndex":3},{"text":"查看系统audio gid","id":"查看系统audio-gid","depth":2,"charIndex":28},{"text":"docker-compose.yml","id":"docker-composeyml","depth":2,"charIndex":74}],"domain":"","frontmatter":{},"version":""},{"id":39,"title":"Openstack","content":"#\n\n\nref#\n\n 1. 安装victoria\n 2. 离线Train版安装\n 3. devstack","routePath":"/notes/01-Cloud Computing/Openstack","lang":"","toc":[{"text":"ref","id":"ref","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":40,"title":"Start workstation wifi","content":"#\n\nnetsh wlan set hostednetwork mode=allow ssid=wifi的名字 key=密码 netsh wlan start\nhostednetwork netsh wlan stop hostednetwork","routePath":"/notes/01-Cloud Computing/Windows/Start workstation wifi","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":41,"title":"route print 查看if 口","content":"addroute#\n\nroute add 192.168.121.0 mask 255.255.255.0 10.2.6.116\n\n\nroute print 查看if 口#\n\n\n添加路由。#\n\nroute add 10.230.169.0 mask 255.255.255.0 172.30.93.53 if 4","routePath":"/notes/01-Cloud Computing/Windows/addroute","lang":"","toc":[{"text":"添加路由。","id":"添加路由","depth":2,"charIndex":88}],"domain":"","frontmatter":{},"version":""},{"id":42,"title":"","content":"type %USERPROFILE%\\.ssh\\id_ed25519.pub | ssh ubuntu@192.168.3.208 \"cat >>\n.ssh/authorized_keys\"","routePath":"/notes/01-Cloud Computing/Windows/cmds","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":43,"title":"msys2","content":"#\n\n\ninstallation#\n\n * download from https://github.com/msys2/msys2-installer/releases\n * unzip to a path, like d:\\apps\\msys2\n * add the path d:\\apps\\msys2\\usr\\bin to windows path.\n\n\nchange the pacman source by editing the files in \\etc\\pacman.d#\n\nmirrorlist.mingw32\n\n\n\nmirrorlist.mingw64\n\n\n\nmirrorlist.msys\n\n\n\nthen run pacman -Syyu to force update\n\n\nintegrate with windows terminal#\n\nwin + r and input wt to open the terminal, settings (ctrl +,), open the json\nfile, add bellow code to the profile list.\n\n\n\n\nintegrate with vs code#\n\nadd bellow code to .vscode/settings.json file\n\n","routePath":"/notes/01-Cloud Computing/Windows/msys2","lang":"","toc":[{"text":"installation","id":"installation","depth":2,"charIndex":3},{"text":"change the pacman source by editing the files in `\\etc\\pacman.d`","id":"change-the-pacman-source-by-editing-the-files-in-etcpacmand","depth":2,"charIndex":-1},{"text":"integrate with windows terminal","id":"integrate-with-windows-terminal","depth":2,"charIndex":349},{"text":"integrate with vs code","id":"integrate-with-vs-code","depth":2,"charIndex":507}],"domain":"","frontmatter":{},"version":""},{"id":44,"title":"task","content":"#\n\n\ninstall TASK#\n\n\n\n\nuninstall task#\n\n","routePath":"/notes/01-Cloud Computing/Windows/tasks","lang":"","toc":[{"text":"install TASK","id":"install-task","depth":2,"charIndex":3},{"text":"uninstall task","id":"uninstall-task","depth":2,"charIndex":21}],"domain":"","frontmatter":{},"version":""},{"id":45,"title":"430install","content":"#\n\n\ninstall flutter#\n\nhttps://flutter.dev/docs/get-started/install/linux export\nPATH=$PATH:$HOME/apps/flutter/bin\n\n\ninstall android sdk#\n\nhttps://developer.android.com/studio/index.html#downloads\n\nexport PATH=$PATH:$HOME/apps/android-sdk/tools/bin sdkmanager \"platform-tools\"\n--sdk_root=$HOME/apps/android-sdk sdkmanager \"build-tools;29.0.2\"\n--sdk_root=$HOME/apps/android-sdk sdkmanager \"platforms;android-29\"\n--sdk_root=$HOME/apps/android-sdk sdkmanager\n\"system-images;android-29;google_apis_playstore;x86_64\"\n--sdk_root=$HOME/apps/android-sdk\n\nexport ANDROID_SDK_ROOT=$HOME/apps/android-sdk/ export\nANDROID_HOME=$ANDROID_SDK_ROOT export PATH=${PATH}:${ANDROID_HOME}/tools export\nPATH=${PATH}:${ANDROID_HOME}/platform-tools flutter doctor -v\n\nflutter emulators --launch phone01 flutter run -v","routePath":"/notes/02-Software Development/flutter/430install","lang":"","toc":[{"text":"install flutter","id":"install-flutter","depth":2,"charIndex":3},{"text":"install android sdk","id":"install-android-sdk","depth":2,"charIndex":115}],"domain":"","frontmatter":{},"version":""},{"id":46,"title":"Android","content":"#\n\n\ninstall sdk#\n\n * download commond tools\n * install the latest jdk\n * create folder android-sdk\n * Create new folders cmdline-tools, platforms and platform-tools inside\n   android-sdk\n * cd C:\\android-sdk\\cmdline-tools\\tools\\bin\n * sdkmanager --list\n * sdkmanager --install system-images;android-35;google_apis_playstore;x86_64\n * sdkmanager \"platform-tools\" \"platforms;android-35\" \"emulator\"\n * avdmanager create avd --name android35 --package\n   \"system-images;android-35;google_apis_playstore;x86_64\"\n * go to C:\\android-sdk\\emulator\n * emulator -avd android35 -qemu -m 3000\n\n\nerror#\n\ncan not clost the emulator\n\n * netstat -ano, find the process 5555\n * taskkill /pid 23368 -f\n\n\nREF#\n\nhow-to-install--android-emulator-without--android--st close emulator","routePath":"/notes/02-Software Development/flutter/431android","lang":"","toc":[{"text":"install sdk","id":"install-sdk","depth":2,"charIndex":3},{"text":"error","id":"error","depth":2,"charIndex":582},{"text":"REF","id":"ref","depth":2,"charIndex":685}],"domain":"","frontmatter":{},"version":""},{"id":47,"title":"REPL","content":"#\n\ngo get -u github.com/motemen/gore/cmd/gore\n\nhttps://play.golang.org/","routePath":"/notes/02-Software Development/go/REPL","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":48,"title":"bazel","content":"#\n\n\ninstall#\n\ncurl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add - echo \"deb\n[arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\" | sudo tee\n/etc/apt/sources.list.d/bazel.list sudo apt install openjdk-11-jdk sudo apt\nupdate sudo apt install bazel\n\n\ngenerate build.bazel file#\n\nbazel run //:gazelle bazel run //:gazelle -- update-repos -from_file=go.mod\n\n\nbuild#\n\nbazel build //... bazel build //cmd/porter\n\ndefaut out files:\n/home/chiching/.cache/bazel/_bazel_chiching/f082d6158c80191153f706865b4c6eef/exe\ncroot/main/bazel-out/k8-fastbuild/bin/\n\n\nclean#\n\nbazel clean","routePath":"/notes/02-Software Development/go/bazel","lang":"","toc":[{"text":"install","id":"install","depth":2,"charIndex":3},{"text":"generate build.bazel file","id":"generate-buildbazel-file","depth":2,"charIndex":279},{"text":"build","id":"build","depth":2,"charIndex":385},{"text":"clean","id":"clean","depth":2,"charIndex":577}],"domain":"","frontmatter":{},"version":""},{"id":49,"title":"","content":"wagger#\n\ngo get -u github.com/swaggo/swag/cmd/swag go install\ngithub.com/swaggo/swag/cmd/swag@latest","routePath":"/notes/02-Software Development/go/doc","lang":"","toc":[{"text":"wagger","id":"wagger","depth":2,"charIndex":-1}],"domain":"","frontmatter":{},"version":""},{"id":50,"title":"Error","content":"#\n\n\nUnkown version for private repository#\n\nexample:\n\n\n\n\nSolution#\n\ngit config --global url.\"git@gitlab.com:\".insteadOf \"https://gitlab.com/\"\n\nor\n\n\n\n\ndependency packages#\n\ngo env -w GOPROXY=https://goproxy.cn,direct","routePath":"/notes/02-Software Development/go/error","lang":"","toc":[{"text":"Unkown version for private repository","id":"unkown-version-for-private-repository","depth":2,"charIndex":3},{"text":"Solution","id":"solution","depth":2,"charIndex":56},{"text":"dependency packages","id":"dependency-packages","depth":2,"charIndex":149}],"domain":"","frontmatter":{},"version":""},{"id":51,"title":"installation","content":"#\n\n``` https://grpc.io/docs/languages/go/quickstart/ ``\n\n * install protoc https://github.com/protocolbuffers/protobuf/releases\n * install grpc go get -u google.golang.org/grpc\n * install protoc-gen-go go install\n   google.golang.org/protobuf/cmd/protoc-gen-go@v1.28\n * install protoc-gen-go-grpc go install\n   google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2\n\nhttps://github.com/grpc/grpc-go\n\n\ngenearate file#\n\nprotoc -I portal/node/v1\n--go_out=plugins=grpc,paths=source_relative:./portal/node/v1\nportal/node/v1/*.proto\n\n\nfor v2#\n\nremove local pb.go and grpc.go files.\n\n","routePath":"/notes/02-Software Development/go/grpc","lang":"","toc":[{"text":"genearate file","id":"genearate-file","depth":2,"charIndex":396},{"text":"for v2","id":"for-v2","depth":3,"charIndex":524}],"domain":"","frontmatter":{},"version":""},{"id":52,"title":"install on ubuntu","content":"#\n\n 1. get file, and unzip it.\n\nhttps://dl.google.com/go/go1.11.4.linux-amd64.tar.gz\n\n 2. add path to ~.profile or /etc/profile\n\nexport PATH=$PATH:/home/chiching/apps/go/bin\n\n 3. make it working\n\nsource .profile\n\ngo env -w GOPRIVATE=github.com/en-trak","routePath":"/notes/02-Software Development/go/install on ubuntu","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":53,"title":"set proxy","content":"#\n\ngit config --global http.proxy http://127.0.0.1:1080 git config --global\nhttps.proxy http://127.0.0.1:1080\n\ngit config --global http.proxy http://10.2.3.51:1080 git config --global\nhttps.proxy http://10.2.3.51:1080","routePath":"/notes/02-Software Development/go/package error","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":54,"title":"","content":"export GOPROXY=\"https://goproxy.io\"","routePath":"/notes/02-Software Development/go/package","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":55,"title":"profile","content":"#\n\n\nimport package#\n\n\"net/http\" _ \"net/http/pprof\"\n\n\nlisten#\n\nhttp.ListenAndServe(\"0.0.0.0:9999\", nil)\n\n\ngraphviz#\n\nsudo apt install graphviz\n\n\nprofile cpu#\n\ngo tool pprof -http=:1234 http://127.0.0.1:9999/debug/pprof/profile?seconds=300\n\n\nprofile memery#\n\ngo tool pprof -http=:1234 http://127.0.0.1:9999/debug/pprof/heap\n\n\nprofile heap#\n\n/usr/local/go/bin/go tool pprof -inuse_space\nhttp://127.0.0.1:9999/debug/pprof/heap?seconds=300\n\n/usr/local/go/bin/go tool pprof -inuse_space\nhttp://127.0.0.1:9999/debug/pprof/profile\n\n/usr/local/go/bin/go tool pprof -http=:1234\nhttp://127.0.0.1:9999/debug/pprof/heap\n\n\nschedule#\n\n‵GODEBUG=\"schedtrace=2000,scheddetail=1\" ./service`","routePath":"/notes/02-Software Development/go/profile","lang":"","toc":[{"text":"import package","id":"import-package","depth":2,"charIndex":3},{"text":"listen","id":"listen","depth":2,"charIndex":52},{"text":"graphviz","id":"graphviz","depth":2,"charIndex":104},{"text":"profile cpu","id":"profile-cpu","depth":2,"charIndex":143},{"text":"profile memery","id":"profile-memery","depth":2,"charIndex":239},{"text":"profile heap","id":"profile-heap","depth":2,"charIndex":323},{"text":"schedule","id":"schedule","depth":2,"charIndex":608}],"domain":"","frontmatter":{},"version":""},{"id":56,"title":"tools","content":"#\n\n\n\n来自 https://www.cnblogs.com/heartchord/p/5127503.html\n\n\nclean test cache#\n\ngo clean -testcache","routePath":"/notes/02-Software Development/go/tools","lang":"","toc":[{"text":"clean test cache","id":"clean-test-cache","depth":2,"charIndex":59}],"domain":"","frontmatter":{},"version":""},{"id":57,"title":"build","content":"#\n\n","routePath":"/notes/02-Software Development/java/docker-build","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":58,"title":"maven","content":"#\n\n\n安装#\n\n * unzip the file to /opt/apps/maven\n * add path export PATH=/opt/apps/maven/bin:$PATH\n\n\ninstall a jar package#\n\nmvn install:install-file -Dpackaging=jar -DgroupId=com.xiaoju.open\n-DartifactId=evcs-core -Dversion=0.2.0 -Dfile=./evcs-core-0.2.0.jar\n\n\nbuild project#\n\nmvn package","routePath":"/notes/02-Software Development/java/mvn","lang":"","toc":[{"text":"安装","id":"安装","depth":2,"charIndex":3},{"text":"install a jar package","id":"install-a-jar-package","depth":2,"charIndex":97},{"text":"build project","id":"build-project","depth":2,"charIndex":258}],"domain":"","frontmatter":{},"version":""},{"id":59,"title":"","content":"创建该账号快捷方式用以测试\n\n然后，在快捷方式 属性，目标中，输入： --args --disable-web-security\n--user-data-dir=C:\\Users\\chiching\\Desktop\\temp\n\n其中，temp为新建的目录，存放浏览器相关信息\n\n打开浏览器，如果出现 chrome://welcome/ 定制你的专属chrome 就可以了","routePath":"/notes/02-Software Development/js/cors","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":60,"title":"start or build","content":"electron_reactjs#\n\n\ncreate reactjs#\n\nnpx create-react-app --typescript\n\n\nadd dependency#\n\nnpm install --save cross-env electron-is-dev npm install concurrently electron\nelectron-builder wait-on\n\n\ncreate electron.js in public folder#\n\n\n\n\nchange in our package.json file#\n\nAdd below information in your package.json file — \"description\": \"\", \"author\":\n\"\", \"build\": { \"appId\": \"\" }, \"main\": \"public/electron.js\", \"homepage\": \"./\",\n\nupdate scripts element inside your package.json like below — \"scripts\": {\n\"react-start\": \"react-scripts start\", \"react-build\": \"react-scripts build\",\n\"react-test\": \"react-scripts test --env=jsdom\", \"react-eject\": \"react-scripts\neject\", \"electron-build\": \"electron-builder\", \"release\": \"yarn react-build &&\nelectron-builder --publish=always\", \"build\": \"yarn react-build && yarn\nelectron-build\", \"start\": \"concurrently \\\"cross-env BROWSER=none yarn\nreact-start\\\" \\\"wait-on http://localhost:3000 && electron .\\\"\" },\n\n\nstart or build#\n\nnpm run react-build && npm run electron-build","routePath":"/notes/02-Software Development/js/electron_reactjs","lang":"","toc":[{"text":"create  reactjs","id":"create--reactjs","depth":2,"charIndex":-1},{"text":"add dependency","id":"add-dependency","depth":2,"charIndex":72},{"text":"create electron.js in public folder","id":"create-electronjs-in-public-folder","depth":2,"charIndex":195},{"text":"change in our package.json file","id":"change-in-our-packagejson-file","depth":2,"charIndex":236}],"domain":"","frontmatter":{},"version":""},{"id":61,"title":"react app","content":"#\n\n\nby webpack#\n\n * create app yarn create react-app APP or npx create-react-app APP\n\n\nby vite#\n\n * init project by vite: yarn create vite vChat --template react\n\n * add eslint: yarn add --dev eslint-config-react-app\n   @typescript-eslint/eslint-plugin@^4.0.0 @typescript-eslint/parser@^4.0.0\n   babel-eslint@^10.0.0 eslint@^7.5.0 eslint-plugin-flowtype@^5.2.0\n   eslint-plugin-import@^2.22.0 eslint-plugin-jsx-a11y@^6.3.1\n   eslint-plugin-react@^7.20.3 eslint-plugin-react-hooks@^4.0.8\n\n\nAdd others#\n\n * add bootstrap yarn add bootstrap react-bootstrap\n * add i18 yarn add i18next react-i18next i18next-http-backend\n   i18next-browser-languagedetector","routePath":"/notes/02-Software Development/js/react app","lang":"","toc":[{"text":"by webpack","id":"by-webpack","depth":2,"charIndex":3},{"text":"by vite","id":"by-vite","depth":2,"charIndex":86},{"text":"Add others","id":"add-others","depth":2,"charIndex":488}],"domain":"","frontmatter":{},"version":""},{"id":62,"title":"compile","content":"#\n\nluajit -bg /path/to/abc.lua /path/to/abc.ljbc","routePath":"/notes/02-Software Development/lua/compile","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":63,"title":"Docker","content":"#\n\n\nclear log#\n\n * find log file docker container inspect --format='{{.LogPath}}' [CONTAINER\n   ID/NAME]\n * truncate it truncate -s 0 /path/to/logfile","routePath":"/notes/02-Software Development/middlewares/docker","lang":"","toc":[{"text":"clear log","id":"clear-log","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":64,"title":"","content":"#【HarmonyOS HiSpark Wi-Fi IoT 智能家居套件】编译脚本学习1\n\n参考教程搭建好了环境后，第一步开始编译，运行python build.py wifiiot。突然有了几个问题。\n\n 1. 为什么开始编译是运行一个python脚本，鸿蒙不是c语言写的吗？\n 2. 如果知道编译构建是用gn, ninja，安装过程中的确有安装这些工具，但是没有用到啊？\n 3. 这个脚本有啥用呢？\n\n接下来大概看一下脚本就明白这几个问题了。\n\n在看编译相关的东西的时候，可能猜也猜到了相关的东西是放在build文件夹里面的。\n\n首先看看build.py文件，看构建是怎么开始的。 看下面main函数的注释。\n\n\n\n接着看build/lite/compile.py中的exec_command函数。\n\n\n\n到这里就已经完了，再里面就是config_create，run_build的细节，但是上面的问题还是不清晰。\n\n下面再跟进config_create看一下： config_create(compile_process.py) -> check_build ->\nparse_product_json -> Compile.get_tool_path(config.py)\nget_tool_path函数中，就有找riscv32-unknown-elf-gcc，gn和ninja等工具的路径。\n\n再看一下run_build： run_build(compile_process.py)-> Compile.compile (config.py) ->\nexec_command(util.py) exec_command这里开了新的进程，来跑上面准备好的命令和参数。\n\n最终执行的，就是两个：\n\n\n\n如果不用python脚本，直接执行上面两个命令，效果一样。 gn根据当前的代码树及配置，产生ninja文件，并把它们放在给定的目录下，然后ninja开始编译\n\n所以，python脚本可能就是为了简化，标准化，跨平台等，不用记忆那些命令，格式以及参数等。","routePath":"/notes/02-Software Development/middlewares/harmony/1.build","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":65,"title":"https://www.harmonyos.com/","content":"#\n\n\ndocs#\n\nhttps://gitee.com/openharmony/docs\n\n\nsetup environment#\n\n * get the code\n   https://gitee.com/openharmony/docs/blob/master/get-code/%E6%BA%90%E7%A0%81%E8\n   %8E%B7%E5%8F%96.md\n * install SCons https://scons.org/\n * download ninja https://ninja-build.org/\n * download GN https://gn.googlesource.com/gn\n * install gcc_riscv32\n   http://tools.harmonyos.com/mirrors/gcc_riscv32/7.3.0/linux/gcc_riscv32-linux-\n   7.3.0.tar.gz\n\npip3 install pycryptodome pip3 install ecdsa\n\n/usr/bin/gn gen /home/chiching/projects/harmony/code/out/wifiiot --root=.\n--dotfile=build/lite/.gn --args='product = \"wifiiot\" ohos_build_type =\n\"release\"'\n\n/usr/bin/ninja -w dupbuild=warn -C\n/home/chiching/projects/harmony/code/out/wifiiot","routePath":"/notes/02-Software Development/middlewares/harmony/dev enrionment","lang":"","toc":[{"text":"docs","id":"docs","depth":2,"charIndex":3},{"text":"setup environment","id":"setup-environment","depth":2,"charIndex":47}],"domain":"","frontmatter":{},"version":""},{"id":66,"title":"MQTT","content":"#\n\n\nserver#\n\ndocker run -d -p 1883:1883 -p 9001:9001 eclipse-mosquitto\n\n\nPublic free mqtt brokers:#\n\nbroker.emqx.io 1883 / 8883(TLS) / 8083(websocket) broker.hivemq.com 1883 /\n8883(TLS)\n\ntest.jmqtt.io 1883 / 8000(websocket) iot.eclipse.org 1883 / 888(TLS)\ntest.mosquitto.org 1883 / 8883(TLS) / 8884 / 80803(websocket) / 80813(websocket)\nbroker.mqttdashboard.com 1883\n\n\ntest with mosquitto#\n\n\ntep dev#\n\nmosquitto_sub -h dev.mqtt.en-trak.app -u admin -P wrLsgeaD1lmGIwiC9k -t '#' -v\nmosquitto_sub -h dev.mqtt.en-trak.app -u admin -P wrLsgeaD1lmGIwiC9k -t\n'hub/+/status' -v\n\nmosquitto_sub -h 3.0.100.10 -u admin -P qte2dZ27uLsm7TR6PK -t 'ems/bacnet/data'\n-v\n\nmosquitto_sub -h 3.0.100.10 -u hub -P k8oBNj2Lvo2SVYSsO1 -t 'emsdata/#' -v\nmosquitto_pub -h 3.0.100.10 -u hub -P k8oBNj2Lvo2SVYSsO1 -t 'ems/bacnet/data' -m\n'test'\n\nmosquitto_pub -h 3.0.100.10 -u admin -P qte2dZ27uLsm7TR6PK -t 'ems/bacnet/data'\n-m 'test'\n\nmosquitto_sub -h dev.mqtt.en-trak.app -u admin -P wrLsgeaD1lmGIwiC9k -t\n'ems/bacnet/data' -v\n\nmosquitto_sub -h mqtt.en-trak.app -u admin -P wrLsgeaD1lmGIwiC9k -t '#' -v\n\nmosquitto_pub -h dev.mqtt.en-trak.app -u admin -P wrLsgeaD1lmGIwiC9k-t\n'ems/bacnet/data' -m '{\"id\": \"123456\", \"body\":\n{\"PM25\":12,\"TVOC\":13,\"TEMP\":14,\"RH\":15,\"CH2O\":16,\"CO2\":17}}'\n\nmosquitto_sub -h broker.emqx.io -t '/xxx' -v mosquitto_sub -h\ndev.mqtt.en-trak.app -u admin -p wrLsgeaD1lmGIwiC9k -t 'nano/data/#' -v\n\nmosquitto_pub -h broker.emqx.io -t '/xxx' -m '{\"id\": \"123\", \"body\":\n{\"PM25\":12,\"TVOC\":13,\"TEMP\":14,\"RH\":15,\"CH2O\":16,\"CO2\":17}}'\n\nmosquitto_sub -h 116.62.170.22 -t 'ALAOSIDJF92LDF92.2SN3nqD01LT55Eb8WI6B' -u\nziyunIot -P Pass1234 -v\n\nmosquitto_pub -h dev.mqtt.en-trak.app -u nano -P 3aCoXOx0ym6DsXWx8c -t\n'nano/data/testbytool' -m '{\"id\": \"123456\", \"body\":\n{\"PM25\":12,\"TVOC\":13,\"TEMP\":14,\"RH\":15,\"CH2O\":16,\"CO2\":17}}'\n\nmosquitto_sub -h 35.200.65.73 -t '/xxx' -v\n\nmosquitto_sub -h 35.200.65.73 -u nano -p 3aCoXOx0ym6DsXWx8c -t 'nano/data/#' -v\n\nmosquitto_pub -h broker.emqx.io -t 'xx' -m 'hello world'\n\nmosquitto_pub -h 127.0.0.1 -t 'xx' -m 'hello world'","routePath":"/notes/02-Software Development/middlewares/mqtt","lang":"","toc":[{"text":"server","id":"server","depth":2,"charIndex":3},{"text":"Public free mqtt brokers:","id":"public-free-mqtt-brokers","depth":2,"charIndex":72},{"text":"test with mosquitto","id":"test-with-mosquitto","depth":2,"charIndex":368},{"text":"tep dev","id":"tep-dev","depth":3,"charIndex":391}],"domain":"","frontmatter":{},"version":""},{"id":67,"title":"install location","content":"#\n\n源码安装默认目录 /usr/local/nginx 修改配置后重新加载生效 /usr/local/nginx/sbin/nginx -s reload\n测试nginx配置文件是否正确 nginx -t -c /usr/local/nginx/conf/nginx.conf 启动nginx nginx -c\n/usr/local/nginx/conf/nginx.conf 停止nginx nginx -s stop 优雅的停止nginx nginx -s quit\n\n","routePath":"/notes/02-Software Development/middlewares/nginx/install location","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":68,"title":"let's encript","content":"#\n\n\nget image#\n\ndocker pull certbot/certbot\n\ndocker run -it --net host --rm --name certbot\n\n-v \"./ssl/:/etc/letsencrypt/\"\n\n-v \"./letsencrypt/:/var/lib/letsencrypt\"\n\n-v \"./log/:/var/log/letsencrypt\"\n\n-v \"./www/:/var/www/html/\"\n\ncertbot/certbot certonly -n --no-eff-email --email test@domain.com --agree-tos\n--webroot -w /var/www/html -d confluence.app.domain.com\n\nserver { listen 80; server_name confluence.app.domain.com;\n\n\n\n}\n\n\n\nhttps://confluence.app.domain.com/.well-known/acme-challenge/abc.txt","routePath":"/notes/02-Software Development/middlewares/nginx/letsencrypt","lang":"","toc":[{"text":"get image","id":"get-image","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":69,"title":"查看用户的权限","content":"rabbitmq#\n\n\ninstall on machine#\n\n\nInstall Erlang from an Apt Repository on Bintray#\n\nAdd Repository Signing Key#\n\ncurl -fsSL\nhttps://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-\nsigning-key.asc | sudo apt-key add -\n\nEnable apt HTTPS Transport#\n\nsudo apt-get install apt-transport-https\n\nAdd a Source List File#\n\nsudo vim /etc/apt/sources.list.d/bintray.erlang.list deb\nhttps://dl.bintray.com/rabbitmq-erlang/debian focal erlang-23.x\n\nInstall Erlang Packages#\n\n\n\n\nUsing RabbitMQ Apt Repository on Bintray#\n\n\n\n\nstart a container instance#\n\ndocker run -d --hostname my-rabbit -p 15672:15672 -p 5672:5672 rabbitmq:3.8.0\n\n\nstart management plugins#\n\nrabbitmq-plugins enable rabbitmq_management rabbitmq-plugins enable\nrabbitmq_mqtt\n\n\naccess the interface#\n\nhttp://hostname:15672 guest guest\n\n\nremote access#\n\n\n\n\ncommon cmd#\n\n\n查看当前所有用户#\n\n$ sudo rabbitmqctl list_users\n\n\n查看默认guest用户的权限#\n\n$ sudo rabbitmqctl list_user_permissions guest\n\n\n由于RabbitMQ默认的账号用户名和密码都是guest。为了安全起见, 先删掉默认用户#\n\n$ sudo rabbitmqctl delete_user guest\n\n\n添加新用户#\n\n$ sudo rabbitmqctl add_user username password\n\n\n设置用户tag#\n\n$ sudo rabbitmqctl set_user_tags username administrator\n\n\n赋予用户默认vhost的全部操作权限#\n\n$ sudo rabbitmqctl set_permissions -p / username \".\" \".\" \".*\"\n\n\n查看用户的权限#\n\n$ sudo rabbitmqctl list_user_permissions username\n\nsudo rabbitmqctl purge_queue queue_name\n\nsudo rabbitmqctl status | grep rabbit\n\n首先定位到 rabbitMQ 安装目录的sbin 目录下。打开cmd窗口。 关闭应用的命令为： sudo rabbitmqctl stop_app &&\nsudo rabbitmqctl reset && sudo rabbitmqctl start_app 清除的命令为： rabbitmqctl reset\n重新启动命令为： rabbitmqctl start_app\n\nsudo rabbitmqadmin purge queue name=retrieve_system_data","routePath":"/notes/02-Software Development/middlewares/rabbitmq","lang":"","toc":[{"text":"install on machine","id":"install-on-machine","depth":2,"charIndex":11},{"text":"Install Erlang from an Apt Repository on Bintray","id":"install-erlang-from-an-apt-repository-on-bintray","depth":3,"charIndex":33},{"text":"Add Repository Signing Key","id":"add-repository-signing-key","depth":4,"charIndex":84},{"text":"Enable apt HTTPS Transport","id":"enable-apt-https-transport","depth":4,"charIndex":243},{"text":"Add a Source List File","id":"add-a-source-list-file","depth":4,"charIndex":314},{"text":"Install Erlang Packages","id":"install-erlang-packages","depth":4,"charIndex":461},{"text":"Using RabbitMQ Apt Repository on Bintray","id":"using-rabbitmq-apt-repository-on-bintray","depth":3,"charIndex":490},{"text":"start a container instance","id":"start-a-container-instance","depth":2,"charIndex":536},{"text":"start management plugins","id":"start-management-plugins","depth":2,"charIndex":645},{"text":"access the interface","id":"access-the-interface","depth":2,"charIndex":756},{"text":"remote access","id":"remote-access","depth":2,"charIndex":815},{"text":"common cmd","id":"common-cmd","depth":2,"charIndex":834}],"domain":"","frontmatter":{},"version":""},{"id":70,"title":"Tongweb","content":"#\n\n\nTongweb#\n\n\napp改造#\n\nSpring Boot外置WAR包东方通TongWeb部署问题 使用东方通部署多个web应用\n\n\n端口#\n\n配置文件conf/tongweb.xml 8088 默认应用访问端口 9060 默认控制台端口 5100 EJB远程端口 7200\nJMX端口，并随机启动两个端口 8005 默认停止端口\n\n\ndomain#\n\n * 删除域 停止域 ./stopserver.sh 删除域 ./domain.sh delete 域名称\n\n * 创建域 创建域 ./domain.sh create 域名称 启动域 ./startservernohoup.sh\n\n\nTonghttpserver#\n\n\n端口#\n\n配置文件bin/https.conf 443 默认负载对外访问端口","routePath":"/notes/02-Software Development/middlewares/tongweb","lang":"","toc":[{"text":"Tongweb","id":"tongweb-1","depth":2,"charIndex":-1},{"text":"app改造","id":"app改造","depth":3,"charIndex":14},{"text":"端口","id":"端口","depth":3,"charIndex":71},{"text":"domain","id":"domain","depth":3,"charIndex":172},{"text":"Tonghttpserver","id":"tonghttpserver","depth":2,"charIndex":299},{"text":"端口","id":"端口-1","depth":3,"charIndex":317}],"domain":"","frontmatter":{},"version":""},{"id":71,"title":"集群","content":"#\n\n\n引用#\n\n-[1]odoo集团多公司SAAS高可用架构部署,性能扩展安全增强 -[2]Odoo(OpenERP)集群/负载均衡方案","routePath":"/notes/02-Software Development/odoo/saas","lang":"","toc":[{"text":"引用","id":"引用","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":72,"title":"400-sqlalchemy","content":"#\n\nPip install alembic\n\nalembic init alembic\n\nalembic revision --autogenerate -m \"initial\"\n\nalembic upgrade head\n\n来自 https://qiita.com/giwa/items/87789d7ac22e633024d2","routePath":"/notes/02-Software Development/python/400-sqlalchemy","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":73,"title":"401 performance","content":"#\n\n\nGDB#\n\n\ninstall#\n\nUbuntu:\n\n\n\nCentos*:\n\n\n\n\ndebug#\n\n\n\nGetting a Python Stack Trace py-bt\n\nget a core file#\n\ngdb -p 7458\n\n> generate-core-file\n\nexamin a core file#\n\nhttps://wiki.python.org/moin/DebuggingWithGdb\n\n\nother#\n\npip install pyrasite # not latest version\n\npip install git+https://github.com/lmacken/pyrasite.git export\nPYRASITE_IPC_TIMEOUT=1800\n\npyrasite-shell\n\npip install cython pip install meliae pip install urwid pyrasite-memory-viewer\n9806\n\npip install psutil import psutil, os\npsutil.Process(os.getpid()).memory_info().rss\n\npip install guppy from guppy import hpy h = hpy() h.heap() h.iso(1,[],{})\n\nbyrcs = h.heap().byrcs; byrcs[0].byid\n\npip install graphviz pip install objgraph import objgraph objgraph.show_growth()\nobjgraph.show_most_common_types(limit=20)\n\n无法回收的对象 import gc gc.collect() # first run gc, find out uncollectable object and\nput them in gc.garbage # output number of object collected gc.garbage # print\nall uncollectable objects [] # empty\n\n1、在需要dump内存的地方，写上以下代码即可： from meliae import scanner\nscanner.dump_all_objects('/opt/log/dump.txt')\n这样，我们就可以把当前的内存Objects都导出到了dump.txt。 2、然后再进行分析： from meliae import loader om =\nloader.load('/opt/log/dump.txt') #加载dump文件 #om.compute_parents()\n#计算各Objects的引用关系 #om.collapse_instance_dicts() #去掉各对象Instance的_dict_属性 print\nom.summarize() #分析内存占用情况\n\n#得到所有的OracleDB对象 p = om.get_all('OracleDB') #查看第一个对象 p[0] #可以查看该对象的所有引用 p[0].c\n#查看谁引用了这个对象 p[0].p","routePath":"/notes/02-Software Development/python/401performance","lang":"","toc":[{"text":"GDB","id":"gdb","depth":2,"charIndex":3},{"text":"install","id":"install","depth":3,"charIndex":10},{"text":"debug","id":"debug","depth":3,"charIndex":44},{"text":"get a core file","id":"get-a-core-file","depth":4,"charIndex":90},{"text":"examin a core file","id":"examin-a-core-file","depth":4,"charIndex":143},{"text":"other","id":"other","depth":2,"charIndex":212}],"domain":"","frontmatter":{},"version":""},{"id":74,"title":"install","content":"#\n\n * install wget https://www.python.org/ftp/python/3.10.12/Python-3.10.12.tar.xz\n * tar -xf Python-3.10.12.tar.xz\n * ./configure --prefix=/opt/python3.10.12\n * make && make install\n\nsudo yum install libffi-devel to support ctypes\n\nsudo yum install openmpi-devel to support mpi for error * _configtest.c:2:10:\nfatal error: mpi.h: No such file or directory * `export\nC_INCLUDE_PATH=/usr/include/openmpi-x86_64/:$C_INCLUDE_PATH``\n\nfor * error: Cannot link MPI programs. Check your configuration!!! * env\nMPICC=/usr/lib64/openmpi/bin/mpicc python -m pip install --no-cache-dir mpi4py\n\nsudo yum -y install bzip2 bzip2-devel to support No module named ‘_bz2’\n\nsudo yum install xz-devel python-backports-lzma -y to support\nModuleNotFoundError: No module named '_lzma'","routePath":"/notes/02-Software Development/python/install","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":75,"title":"换源","content":"#\n\n~/.pip/pip.conf\n\n","routePath":"/notes/02-Software Development/python/pip","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":76,"title":"Error: pg_config executable not found.","content":"#\n\n * sudo apt-get install libpq-dev\n * yum install postgresql-devel*","routePath":"/notes/02-Software Development/python/pip_error","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":77,"title":"SQLX","content":"#\n\n\nsqlx-cli#\n\ncargo install sqlx-cli","routePath":"/notes/02-Software Development/rust/1 sqlx","lang":"","toc":[{"text":"sqlx-cli","id":"sqlx-cli","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":78,"title":"","content":"docker run -it -v /home/chiching/projects/spire/sensor:/app --name rust2 a47\n/bin/bash\n\napt -y update && apt -y install mingw-w64\n\nrustup target add x86_64-pc-windows-gnu\n\nrustup target add i686-pc-windows-gnu // rustup target list\n\ncargo build --release --target i686-pc-windows-gnu\n\nrustup toolchain install stable-gnu // maybe\n\ncat .cargo/config.toml // add this file in current working project.\n\n[target.x86_64-pc-windows-gnu] linker = \"/usr/bin/x86_64-w64-mingw32-gcc\"\n\n[target.i686-pc-windows-gnu] linker = \"/usr/bin/i686-w64-mingw32-gcc\" ar =\n\"/usr/i686-w64-mingw32/bin/ar\" rustflags = \"-C panic=abort\"","routePath":"/notes/02-Software Development/rust/build_windows","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":79,"title":"CMDS","content":"#\n\n\ncargo#\n\n * test cargo test -v -- --nocapture","routePath":"/notes/02-Software Development/rust/cmd","lang":"","toc":[{"text":"cargo","id":"cargo","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":80,"title":"config, 放到 `$HOME/.cargo/config` 文件中","content":"config, 放到 $HOME/.cargo/config 文件中#\n\n","routePath":"/notes/02-Software Development/rust/config","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":81,"title":"Errors","content":"#\n\n\ncargo#\n\nerror: warning: spurious network error (1 tries remaining): [6] Couldn't resolve\nhost name (Could not resolve host: crates)\n\nsolution: add this env before excution. CARGO_HTTP_MULTIPLEXING=false","routePath":"/notes/02-Software Development/rust/error","lang":"","toc":[{"text":"cargo","id":"cargo","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":82,"title":"expand","content":"#\n\ncargo install cargo-expand","routePath":"/notes/02-Software Development/rust/expand","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":83,"title":"Grammar","content":"#\n\n\ncontainer#","routePath":"/notes/02-Software Development/rust/grammar","lang":"","toc":[{"text":"container","id":"container","depth":2,"charIndex":-1}],"domain":"","frontmatter":{},"version":""},{"id":84,"title":"Chrome","content":"#\n\n\nWindows#\n\n 1. find your browser install location. mine is C:\\Program Files\n    (x86)\\Google\\Chrome\\Application\n 2. create a shortcut of your chrome.exe\n 3. right click your shortcut, select properties.\n 4. update the target like this, This is mine: \"C:\\Program Files\n    (x86)\\Google\\Chrome\\Application\\chrome.exe\" --args --disable-web-security\n    --user-data-dir=C:\\Users\\chiching\\Desktop\\temp\n 5. Now this shortcut browser don't have CORS issue.\n\n\nLinux#\n\n 1. go to /usr/share/applications, find chrome shortcut and copy to desktop.\n 2. open this new file, --args --disable-web-security\n    --user-data-dir=/home/chiching/Desktop/tmp to Exec=\n    (Exec=/usr/bin/google-chrome-stable)\n\nor run /usr/bin/google-chrome-stable --incognito --allow-file-access-from-files\n--args --disable-web-security --user-data-dir=/home/chiching/Desktop/tmp/","routePath":"/notes/02-Software Development/test/cors","lang":"","toc":[{"text":"Windows","id":"windows","depth":2,"charIndex":3},{"text":"Linux","id":"linux","depth":2,"charIndex":454}],"domain":"","frontmatter":{},"version":""},{"id":85,"title":"hping3","content":"#\n\nsudo hping3 -S --flood --rand-source 10.2.122.100\n\n\nUDP#\n\nhping3 --udp -s 6666 -p 53 -a 8.8.8.8 --flood 10.2.122.100\n\n./hping3 -S --flood --rand-source 10.2.127.2","routePath":"/notes/02-Software Development/test/hping3","lang":"","toc":[{"text":"UDP","id":"udp","depth":2,"charIndex":54}],"domain":"","frontmatter":{},"version":""},{"id":86,"title":"remove the tips","content":"#\n\n","routePath":"/notes/02-Software Development/tool/50-vscode/gitlen","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":87,"title":"install on ubuntu","content":"#\n\n 1. get file and unzip it\n\n 2. install dependency\n\nsudo apt-get install libgconf-2-4\n\n 3. create file desktopfile at ~./local/share/applications\n\n","routePath":"/notes/02-Software Development/tool/50-vscode/install on ubuntu","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":88,"title":"","content":"#my git config\n\nssh-keygen -t rsa\n\n\nconfig#\n\ngit config --global url.\"git@github.com:\".insteadOf https://github.com/\n\n\nlocal#\n\n[user] email = @outlook.com name = signkey =\nA476A1FB5858463C61564EBE19C04F851ED9B542 gpgsign = true [url \"git@github.com:\"]\ninsteadOf = https://github.com/ [pull] rebase = true [init] templatedir =\n/home/chiching/.git-templates [commit] gpgsign = true [core] editor = vim","routePath":"/notes/02-Software Development/tool/52-git/git.config","lang":"","toc":[{"text":"config","id":"config","depth":2,"charIndex":35},{"text":"local","id":"local","depth":2,"charIndex":118}],"domain":"","frontmatter":{},"version":""},{"id":89,"title":"","content":"removed a tracked file#\n\ngit rm --cached git rm -r --cached\n\n\nremove un tracked file#\n\n * To remove directories, run git clean -f -d or git clean -fd\n\n * To remove ignored files, run git clean -f -X or git clean -fX\n\n * To remove ignored and non-ignored files, run git clean -f -x or git clean -fx\n\n\ncheckout remote branch after `git clone --depth 1 git@xxxxx#\n\n * git remote set-branches origin 'remote_branch_name'\n * git fetch --depth 1 origin remote_branch_name\n * git checkout remote_branch_name\n\n\nset file to untracked#\n\n * git update-index --assume-unchanged index.ext\n\n * find . -name *.pyc | xargs git update-index --assume-unchanged\n\n\nfix http need user name and password frequently.#\n\ngit config --global credential.helper store\n\n","routePath":"/notes/02-Software Development/tool/52-git/git_cmds","lang":"","toc":[{"text":"removed a tracked file","id":"removed-a-tracked-file","depth":2,"charIndex":-1},{"text":"remove un tracked file","id":"remove-un-tracked-file","depth":2,"charIndex":61},{"text":"checkout remote branch after `git clone --depth 1 git@xxxxx","id":"checkout-remote-branch-after-git-clone---depth-1-gitxxxxx","depth":2,"charIndex":299},{"text":"set file to untracked","id":"set-file-to-untracked","depth":2,"charIndex":502},{"text":"fix http need user name and password frequently.","id":"fix-http-need-user-name-and-password-frequently","depth":2,"charIndex":644}],"domain":"","frontmatter":{},"version":""},{"id":90,"title":"GPG","content":"#\n\n\ngerate key#\n\nsudo apt-get install gnupg\n\n\n\n\nfind the gpg key#\n\n\n\n\nconfig for git#\n\n","routePath":"/notes/02-Software Development/tool/52-git/git_gpg","lang":"","toc":[{"text":"gerate key","id":"gerate-key","depth":2,"charIndex":3},{"text":"find the gpg key","id":"find-the-gpg-key","depth":2,"charIndex":47},{"text":"config for git","id":"config-for-git","depth":2,"charIndex":69}],"domain":"","frontmatter":{},"version":""},{"id":91,"title":"git lint","content":"#\n\n\ngit project template#\n\n\n\ninit a new git project git init\n\nedit the default template vi .git/hooks/commit-msg\n\nadd bellow\n\n\n\nconfig template\n\n\n\n\ninstall commitlint#\n\nnpm install -g @commitlint/cli @commitlint/config-conventional --registry\nhttp://registry.npm.taobao.org\n\n\nconfig commitlint#\n\n~/.commitlintrc.js\n\n\n\n\ntest#\n\necho \"abc\" | commitlint","routePath":"/notes/02-Software Development/tool/52-git/git_lint","lang":"","toc":[{"text":"git project template","id":"git-project-template","depth":2,"charIndex":3},{"text":"install commitlint","id":"install-commitlint","depth":2,"charIndex":147},{"text":"config commitlint","id":"config-commitlint","depth":2,"charIndex":275},{"text":"test","id":"test","depth":2,"charIndex":318}],"domain":"","frontmatter":{},"version":""},{"id":92,"title":"gitea/conf/app.ini","content":"Gitea installation#\n\n\nwindows ssh-copy-id#\n\ntype %USERPROFILE%.ssh\\id_ed25519.pub | ssh ubuntu@192.168.3.208 \"cat >>\n.ssh/authorized_keys\"\n\n\ninstall gitea#\n\n\nadd git user#\n\n\n\n\nfind git uid#\n\nsu - git && echo $UID && exit\n\n\nperpare ssh from host to docker#\n\n\n\n\nhack#\n\n\n\n\ndocker-compose.yml#\n\n\n\n\ngitea/conf/app.ini#\n\n","routePath":"/notes/02-Software Development/tool/52-git/gitea","lang":"","toc":[{"text":"windows ssh-copy-id","id":"windows-ssh-copy-id","depth":2,"charIndex":21},{"text":"install gitea","id":"install-gitea","depth":2,"charIndex":140},{"text":"add git user","id":"add-git-user","depth":3,"charIndex":157},{"text":"find git uid","id":"find-git-uid","depth":3,"charIndex":175},{"text":"perpare ssh from host to docker","id":"perpare-ssh-from-host-to-docker","depth":3,"charIndex":222},{"text":"hack","id":"hack","depth":3,"charIndex":259},{"text":"docker-compose.yml","id":"docker-composeyml","depth":3,"charIndex":269}],"domain":"","frontmatter":{},"version":""},{"id":93,"title":"github","content":"#\n\n\nproblem#\n\n\n\n\nsolution#\n\nvim ~/.ssh/config\n\n","routePath":"/notes/02-Software Development/tool/52-git/github","lang":"","toc":[{"text":"problem","id":"problem","depth":2,"charIndex":3},{"text":"solution","id":"solution","depth":2,"charIndex":16}],"domain":"","frontmatter":{},"version":""},{"id":94,"title":"gitlab runner","content":"#\n\n\ndocker compose file#\n\n\n\n\nregistor#\n\ndocker exec -it gitlab-runner gitlab-runner register","routePath":"/notes/02-Software Development/tool/52-git/gitlab-runner","lang":"","toc":[{"text":"docker compose file","id":"docker-compose-file","depth":2,"charIndex":3},{"text":"registor","id":"registor","depth":2,"charIndex":28}],"domain":"","frontmatter":{},"version":""},{"id":95,"title":"setting up git server","content":"#\n\nsudo adduser git cat /etc/shells see if git-shell is in the file. if not, run\nwhich git-shell to get the path, then append the apth to /etc/shells run sudo\nchsh git_dev -s $(which git-shell) to update user shell git hook, post update\n#!/bin/bash chmod 777 -fR /home/git/ik_ddos_web.git git\n--work-tree=/home/git/ik_ddos_web.git checkout -f exec git update-server-info","routePath":"/notes/02-Software Development/tool/52-git/setting up git server","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":96,"title":"三次删除字符（等价于删除三个字符）：three times delete character","content":"shortcut#\n\n动词 动词代表了我们打算对文本进行什么样的操作。例如： • d 表示删除（delete） • r 表示替换（replace） • c 表示修改（change）\n• y 表示复制（yank） • v 表示选取（visual select） 名词 名词代表了我们即将处理的文本。Vim\n中有一个专门的术语叫做文本对象（text object），下面是一些文本对象的示例： • w 表示一个单词（word） • s 表示一个句子（sentence）\n• p 表示一个段落（paragraph） • t 表示一个 HTML 标签（tag） • 引号或者各种括号所包含的文本称作一个文本块。 介词\n介词界定了待编辑文本的范围或者位置。例如： • i 表示“在...之内”（inside） • a 表示“环绕...”（around） • t\n表示“到...位置前”（to） • f 表示“到...位置上”（forward） 下面是几个有关范围的示意图，你们感受一下：\n\nPrepositions 组词为句 有了这些基本的语言元素，我们就可以着手构造一些简单的命令了。文本编辑命令的基本语法如下： 动词 介词 名词\n下面是一些例子（如果熟悉了上面的概念，你将会看到这些例子非常容易理解），请亲自在 Vim 中试验一番。\n\n\n删除一个段落: delete inside paragraph#\n\ndip\n\n\n选取一个句子: visual select inside sentence#\n\nvis\n\n\n修改一个单词: change inside word#\n\nciw\n\n\n修改一个单词: change around word#\n\ncaw\n\n\n删除文本直到字符“x”（不包括字符“x”）: delete to x#\n\ndtx\n\n\n删除文本直到字符“x”（包括字符“x”）: delete forward x#\n\ndfx 数词 数词指定了待编辑文本对象的数量，从这个角度而言，数词也可以看作是一种介词。引入数词之后，文本编辑命令的语法就升级成了下面这样： 动词 介词/数词\n名词 下面是几个例子：\n\n\n修改三个单词：change three words#\n\nc3w\n\n\n删除两个单词：delete two words#\n\nd2w 另外，数词也可以修饰动词，表示将操作执行 n 次。于是，我们又有了下面的语法： 数词 动词 名词 请看示例：\n\n\n两次删除单词（等价于删除两个单词）: twice delete word#\n\n2dw\n\n\n三次删除字符（等价于删除三个字符）：three times delete character#\n\n3x 怎么样，是不是很容易理解？\n\nFrom http://www.jianshu.com/p/a361ce8c97bc","routePath":"/notes/02-Software Development/tool/53-vim/shortcut","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":97,"title":"Usefull cmd","content":"#\n\n\nsave with sudo#\n\n:w !sudo tee %\n\n * :w = Write a file.\n * !sudo = Call shell sudo command.\n * tee = The output of the vi/vim write command is redirected using tee.\n * % = Triggers the use of the current filename.\n * Simply put, the ‘tee’ command is run as sudo and follows the vi/vim command\n   on the current filename given.","routePath":"/notes/02-Software Development/tool/53-vim/vim","lang":"","toc":[{"text":"save with sudo","id":"save-with-sudo","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":98,"title":"code review","content":"#\n\n\nwhy#\n\n代码有几种级别：1）可编译，2）可运行，3）可测试，4）可读，5）可维护，6）可重用。通过自动化测试的代码只能达到第3）级，而通过Code\nReview的代码少会在第4）级甚至更高","routePath":"/notes/02-Software Development/tool/code review","lang":"","toc":[{"text":"why","id":"why","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":99,"title":"","content":"PKI Public Key Infrastructure\n\nPKCS, Public-Key Cryptography Standards\n\nPKCS 目前共发布过 15 个标准。 常用的有：\n\n 1. PKCS#7 Cryptographic Message Syntax Standard\n 2. PKCS#10 Certification Request Standard\n 3. PKCS#12 Personal Information Exchange Syntax Standard\n\nX.509是常见通用的证书格式。所有的证书都符合为Public Key Infrastructure (PKI) 制定的 ITU-T X509 国际标准。\n\n 1.  PKCS#7常用的后缀是： .P7B .P7C .SPC\n\n 2.  PKCS#12常用的后缀有： .P12 .PFX\n\n 3.  X.509 DER编码(ASCII)的后缀是： .DER .CER .CRT\n\n 4.  X.509 PAM编码(Base64)的后缀是： .PEM .CER .CRT\n\n 5.  .cer/.crt是用于存放证书，它是2进制形式存放的，不含私钥。\n\n 6.  .pem跟crt/cer的区别是它以Ascii来表示。\n\n 7.  pfx/p12用于存放个人证书/私钥，他通常包含保护密码，2进制方式\n\n 8.  p10是证书请求\n\n 9.  p7r是CA对证书请求的回复，只用于导入\n\n 10. p7b以树状展示证书链(certificate chain)，同时也支持单个证书，不含私钥。\n\n\n编码格式#\n\n同样的X.509证书,可能有不同的编码格式,目前有以下两种编码格式.\n\nPEM - Privacy Enhanced Mail,打开看文本格式,以\"-----BEGIN...\"开头,\n\"-----END...\"结尾,内容是BASE64编码.\n\n查看PEM格式证书的信息:openssl x509 -in certificate.pem -text -noout\n\nApache和*NIX服务器偏向于使用这种编码格式.\n\nDER - Distinguished Encoding Rules,打开看是二进制格式,不可读.\n\n查看DER格式证书的信息:openssl x509 -in certificate.der -inform der -text -noout\n\nJava和Windows服务器偏向于使用这种编码格式.","routePath":"/notes/02-Software Development/tool/key","lang":"","toc":[{"text":"编码格式","id":"编码格式","depth":2,"charIndex":696}],"domain":"","frontmatter":{},"version":""},{"id":100,"title":"","content":"","routePath":"/notes/02-Software Development/tool/postfix","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":101,"title":"","content":"docker run -it -v /home/chiching/projects/cqq/pandoc_resume:/app --name res a47\n/bin/bash\n\napt update\n\napt install pandoc context make\n\napt-get install chinese*\n\nmkdir /usr/share/fonts/stsong && cp STSong.ttf /usr/share/fonts/stsong/\n\nfc-list :lang=zh\n\nmtxrun --script font --reload mtxrun --script font --list --all | grep song\n\nmake all","routePath":"/notes/02-Software Development/tool/resume","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":102,"title":"Terminal","content":"#\n\n\nalacritty#\n\n\n\n\nZellij#","routePath":"/notes/02-Software Development/tool/terminal","lang":"","toc":[{"text":"alacritty","id":"alacritty","depth":2,"charIndex":3},{"text":"Zellij","id":"zellij","depth":2,"charIndex":-1}],"domain":"","frontmatter":{},"version":""},{"id":103,"title":"ventoy.json file","content":"ventory#\n\n\nventoy.json file#\n\n{ \"control\": [ { \"VTOY_MENU_LANGUAGE\": \"zh_CN\" }, { \"VTOY_DEFAULT_MENU_MODE\":\n\"0\" }, { \"VTOY_TREE_VIEW_MENU_STYLE\": \"0\" }, { \"VTOY_FILT_DOT_UNDERSCORE_FILE\":\n\"1\" }, { \"VTOY_SORT_CASE_SENSITIVE\": \"0\" }, { \"VTOY_MAX_SEARCH_LEVEL\": \"max\" },\n{ \"VTOY_DEFAULT_SEARCH_ROOT\": \"/iso\" },\n\n{ \"VTOY_MENU_TIMEOUT\": \"10\" }, { \"VTOY_DEFAULT_IMAGE\":\n\"/iso/debian-12.2.0-amd64-netinst.iso\" }, { \"VTOY_FILE_FLT_EFI\": \"1\" }, {\n\"VTOY_DEFAULT_KBD_LAYOUT\": \"QWERTY_USA\" }, { \"VTOY_WIN11_BYPASS_CHECK\": \"1\" }, {\n\"VTOY_WIN11_BYPASS_NRO\": \"1\" }, { \"VTOY_LINUX_REMOUNT\": \"0\" }, {\n\"VTOY_SECONDARY_BOOT_MENU\": \"1\" }, { \"VTOY_SECONDARY_TIMEOUT\": \"20\" } ] }\n\n\n\n\niso file#\n\n\n\n","routePath":"/notes/02-Software Development/tool/ventory/file","lang":"","toc":[{"text":"iso file","id":"iso-file","depth":2,"charIndex":661}],"domain":"","frontmatter":{},"version":""},{"id":104,"title":"Wireshark","content":"#\n\n\nubuntu#\n\nFix, not able to show NICs:\n\nsudo dpkg-reconfigure wireshark-common press the right arrow and enter for yes\n\nsudo chmod +x /usr/bin/dumpcap","routePath":"/notes/02-Software Development/tool/wareshark","lang":"","toc":[{"text":"ubuntu","id":"ubuntu","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":105,"title":"linux 安装配置zerotier. The service name is ` zerotier-one.service`","content":"linux 安装配置zerotier. The service name is zerotier-one.service#\n\n\n在线安装zerotier#\n\ncurl -s https://install.zerotier.com/ | sudo bash\n\n\n加入网络#\n\nsudo zerotier-cli join xxxxx\n\n\n查看网络#\n\nsudo zerotier-cli info","routePath":"/notes/02-Software Development/tool/zerotier","lang":"","toc":[{"text":"在线安装zerotier","id":"在线安装zerotier","depth":2,"charIndex":63},{"text":"加入网络","id":"加入网络","depth":2,"charIndex":130},{"text":"查看网络","id":"查看网络","depth":2,"charIndex":168}],"domain":"","frontmatter":{},"version":""},{"id":106,"title":"npm","content":"#\n\n\ndisable map file#\n\nset env first, GENERATE_SOURCEMAP=false then npm run build\n\n\nchange the source#\n\nnpm config set registry https://registry.npm.taobao.org\n\nnpm config list\n\nnpm config set registry https://registry.npm.taobao.org --global\n\nnpm config set disturl https://npm.taobao.org/dist --global\n\n\nError#\n\n\nBuilding for production...Error: error:0308010C:digital envelope\nroutines::unsupported#\n\n\nfix#\n\n * windows： set NODE_OPTIONS=--openssl-legacy-provider\n\n * linux & mac: export NODE_OPTIONS=--openssl-legacy-provider","routePath":"/notes/02-Software Development/web/npm","lang":"","toc":[{"text":"disable map file","id":"disable-map-file","depth":2,"charIndex":3},{"text":"change the source","id":"change-the-source","depth":2,"charIndex":83},{"text":"Error","id":"error","depth":2,"charIndex":305},{"text":"Building for production...Error: error:0308010C:digital envelope routines::unsupported","id":"building-for-productionerror-error0308010cdigital-envelope-routinesunsupported","depth":3,"charIndex":-1},{"text":"fix","id":"fix","depth":3,"charIndex":404}],"domain":"","frontmatter":{},"version":""},{"id":107,"title":"uni app","content":"#\n\n\nsetup env#\n\n\n\n\n运行、发布uni-app#\n\n\n\n","routePath":"/notes/02-Software Development/web/uni-app","lang":"","toc":[{"text":"setup env","id":"setup-env","depth":2,"charIndex":3},{"text":"运行、发布uni-app","id":"运行发布uni-app","depth":2,"charIndex":18}],"domain":"","frontmatter":{},"version":""},{"id":108,"title":"dameng","content":"#\n\n * download docker image from 1\n * load image docker load -i dm8_20220822_rev166351_x86_rh6_64_ctm.tar\n * start container docker run -d -p 5236:5236 --restart=always --name dm8_01\n   --privileged=true -e PAGE_SIZE=16 -e EXTENT_SIZE=16 -e CASE_SENSITIVE=n -e\n   UNICODE_FLAG=1 -e LENGTH_IN_CHAR=1 -e LD_LIBRARY_PATH=/opt/dmdbms/bin -e\n   INSTANCE_NAME=dm8_01 -v /opt/dameng:/opt/dmdbms/data\n   dm8_single:dm8_20230808_rev197096_x86_rh6_64\n\n\n\n\nRef#\n\n * [1] 达梦\n * [2] 达梦\n * [3] 达梦\n\n\ninit#\n\n./dminit path=/dm8/data PAGE_SIZE=16 EXTENT_SIZE=16 CASE_SENSITIVE=n CHARSET=1\nLENGTH_IN_CHAR=1\n\n\nconnect#\n\n\n\n\ncreate tablespace#\n\nselect tablespace_name from dba_tablespaces;\n\n\n\n\ncreate dbuser#\n\nselect username from dba_users;\n\n\n\n\n\n\ndrop user#\n\n\n\n\nexport && import#\n\n","routePath":"/notes/03-Databases & Data Storage/dm-install","lang":"","toc":[{"text":"Ref","id":"ref","depth":2,"charIndex":444},{"text":"init","id":"init","depth":2,"charIndex":482},{"text":"connect","id":"connect","depth":2,"charIndex":587},{"text":"create tablespace","id":"create-tablespace","depth":2,"charIndex":600},{"text":"create dbuser","id":"create-dbuser","depth":2,"charIndex":669},{"text":"drop user","id":"drop-user","depth":2,"charIndex":723},{"text":"export && import","id":"export--import","depth":2,"charIndex":738}],"domain":"","frontmatter":{},"version":""},{"id":109,"title":"达梦数据库迁移","content":"#\n\n * 安装数据库，一定要大小写不敏感。CASE_SENSITIVE=n, 否则orm中colum的大小写要完全一样，得一个一个改。\n * 达梦是单数据库，多实列。每个库要建对应的表空间，用户。 用工具新建用户会自动创建模式。模式对应mysql中的一个数据库。\n   工具连接，必须用对应的用户查询，否则需要在表名前面加模式名前缀。\n * group_contact -> wm_concat\n * union 操作，必须保证每列数据类型完全一样。\n * mysql的 STR_TO_DATE('2020-09-17 16:27:30','%Y-%m-%d %H:%i:%s') ->\n   TO_DATE('2020-09-17 16:27:30','YYYY-MM-DD HH24:MI:SS')\n * mysql的别名可以加单引号，如 select abc as 'alias' from xxx， 达梦不能加。\n * gorm数据查询，需要select指定具体列，如果是select * 映射失败。\n * 计算一天前。select DATE_SUB( CURRENT_TIMESTAMP(), INTERVAL '1' DAY), mysql\n   可不加单引号，达梦必须加。\n * DATE_FORMAT(CURRENT_TIMESTAMP,'%Y-%m-%d') 达梦不能是双引号。\n * 窗口函数，partition后必须加order by\n * mysql的特定函数，比如help_topic，达梦不支持。\n   有自己的解法https://blog.csdn.net/mcband/article/details/123089081\n * IF(contidtion, true, false), 达梦IF() 的返回值为数字值或字符串值，不能为NULL，也不能为变量。 可以这样判断\n   IFNULL(NULLIF(area, 0), 1)。 NULLIF(n1,n2) 如果n1=n2返回NULL，否则返回n1。 IFNULL(n1,n2)\n   当n1为非空时，返回n1；若n1为空，则返回n2\n   https://eco.dameng.com/community/question/2922dbe65be58ed994a6cf9f4989842a，\n   https://eco.dameng.com/community/question/3d9dbaf4e5a8fbd1d8565d754579602b\n * select abc as key from table， 达梦不支持，可以去掉反引号\n * 达梦没有FIND_IN_SET， 可以通过行转列，然后用in来实现。\n * 类型转CONVERT， 字符串在前，类型在后。 达梦相反。\n * 达梦没有SIGNED，unsigned数据类型。\n * 达梦不能用别名直接group by, 需要在加一个外层查询。\n * Error -2685: 试图在blob或者clob列上排序或比较。\n   修改数据库参数ENABLE_BLOB_CMP_FLAG。sp_set_para_value(1,'ENABLE_BLOB_CMP_FLAG',1);\n   ，然后重启服务。\n * 网上说的通过这种方式计算秒级别的加减法是不行的，now()- 1/(246060)*90， 后面的除法为0，可能还需要其他设置。 用这个\n   DATEADD(S, -90, now())，或者sysdate+numtodsinterval(-90,'second')\n * 容器内中文乱码，可给容器添加环境变量 LANG=en_US.UTF-8\n * disql不能上下翻，可去https://rpmfind.net/linux/rpm2html/search.php?query=rlwrap下载。（EP\n   EL 8 for\n   x86_64），然后解压，上传rlwrap到容器内。可能还需要拷贝以下文件到/usr/lib下，/usr/lib64/libtinfo.so.6.2，/u\n   sr/lib64/libtinfo.so.6， /usr/lib64/libreadline.so.7.0，\n   /usr/lib64/libreadline.so.7， 可先使用命令，看提示错误确认文件版本。 kylin\n   v10下载地址https://archive.kylinos.cn/yum/v10/kylin-openstack-q/x86_64/x86_64/\n\n\n\n * 查询版本 SELECT * FROM v$version;\n * 查询license过期 select * from v$license;\n * DATEDIFF 的格式应该是 表达式 DATEDIFF(timeinterval,date1,date2)","routePath":"/notes/03-Databases & Data Storage/dm-migrate","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":110,"title":"query","content":"#\n\nKibana: http://192.168.1.35:5601/\n\n\n\n\n\n","routePath":"/notes/03-Databases & Data Storage/es-query","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":111,"title":"ETCD commands","content":"#\n\n * etcdctl member list --cacert=/etc/kubernetes/pki/etcd/ca.pem\n   --cert=/etc/kubernetes/pki/etcd/etcd-server.pem\n   --key=/etc/kubernetes/pki/etcd/etcd-server-key.pem\n * xxxx","routePath":"/notes/03-Databases & Data Storage/etcd","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":112,"title":"LDAP","content":"#\n\nldap location is /opt/bitnami/openldap/sbin\n\nldapsearch -Q -LLL -H ldap://10.230.168.174:1389 -b cn=config dn\n\nldapsearch -Q -LLL -x -D \"cn=admin,dc=,dc=com\" -W -H ldap://127.0.0.1:1389 -b\ncn=config dn\n\nldapsearch -Q -x -D \"cn=admin,dc=,dc=com\" -W -H ldap://127.0.0.1:1389 -b\ncn=config \"(objectClass=olcPPolicyConfig)\"\n\n\ngenerate pasword#\n\nslappasswd -h {SSHA}\n\n\n\n\nmodify user password#\n\n\n\nldapmodify -x -D \"cn=admin,dc=,dc=com\" -W -H ldap://127.0.0.1:1389 -f\n/bitnami/openldap/test3.ldif","routePath":"/notes/03-Databases & Data Storage/ldap","lang":"","toc":[{"text":"generate pasword","id":"generate-pasword","depth":2,"charIndex":323},{"text":"modify user password","id":"modify-user-password","depth":2,"charIndex":367}],"domain":"","frontmatter":{},"version":""},{"id":113,"title":"install mongodb on ubuntu","content":"#\n\n\nImport the public key used by the package management system#\n\nwget -qO - https://www.mongodb.org/static/pgp/server-4.4.asc | sudo apt-key add\n-\n\n\nCreate a list file for MongoDB.#\n\necho \"deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu\nfocal/mongodb-org/4.4 multiverse\" | sudo tee\n/etc/apt/sources.list.d/mongodb-org-4.4.list\n\n\nReload local package database#\n\nsudo apt-get update\n\n\nInstall the MongoDB packages#\n\nsudo apt-get install -y mongodb-org\n\ninstall-mongodb-on-ubuntu","routePath":"/notes/03-Databases & Data Storage/mongo-install","lang":"","toc":[{"text":"Import the public key used by the package management system","id":"import-the-public-key-used-by-the-package-management-system","depth":2,"charIndex":3},{"text":"Create a list file for MongoDB.","id":"create-a-list-file-for-mongodb","depth":2,"charIndex":149},{"text":"Reload local package database","id":"reload-local-package-database","depth":2,"charIndex":342},{"text":"Install the MongoDB packages","id":"install-the-mongodb-packages","depth":2,"charIndex":396}],"domain":"","frontmatter":{},"version":""},{"id":114,"title":"auto","content":"#\n\n导出一条数据 mysqldump -uroot -p ik tbl_guardset --where \"id=22\" --no-create-info\n--skip-add-locks\n\n重置auto id ALTER TABLE tbl_guardset AUTO_INCREMENT = 37;\n\n查询当前的auto id， 即下一个id SELECT AUTO_INCREMENT FROM information_schema.TABLES WHERE\nTABLE_SCHEMA = \"ik\" AND TABLE_NAME = tbl_guardset;","routePath":"/notes/03-Databases & Data Storage/mysql/auto","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":115,"title":"backup script","content":"#\n\n\n\nmysql -u用户名 -p 数据库名 < 数据库名.sql","routePath":"/notes/03-Databases & Data Storage/mysql/backup","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":116,"title":"","content":"version: '3' services: mysql: restart: always privileged: true image: mysql:8.0\ncontainer_name: mysql volumes: - ./data:/var/lib/mysql -\n./conf:/etc/mysql/conf.d - ./logs:/logs command: --character-set-server=utf8mb4\n--collation-server=utf8mb4_general_ci --explicit_defaults_for_timestamp=true\nenvironment: MYSQL_ROOT_PASSWORD: \"#2023\" MYSQL_USER: \"_admin\" MYSQL_PASSWORD:\n\"#2023\" MYSQL_INITDB_SKIP_TZINFO: \"Asia/Shanghai\" ports: - 3306:3306","routePath":"/notes/03-Databases & Data Storage/mysql/docker-compose","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":117,"title":"lock","content":"#\n\n将服务器的数据库加锁，避免同步时数据发生改变 flush tables with read lock;\n\nunlock tables;","routePath":"/notes/03-Databases & Data Storage/mysql/lock","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":118,"title":"/etc/mysql/conf.d/my.cnf","content":"my.cnf#\n\n可以执行 mysql --help|grep 'my.cnf' 查看程序读取的配置文件顺序\n\n\n/etc/mysql/conf.d/my.cnf#\n\n","routePath":"/notes/03-Databases & Data Storage/mysql/my.cnf","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":119,"title":"permission related operations","content":"#\n\n\nchange password#\n\n\n\n\nuninstall plugin validate_password#\n\n\n\n\nclear root password in safe mode#\n\n\n\nref from\n\n\nallow remove connection#\n\n 1. Comment the bind address from the file /etc/mysql/my.cnf #bind-address =\n    127.0.0.1\n\n 2. GRANT ALL PRIVILEGES ON . TO 'root'@'%' IDENTIFIED BY 'Ikglobal.com2018'\n    WITH GRANT OPTION;\n\nmysqldump -udbuser -pdbpass devdb > mydb.sql\n\nCREATE USER 'newuser'@'localhost' IDENTIFIED BY 'password';","routePath":"/notes/03-Databases & Data Storage/mysql/permissions","lang":"","toc":[{"text":"change password","id":"change-password","depth":2,"charIndex":3},{"text":"uninstall plugin validate_password","id":"uninstall-plugin-validate_password","depth":2,"charIndex":24},{"text":"clear root password in safe mode","id":"clear-root-password-in-safe-mode","depth":2,"charIndex":64},{"text":"allow remove connection","id":"allow-remove-connection","depth":2,"charIndex":112}],"domain":"","frontmatter":{},"version":""},{"id":120,"title":"set log","content":"#\n\nSET global log_output = 'FILE'; SET global general_log_file='d:\\mysql.log'; SET\nglobal general_log = 1; mysql> show variables like 'slow_query%';\n+---------------------+-----------------------------------+ | Variable_name |\nValue | +---------------------+-----------------------------------+ |\nslow_query_log | OFF | | slow_query_log_file | /var/lib/mysql/localhost-slow.log\n| +---------------------+-----------------------------------+ SET global\nslow_query_log = 'ON'; SET global\ngeneral_log_file='/var/lib/mysql/localhost-slow.log';","routePath":"/notes/03-Databases & Data Storage/mysql/set log","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":121,"title":"reset passwor on windows.","content":"#\n\n * go to bin folder, mysqld --defaults-file=\"../my.ini\" --skip-grant-tables\n * connect mysql without password, then update mysql.user set\n   authentication_string=\"\" where user=\"root\";\n * restart server , reconnect without password","routePath":"/notes/03-Databases & Data Storage/mysql/windows_restpassword","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":122,"title":"MySQL 三级等保整改","content":"#\n\n\n\n\nMySQL基本操作#\n\n\n\n\n定期更密码#\n\n\n\n\n登录失败处理#\n\n\n\n\n超时处理#\n\nMysql 连接超时退出主要看三个参数：\n\nwait_timeout ：这个参数的单位是秒，默认是28880\n\ninteractive_timeout ：交互式登录超时\n\nconnect_timeout =10\n\nmysql在使用交互式操作的时候，就是你打开mysql黑窗口进行的操作时使用的是wait_timeout，默认已经配置好了。\n在使用非交互式操作时候，就是interactive_timeout，例如你程序的jdbc连接数据库。\n\n\n访问控制#\n\n 1. 首先创建三个角色：操作员、审计员、管理员。 操作员：负责业务层面开发，对应我们开发人员。 审计员：只需对日志具有审查权限\n    管理员：拥有所有的权限，制定安全策略。\n    \n    create role 'system_db','dev_db','log_db';\n\n 2. 创建用户，给管理员角色分配所有权限。禁止将file，process ,super 权限分给管理员之外的人员。\n    \n    \n\n 3. 查看该角色的权限。\n    \n    \n    \n    > 注：USAGE 是连接（登陆）权限，建立一个用户，就会自动授予其usage权限（默认授予）。该权限不能被回收\n\n 4. 创建用户，给开发角色分配权限。\n    \n    对于开发人员： 1）赋予用户对数据库的增删改操作；\n    2）赋予用户创建，修改，删除表结构；操作mysql外键权限、操作临时表权限、操作索引权限、操作mysql视图、操作mysql存储过程权限；\n    3）赋予用户全局权限：reload，process。查看所有进程\n    \n    \n\n 5. 创建审计员，分配角色\n    \n    分配审计人员对auditlog库的查询和插入删除权限。\n    \n    \n\n 6. 激活角色\n    \n    需要注意的是，角色创建后，并不会直接激活，激活的方式有几种，但推荐的一种就是去配置文件配置参数。\n    \n    当用户登录后，可以查看该角色是否存在。查看参数是off状态。更改位on，该角色在登录后就会被自动激活。\n\n\n\n\n安全审计#\n\n\n\n\n\n\nmy.cnf#\n\n\n\n索引","routePath":"/notes/03-Databases & Data Storage/mysql/等保整改","lang":"","toc":[{"text":"MySQL基本操作","id":"mysql基本操作","depth":2,"charIndex":5},{"text":"定期更密码","id":"定期更密码","depth":2,"charIndex":20},{"text":"登录失败处理","id":"登录失败处理","depth":2,"charIndex":31},{"text":"超时处理","id":"超时处理","depth":2,"charIndex":43},{"text":"访问控制","id":"访问控制","depth":2,"charIndex":273},{"text":"安全审计","id":"安全审计","depth":2,"charIndex":955},{"text":"my.cnf","id":"mycnf","depth":2,"charIndex":967}],"domain":"","frontmatter":{},"version":""},{"id":123,"title":"install opengauss","content":"#\n\n\ninstall by docker#\n\n\n\n\ndocker compose#\n\n\n\n\nconnect#\n\n","routePath":"/notes/03-Databases & Data Storage/opengauss/install","lang":"","toc":[{"text":"install by docker","id":"install-by-docker","depth":2,"charIndex":3},{"text":"docker compose","id":"docker-compose","depth":2,"charIndex":26},{"text":"connect","id":"connect","depth":2,"charIndex":46}],"domain":"","frontmatter":{},"version":""},{"id":124,"title":"migration","content":"#\n\n\ntools chameleon#\n\n\nconfig#\n\n\n\n\ncommand#\n\nchameleon create_replica_schema --config default chameleon add_source --config\ndefault --source mysql chameleon init_replica --config default --source mysql\n\n\nref#\n\n 1. chameleon使用指南","routePath":"/notes/03-Databases & Data Storage/opengauss/migrate_chameleon","lang":"","toc":[{"text":"tools chameleon","id":"tools-chameleon","depth":2,"charIndex":3},{"text":"config","id":"config","depth":2,"charIndex":22},{"text":"command","id":"command","depth":2,"charIndex":34},{"text":"ref","id":"ref","depth":2,"charIndex":203}],"domain":"","frontmatter":{},"version":""},{"id":125,"title":"pgloader","content":"#\n\n\ninstall#\n\ndocker run -it --name pgloader dimitri/pgloader:latest bash\n\n\npgload.load#\n\n\n\n\nrun command#\n\npgloader pgload.load","routePath":"/notes/03-Databases & Data Storage/opengauss/migrate_pugloader","lang":"","toc":[{"text":"install","id":"install","depth":2,"charIndex":3},{"text":"pgload.load","id":"pgloadload","depth":2,"charIndex":75},{"text":"run command","id":"run-command","depth":2,"charIndex":92}],"domain":"","frontmatter":{},"version":""},{"id":126,"title":"","content":"","routePath":"/notes/03-Databases & Data Storage/openldap/bitnami","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":127,"title":"","content":"","routePath":"/notes/03-Databases & Data Storage/openldap/lam","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":128,"title":"","content":"","routePath":"/notes/03-Databases & Data Storage/openldap/osixia","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":129,"title":"","content":"","routePath":"/notes/03-Databases & Data Storage/openldap/phpldapadmin","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":130,"title":"ssp.conf.php","content":"#\n\n","routePath":"/notes/03-Databases & Data Storage/openldap/ssp","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":131,"title":"setup abc....","content":"#\n\n\ncreate role#\n\ncreate user mangotree createdb password 'mangotree'; Need to create role first,\notherwise, the restore will fail. The password can be changed as requirement.\n\n\ncreate database#\n\npsql --host=127.0.0.1 --username=mangopie --dbname=postgres -c \"create database\nmangopie\"\n\npsql -h\nls-f63a30f1b6958e8d004c5262cc2430ef48f1108d.ckbptluc0byy.ap-southeast-1.rds.amaz\nonaws.com -Umangotree --dbname=postgres -c \"create database mangotree\"\n\n\\copy (select * from companies_company) to '~/comany.csv' csv;","routePath":"/notes/03-Databases & Data Storage/postgres/db","lang":"","toc":[{"text":"create role","id":"create-role","depth":3,"charIndex":3},{"text":"create database","id":"create-database","depth":3,"charIndex":177}],"domain":"","frontmatter":{},"version":""},{"id":132,"title":"","content":"docker pull postgres\n\ndocker run -d\n\n--name pg\n\n-e POSTGRES_PASSWORD=password\n\n-v /home/chiching/pgdata:/var/lib/postgresql/data\n\n-p 5432:5432\n\npostgres\n\n\ndocker-compose#\n\nversion: '3' networks: ems_bridge: external: true services: postgresql: image:\npostgres:13.3 restart: always environment: -\nPGDATA=/var/lib/postgresql/data/pgdata - POSTGRES_PASSWORD=en-trak.com volumes:\n- ./data:/var/lib/postgresql/data networks: - ems_bridge ports: - \"5432:5432\"","routePath":"/notes/03-Databases & Data Storage/postgres/docker","lang":"","toc":[{"text":"docker-compose","id":"docker-compose","depth":2,"charIndex":154}],"domain":"","frontmatter":{},"version":""},{"id":133,"title":"install postgres","content":"#\n\n初始化数据库 e:\\apps\\pgsql\\bin\\initdb.exe -D e:\\apps\\pgsql\\data -E UTF8\n--locale=Chinese\n\n启动 e:\\apps\\pgsql\\bin\\pg_ctl.exe start -w -D e:\\apps\\pgsql\\data\n\n关闭 e:\\apps\\pgsql\\bin\\pg_ctl.exe stop -W -D e:\\apps\\pgsql\\data\n\n创建用户 e:\\apps\\pgsql\\bin\\createuser.exe -s -r postgres\n\n修改用户密码 e:\\apps\\pgsql\\bin\\psql.exe postgres postgres=# alter user postgres with\npassword 'xxx'; postgres-# \\q\n\n\ninstall pg on ubuntu#\n\n\nCreate the file repository configuration:#\n\nsudo sh -c 'echo \"deb http://apt.postgresql.org/pub/repos/apt $(lsb_release\n-cs)-pgdg main\" > /etc/apt/sources.list.d/pgdg.list'\n\n\nImport the repository signing key:#\n\nwget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo\napt-key add -\n\n\nUpdate the package lists:#\n\nsudo apt-get update\n\n\nInstall the latest version of PostgreSQL.#\n\n\nIf you want a specific version, use 'postgresql-12' or similar instead of\n'postgresql':#\n\nsudo apt-get -y install postgresql\n\n\nconnect pg#\n\nsudo -i -u postgres psql\n\nor sudo -u postgres psql","routePath":"/notes/03-Databases & Data Storage/postgres/install","lang":"","toc":[{"text":"install pg on ubuntu","id":"install-pg-on-ubuntu","depth":2,"charIndex":378},{"text":"Create the file repository configuration:","id":"create-the-file-repository-configuration","depth":3,"charIndex":402},{"text":"Import the repository signing key:","id":"import-the-repository-signing-key","depth":3,"charIndex":577},{"text":"Update the package lists:","id":"update-the-package-lists","depth":3,"charIndex":706},{"text":"Install the latest version of PostgreSQL.","id":"install-the-latest-version-of-postgresql","depth":3,"charIndex":756},{"text":"If you want a specific version, use 'postgresql-12' or similar instead of 'postgresql':","id":"if-you-want-a-specific-version-use-postgresql-12-or-similar-instead-of-postgresql","depth":3,"charIndex":-1},{"text":"connect pg","id":"connect-pg","depth":2,"charIndex":928}],"domain":"","frontmatter":{},"version":""},{"id":134,"title":"create ueser and grant permission","content":"#\n\ncreate user odoo with encrypted password 'odoo.pwd@2022'; grant all privileges\non database mydb to odoo;\n\nGRANT ALL ON SCHEMA public TO odoo;","routePath":"/notes/03-Databases & Data Storage/postgres/permission","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":135,"title":"","content":"#psql\n\n\nexport data#\n\npsql -h 127.0.0.1 -U mangopie -d mangopie -t -A -F\",\" -c \"select * from\nenergy_meter where company_id = 140\" > meters.csv\n\npsql -h 127.0.0.1 -U mangopie -d mangopie -t -A -F\",\" -c \"select * from\nenergy_system where company_id = 140\" > systems.csv\n\nCOPY (select * from energy_system where id in (246, 247, 3395) union select *\nfrom energy_system where parent_system_id in (select id from energy_system where\nparent_system_id in (246, 247, 3395)) union select * from energy_system where\nparent_system_id in ( select id from energy_system where parent_system_id in\n(select id from energy_system where parent_system_id in (247, 3395))) union\nselect * from energy_system where parent_system_id in ( select id from\nenergy_system where parent_system_id in (select id from energy_system where\nparent_system_id in (select id from energy_system where parent_system_id in\n(247, 3395)))) order by id) TO 'systems.csv' CSV HEADER\n\nCASE department_id WHEN null THEN '00000000-0000-0000-0000-000000000000' ELSE\ndepartment_id END\n\npsql -d user -t -A -F\",\" -c \"select id, email, first_name, last_name, CASE\ndepartment_id WHEN null THEN '00000000-0000-0000-0000-000000000000' ELSE\ndepartment_id END,current_timestamp, current_timestamp from profiles;\" >\nprofile.csv\n\ngcloud sql connect dev-tep-postgresql -d user -u user -t -A -F\",\" -c \"select id,\nemail, first_name, last_name, CASE department_id WHEN null THEN\n'00000000-0000-0000-0000-000000000000' ELSE department_id END,current_timestamp,\ncurrent_timestamp from profiles;\" > profiles.csv\n\ngcloud sql export csv dev-tep-postgresql\ngs://en-trak_tep_storage/sql_exports/export_profiles.csv\n\n--database=user\n\n--offload\n\n--query=\"select id, email, first_name, last_name, CASE WHEN department_id IS\nnull THEN '00000000-0000-0000-0000-000000000000' ELSE department_id\nEND,current_timestamp, current_timestamp from profiles;\"\n\n\nimport#\n\ngcloud sql import csv dev-tep-postgresql\ngs://en-trak_tep_storage/sql_exports/export_profiles.csv --database=node\n--table=profiles\n\nCOPY profiles(id, email, first_name, last_name, department_id) FROM\n'C:/Users/chiching/Desktop/profile.csv' WITH (FORMAT csv);\n\nCOPY energy_meter FROM '~/meters.csv' WITH (FORMAT csv);\n\nCOPY\nenergy_system(id,name,name_zh_tw,source_key,category_id,company_id,meter_id,pare\nnt_system_id,city_id,location_id,component_of_id,weight,datasource_type,active,p\nower_plan_id,is_billing_level,equipment_index,equipment_type,equipment_unit,comp\nosition_expression,sensor_id,is_solar) FROM '/systems.csv' WITH (FORMAT csv);\n\nCOPY energy_system FROM '/systems.csv' WITH (FORMAT csv, encoding 'gbk18030');\n\npsql -h 127.0.0.1 -U mangopie -d mangopie -t -A -F\",\" -c \"select * from\nenergy_system where id in (246, 247, 3395) union select * from energy_system\nwhere parent_system_id in (select id from energy_system where parent_system_id\nin (246, 247, 3395)) union select * from energy_system where parent_system_id in\n( select id from energy_system where parent_system_id in (select id from\nenergy_system where parent_system_id in (247, 3395))) union select * from\nenergy_system where parent_system_id in ( select id from energy_system where\nparent_system_id in (select id from energy_system where parent_system_id in\n(select id from energy_system where parent_system_id in (247, 3395)))) order by\nid\" > systems.csv\n\nselect * from energy_system f left join energy_system s on f.parent_system_id =\ns.id where f.id = 246","routePath":"/notes/03-Databases & Data Storage/postgres/psql cmd","lang":"","toc":[{"text":"export data","id":"export-data","depth":2,"charIndex":7},{"text":"import","id":"import","depth":2,"charIndex":1877}],"domain":"","frontmatter":{},"version":""},{"id":136,"title":"redis","content":"#\n\n\ninstallation#\n\n","routePath":"/notes/03-Databases & Data Storage/redis","lang":"","toc":[{"text":"installation","id":"installation","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":137,"title":"config ssh login by password","content":"#\n\n * system-view\n\n * ssh user sshclient authentication-type password\n\n * ssh user sshclient service-type stelnet\n\n * aaa\n\n * local-user sshclient password cipher password\n\n * local-user sshclient service-type ssh\n\n * local-user sshclient user-group mange-ug\n\n * quit\n\n * stelnet server enable\n\n * user-interface vty 0 4\n\n * authentication-mode aaa\n\n * protocol inbound ssh\n\n * commit\n\n\nSSH tunnel as SOCKS5 proxy#\n\nssh -C -f -N -q -D 9999 user@example.com\n\nRef","routePath":"/notes/05-Networking & Security/001-ssh","lang":"","toc":[{"text":"SSH tunnel as SOCKS5 proxy","id":"ssh-tunnel-as-socks5-proxy","depth":2,"charIndex":386}],"domain":"","frontmatter":{},"version":""},{"id":138,"title":"EasyConnect","content":"#\n\n\ninstall#\n\nvpn address\n\n\nfix issue#\n\nstart app without response by downgrading Pango\nhttps://zhuanlan.zhihu.com/p/648655420","routePath":"/notes/05-Networking & Security/EasyConnect","lang":"","toc":[{"text":"install","id":"install","depth":2,"charIndex":3},{"text":"fix issue","id":"fix-issue","depth":2,"charIndex":27}],"domain":"","frontmatter":{},"version":""},{"id":139,"title":"privoxy","content":"#\n\nsystemd 开机无法启动privoxy\n\n\n\n\nSetting up proxy#\n\nThis is only required for the places where is not able to access google service,\notherwise please ignore this part.\n\nFirstly you have to set up an socks proxy server which is able to access google\nservice. If you don't' have a server available, Please try to find some free\nsocks server. Then you only need to set up a client.\n\nFor the client. there are shadowsocks for socks proxy and privoxy for http\nproxy.\n\ndownload shadowsocks and move it to /usr/local/bin, then start socks proxy:\n\nshadowsocks2-linux -c=ss://METHOD:PASSWORD@IPADDRESS:PORT -verbose -socks\n0.0.0.0:1080\n\ne.g. shadowsocks2-linux\n-c=ss://aes-256-gcm:ntdtv.com%20123abc@45.147.201.142:1000 -verbose -socks\n0.0.0.0:1080\n\nsudo apt-get install privoxy\n\nsudo vim /etc/privoxy/config\n\nmake sure these two lines are no commented. if socks server is not on the same\nserver, please change the 127.0.0.1 to server IP.\n\nforward-socks5 / 127.0.0.1:1080 .\n\nlisten-address 0.0.0.0:8118\n\nThen restart privoxy\n\nsudo systemctl restart privoxy","routePath":"/notes/05-Networking & Security/GFW/1.privoxy","lang":"","toc":[{"text":"Setting up proxy","id":"setting-up-proxy","depth":2,"charIndex":28}],"domain":"","frontmatter":{},"version":""},{"id":140,"title":"SSR","content":"#\n\n\nhttps://github.com/shadowsocksrr/shadowsocksr#\n\n\nhttps://git.mrwang.pw/Reed/Linux_ssr_script.git#","routePath":"/notes/05-Networking & Security/GFW/2.ssr","lang":"","toc":[{"text":"https://github.com/shadowsocksrr/shadowsocksr","id":"httpsgithubcomshadowsocksrrshadowsocksr","depth":2,"charIndex":3},{"text":"https://git.mrwang.pw/Reed/Linux_ssr_script.git","id":"httpsgitmrwangpwreedlinux_ssr_scriptgit","depth":2,"charIndex":-1}],"domain":"","frontmatter":{},"version":""},{"id":141,"title":"","content":"#Shadowsocks5\n\n\ncmd#\n\nsslocal -c 'ss://aes-256-gcm:f55.fun-70948099@172.104.185.140:14089' -verbose\n-socks :1080 -u -plugin v2ray -udptun :8053=8.8.8.8:53,:8054=8.8.4.4:53 -tcptun\n:8053=8.8.8.8:53,:8054=8.8.4.4:53\n\nsslocal -c ss://45.136.244.225:10000 -verbose-cipher=aes-256-gcm\n-password=\"dongtaiwang.com 666nice\" -socks :1080 -u -udptun\n:8053=8.8.8.8:53,:8054=8.8.4.4:53 -tcptun :8053=8.8.8.8:53,:8054=8.8.4.4:53\n\nsslocal -c=ss://aes-256-gcm:dongtaiwang.com%20666nice@45.136.244.225:10000\n-verbose -socks 0.0.0.0:1080 -u -udptun :8053=8.8.8.8:53,:8054=8.8.4.4:53\n-tcptun :8053=8.8.8.8:53,:8054=8.8.4.4:53\n\nsslocal -c\n\nexport http_proxy=http://127.0.0.1:8118 export\nhttps_proxy=https://127.0.0.1:8118\n\n\nmore resource#\n\n * (free-ss)[https://free-ss.site/]\n\n * (Alvin9999)[https://github.com/Alvin9999/new-pac/wiki/ss%E5%85%8D%E8%B4%B9%E8\n   %B4%A6%E5%8F%B7]\n\nProxyChains:\n\ninstall location https://github.com/rofl0r/proxychains-ng\n\n\n\nproxychains4 bash then all will be proxied.","routePath":"/notes/05-Networking & Security/GFW/ss","lang":"","toc":[{"text":"cmd","id":"cmd","depth":2,"charIndex":15},{"text":"more resource","id":"more-resource","depth":2,"charIndex":704}],"domain":"","frontmatter":{},"version":""},{"id":142,"title":"","content":"","routePath":"/notes/05-Networking & Security/GFW/xray/xray","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":143,"title":"asm","content":"Errors#\n\n 1. pcap.h: No such file or directory\n    \n    sudo apt install libpcap-dev\n\n 2. ERROR: Cannot find tool llc\n    \n    sudo apt install llvm\n\n 3. No package 'libelf' found sudo apt install libelf-dev\n\n 4. fatal error: 'asm/types.h' file not found sudo ln -s\n    /usr/include/x86_64-linux-gnu/asm /usr/include/asm\n\n 5. while loading shared libraries: libpcap.so.1: cannot open shared object\n    file: No such file or directory\n    \n    sudo apt install libpcap-dev\n\n\nasm#\n\n 1. Create bpf.c.file\n    \n    \n\n 2. generate it to ebpf asm\n    \n    ","routePath":"/notes/05-Networking & Security/bpf","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":144,"title":"install golang","content":"Cap#\n\n\ninstall build tools#\n\nsudo apt install make\n\n安装llvm\n\n\n\nllvm\n\n\ninstall pcap#\n\n\n\n\ninstall pf_ring#\n\n\n\ninstall links\n\n\ninstall golang#\n\n","routePath":"/notes/05-Networking & Security/cap","lang":"","toc":[{"text":"install build tools","id":"install-build-tools","depth":2,"charIndex":6},{"text":"install pcap","id":"install-pcap","depth":2,"charIndex":68},{"text":"install pf_ring","id":"install-pf_ring","depth":2,"charIndex":86}],"domain":"","frontmatter":{},"version":""},{"id":145,"title":"Connection","content":"#\n\n\nsudo lsof -i -P -n#\n\n\ntest TCP#\n\nnc -z -v [hostname/IP address] [port number] eg: nc -z -v 192.168.10.12 22\n\n\ntest UDP#\n\nnc -z -v -u [hostname/IP address] [port number] eg: nc -z -v -u 192.168.10.12\n123","routePath":"/notes/05-Networking & Security/connect","lang":"","toc":[{"text":"sudo lsof -i -P -n","id":"sudo-lsof--i--p--n","depth":2,"charIndex":3},{"text":"test TCP","id":"test-tcp","depth":2,"charIndex":25},{"text":"test UDP","id":"test-udp","depth":2,"charIndex":113}],"domain":"","frontmatter":{},"version":""},{"id":146,"title":"installation","content":"#\n\n\ninstall python3#\n\n","routePath":"/notes/05-Networking & Security/dpdk/dpdk","lang":"","toc":[{"text":"install python3","id":"install-python3","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":147,"title":"599-mail","content":"#\n\nMail Process-\n\n * MTA- Mail Transfer Agent\n * MDA- Mail Delivery Agent\n * MUA- Mail User Agent\n * MRA- Mail Retiveral Agent\n * MAA- Mail Access Agent\n\n\n\n\n\n * 常用的MUA有：outlook、thunderbird、Mac Mail、mutt；\n * 常用的MTA服务有：sendmail、postfix；\n * 常用的MDA有：procmail、dropmail；\n * 常用的MRA有：dovecot。\n\nFrom http://www.itye.org/archives/1304\n\n","routePath":"/notes/05-Networking & Security/mail/299-mail","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":148,"title":"postfix","content":"#\n\n\ndocker compoise file#\n\n\n\n\nenv#\n\n","routePath":"/notes/05-Networking & Security/mail/postfix","lang":"","toc":[{"text":"docker compoise file","id":"docker-compoise-file","depth":2,"charIndex":3},{"text":"env","id":"env","depth":2,"charIndex":29}],"domain":"","frontmatter":{},"version":""},{"id":149,"title":"handshake","content":"#\n\n","routePath":"/notes/05-Networking & Security/protocol/handshake","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":150,"title":"link","content":"#\n\n\n\n\n\n![UDP报头结构](./_v_images/20200121103430599_23845.png =1000x)\n\n![TCP报头结构](./_v_images/20200121103512775_26619.png =1000x)\n\n![IP报头结构](./_v_images/20200121103610511_31665.png =1000x)","routePath":"/notes/05-Networking & Security/protocol/pack head","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":151,"title":"stack","content":"#\n\n","routePath":"/notes/05-Networking & Security/protocol/stack","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":152,"title":"pktgen","content":"#\n\nsudo ${cmd} ${dpdk_opts} ${black_list} -- ${pktgen_opts} ${port_map}\n${load_file}\n\ndpdk_opts=\"-l 1-38 -n 4 --proc-type primary --log-level 7 --socket-mem\n4096,4096\" pktgen_opts=\"-T -P -N -l /var/log/pktgen.log\" port_map=\"-m\n[3:4].1,[6:7].2,[8:9].3,[12:15].4,[13:14].5,[10:11].6,[16:17].7\" black_list=\"\"\nload_file=\"-f themes/white-black.theme\"\n\nstty sane\n\nsocat - TCP4:localhost:22022 < ttt.lua\n\npktgen.ip_proto(\"all\", \"udp\")\n\nsudo /dpdk/pktgen-3.4.0/app/x86_64-native-linuxapp-gcc/pktgen -l 1-38 -n 4\n--proc-type primary --log-level 7 --socket-mem 4096,4096 -- -T -P -N -l\n/var/log/pktgen.log -m\n[3:4].1,[6:7].2,[8:9].3,[12:15].4,[13:14].5,[10:11].6,[16:17].7 -g\n192.168.1.115:22022\n\n/home/bkl/pktgen-3.5.1/app/x86_64-native-linuxapp-gcc/pktgen -l 1-38 -n 4\n--proc-type primary --log-level 7 --socket-mem 4096,4096 -- -T -P -N -l\n/var/log/pktgen.log -m\n[3:4].1,[6:7].2,[8:9].3,[12:15].4,[13:14].5,[10:11].6,[16:17].7 -g\n192.168.1.115:22022\n\nEnable all range range all dst ip 10.0.4.1 10.0.4.1 10.0.4.255 0.0.0.1 range all\nsrc ip 1.1.1.1 1.1.1.1 255.255.255.255 0.0.0.1 start all 设置速率50%： Set all rate\n50 设置发包数量： Set all count 1000 可以设置对应端口，将0换成对应端口号就行： Set 0 count 100\n\nrange all dst ip 192.168.123.1 192.168.123.1 192.168.123.255 0.0.0.1 range all\nsize 128, 128, 512, 128\n\n\n\n","routePath":"/notes/05-Networking & Security/ptkgen/pktgen","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":153,"title":"Cisco IOS模式","content":"#\n\n1.用户模式 cisco > 正常登陆设备CLI后的第一个配置模式，只具备最基本的查看权限\n\n2.特权模式 cisco # 从用户模式通过认证后即可进入特权模式\n\n3.全局配置模式 可配置设备全局参数，开启或关闭设备全局特性或功能\n\n从全局配置模式可进入多种不同的其他子配置模式\n\n4.接口模式 用于配置设备的接口\n\n5.线路模式 用于配置一条线路（实际线路或虚拟线路）（例如控制台、AUX 或 VTY 等等）\n\n6.路由进程配置模式 用于配置一个路由协议进程\n\n\n\n","routePath":"/notes/05-Networking & Security/router/Cisco IOS模式","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":154,"title":"Centos:","content":"add route#\n\n\nwindows:#\n\nroute add 192.168.121.0 mask 255.255.255.0 192.168.1.133\n\n\nCentos:#\n\nNet-tools route add -net 192.168.121.0 netmask 255.255.255.0 gw 192.168.1.133\ndev enp0s3 route del -net 192.168.121.0/24 gw 0.0.0.0\n\nIproute\n\nSudo ip route add ip/24 via 192.168.1.133 dev enp0s3 Sudo ip route del ip/24\n\nip route add 192.168.121.0/24 via 10.2.6.116 dev enp4s0f0","routePath":"/notes/05-Networking & Security/router/add route","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":155,"title":"dataplane","content":"#\n\n2004年9月：三平面分离\n交换机的基本工作是处理不同接口上各种类型的数据，对于数据处理过程中各种具体的处理转发过程，例如L2/L3/ACL/QOS/组播/安全防护等各种网络功能的具体执行\n，都划分为交换机的数据平面；而控制平面用于控制各种网络协议的运行，例如控制OSPF、ARP、STP等等协议的正常运行，控制平面提供了对网络环境的准确认识，提供了\n数据平面数据处理转发前所必须的各种网络信息和转发查询表项；至于管理平面的功能是提供给网络管理人员使用TELNET、WEB、SSH、SNMP、RMON等方式管理设\n备的各种管理接口，并支持、理解和执行管理人员对于网络设备各种网络功能的设置命令。 为什么需要对数据平面、控制平面和管理平面进行相互的分离呢？\n\n\n\n假设这几个平面不进行任何的分离，数据平面和控制、管理平面使用共用的主机资源，在大数据流量、复杂应用环境下数据平面由于承担着繁重的日常任务将可能消耗绝大部分资源，\n这对于整个交换机系统无疑是灾难性的，因为在某些极端的情况下，控制平面将没有充分的资源来保障运行，这就意味网络设备失去了对设备所处网络环境的真实了解，网络设备将立\n即陷于非正常工作状态甚至瘫痪状态，而管理人员也没有资源使用管理平面对网络设备的运行进行干预，所以数据平面需要严格地与控制平面、管理平面进行分离。\n管理平面所要求的系统资源是最低的，分离出一定的系统资源独立运行管理平面并不影响控制平面的运行，反而，是为了更好地保证控制平面的正常运行。因为，在网络环境频繁变动\n、网络协议剧烈动荡的情况下，控制平面所需要的资源将持续保持在一个极高的水平线，这其实说明了网络设备在该网络情况下是无法适应和正常运行的，管理平面的分离让系统管理\n员可以在控制平面出现异常状况的时候依然拥有足够资源顺利地打开设备的管理界面，通过改变或终止某个协议、端口的运行来阻止非正常网络环境对网络设备的剧烈影响，最终达到\n在线改变网络设备控制平面非正常运行的局面，因为控制平面的正常运行是至关重要的。\n通过采用数据平面、控制平面、管理平面相互分离的结构模型，保证了大量的数据处理不影响管理和控制，而在路由和环境复杂条件下，控制平面不影响管理平面，高度保证了系统安\n全稳定性。\n“三平面分离”技术注重于保护核心设备在病毒和攻击环境下依然提供正常的网络设备管理，满足在线地定位和解决安全问题，在稳定性设计上优于传统的“两平面分离”技术。\n\n2006年9月：CPP技术\n从交换机的体系结构来看，交换机有两部分组成：ASIC芯片用于高速的转发数据包，而CPU主要是来处理一些更为复杂的事务，包括对网络管理方面任务和请求进行处理；处理\n各种协议报文以及部分特殊的数据报文。\n常见对网络设备的病毒和攻击实际上就是让主机没有资源去应付这些正常的请求，把大量的资源都用在处理那些非法性质的请求和事务上，从而导致系统的不可用。\n\n随着交换机应用的逐渐普及，以及网络攻击的不断增多，越来越需要为数据交换机提供一种保护机制，对发往交换机CPU的数据流，进行流分类和优先级分级处理，以及CPU的带\n宽限速，以确保在任何情况下CPU都不会出现负载过高的状况，从而能为用户提供一个稳定的网络环境，这种保护机制就是CPU Protect Policy，简称CPP。\n\n来自 http://www.ruijie.com.cn/special/wzwn/11/content.html#4\n\n1 交换机数据、控制、管理平面分离设计 1.1 交换机数据、控制、管理平面的概念\n\n1.1.1 交换机数据平面 交换机的基本任务是处理和转发交换机各不同端口上各种类型的数据，对于数据处理过程中 各种具体的处理转发过程，例如\nL2/L3/ACL/QOS/组播/安全防护等各功能的具体执行过程，都 属于交换机数据平面的任务范畴。\n交换机的数据平面在交换机的各种平面任务当中需要占用决大部分的资源，也直接地对交换\n机的性能表现起决定作用，各个厂家都通过各种技术手段和芯片技术努力地提高交换机数据 平面的处理性能。\n\n1.1.2 交换机控制平面 交换机的控制平面用于控制和管理所有网络协议的运行，例如生成树协议、VLAN 协议、ARP\n协议、各种路由协议和组播协议等等的管理和控制。交换机控制平面通过网络协议提供给交\n换机对整个网络环境中网络设备、连接链路和交互协议的准确了解，并在网络状况发生改变\n时做出及时的调整以维护网络的正常运行。控制平面提供了数据平面数据处理转发前所必须 的各种网络信息和转发查询表项。\n交换机的控制平面并不占用过多的主机资源，但在正常状况下依然是交换机 CPU 资源的主要\n占用平面，因此除了优化交换机对于控制平面的调度流程和效率，一般还可以通过提供多 CPU 或提高 CPU 的处理性能来提高交换机的控制平面性能。\n目前业界一般采用两平面分离的设计方式，“数据平面”是一个平面，“管理和控制平面”同\n属于一个平面，合并统称为“控制平面”，可以看出，对于“数据平面”的分离已经达到了业 界高度的一致。\n因为对于交换机而言，数据平面所耗费的主机资源是最多的，正常状况下，数据平面消耗的 是主机的硬件 ASIC 资源，但在大流量或某些病毒攻击网络环境下，在硬件\nASIC 资源无法满 足数据平面处理的情况下，数据平面的处理任务会进一步占用主机 CPU、内存等方面资源，\n从而可能会耗尽主机的所有软硬件资源，不仅系统管理员无法对设备进行管理，而且交换机\n的控制平面由于没有资源运行使得交换机成为一个“孤岛”，交换机无法及时准确地提供数据\n平面处理转发前所必须的各种网络信息和转发查询表项，无法通过各种网络协议对网络上的\n设备和链路的状态和异常情况进行了解，交换机失去了网络互联的意义。所以，数据平面的 单独分离是必不可少的。（其实，交换机在主机资源特别是 CPU\n资源耗尽时已经处于瘫痪状态， 数据平面的处理任务也无法得以保障。） 那为何又要对交换机的管理平面和控制平面进行相互的分离呢？在网络设备正常运行的状态\n下这两个平面是可以共存的，因为不论是控制平面或是管理平面都由于占用主机资源较少， 不存在主机资源（主要是 CPU）的争夺。\n但在现实的使用中却大量地存在类似情况：在病毒攻击情况下或网络中某些设备或链路发生\n状态震荡的状况下，由于各种二/三层协议必须跟随着网络的状态震荡进行相应的快速重计算 和变更，这将耗费巨大的主机资源（主要是\nCPU），交换机将随时进入瘫痪状态。系统管理员 发现网络运行不正常后希望登陆到网络设备，对网络设备的各种协议和状态进行查看，期望\n找出问题，必要时对某些协议或物理端口进行重新设置或屏蔽以保障网络设备的正常运行，\n但由于主机没有资源预留给管理平面，系统管理员的一切行为都无法实施，因此，发生了大\n量系统管理员直接开关电源重新启动设备的无奈之举，不仅极大地影响了网络的持续稳定运\n行，而且无法及时对网络的异常状况进行定位和分析。因此，进一步地对管理平面进行单独 分离的设计思路随之而出。\n下图是管理平面和控制平面进一步分离的三平面分离设计示意图：\n\n从上图可以看到，管理平面和控制平面进行了分离，管理平面所要求的系统资源是最低的，\n分离出一定的系统资源独立运行管理平面并不影响控制平面的运行资源，反而，是为了更好\n地保证控制平面的正常运行。因为，在网络环境频繁变动、网络协议剧烈动荡的情况下，控\n制平面所需要的资源将持续保持在一个极高的水平线，网络设备在该网络情况下已经无法适\n应和正常运行，管理平面的分离让系统管理员可以在控制平面出现异常状况的时候依然拥有\n足够资源顺利地打开设备的管理界面，拥有资源对网络设备的不正常现象进行查看和分析，\n并可以通过改变或终止某个协议、端口的运行来阻止非正常网络环境对网络设备的剧烈影响，\n最终达到在线改变网络设备控制平面非正常运行的局面，因为控制平面的正常运行是至关重 要的。\n所以，交换机通过采用数据平面、控制平面、管理平面相互分离的设计方式，保证了最耗费\n主机资源的数据处理转发任务不影响交换机的管理和协议运行，而在路由和环境复杂多变条 件下，控制平面的任务不影响交换机的管理，高度保证了交换机系统的稳定性。\n\n1.1.3 交换机管理平面 交换机的管理平面是提供给网络管理人员使用 TELNET、WEB、SSH、SNMP、RMON\n等方式来管理设备，并支持、理解和执行管理人员对于网络设备各种网络协议的设置命令。管理\n平面提供了控制平面正常运行的前提，管理平面必须预先设置好控制平面中各种协议的相关 参数，并支持在必要时刻对控制平面的运行进行干预。\n交换机的管理平面所需的交换机资源最少，目前都通过交换机 CPU 实现。 1.2 为什么需要对数据、控制和管理平面进行相互的分离？\n首先，从业界流行的平面设计方式进行分析可以得到一些初步的结论，下图是目前业界绝大 部分网络设备采用的设计方式：\n\n2 锐捷网络高端产品的三平面分离设计 锐捷万兆核心路由交换机 RG-S6800E 和面向十万兆平台设计的 RG-S8600、RG-S9600 通过进 一步优化\nNP+ASIC 的设计体系形成了数据平面、控制平面和管理平面的相互分离，如下 示意 图： 图2-1\n近几年的芯片技术发展已经支持ASIC芯片独立实现L2/L3/ACL/QOS/组播等数据平面的功能， 抛弃了数据流第一个数据包需要 CPU\n干预的传统工作机制。如图所示，在交换机的结构模型 里，每个线卡都拥有独立的 ASIC 芯片，可以独立地运行数据平面的各种工作，当数据在不同\n线卡之间转发时管理模块的 ASIC 芯片发挥作用，因此交换机的 ASIC 芯片负责着交换机数据 平面的工作。而多业务卡由于使用 NP\n技术拥有若干个微码处理器（CPU），性能强大，所以 RG-S6800E、RG-S8600、RG-S9600 可以把控制平面的任务交由多业务卡来实现，这样，管理\n模块的 CPU 摆脱了同时负责控制平面和管理平面任务的传统做法，而仅仅独立负责管理平面 的工作，从而达到了数据平面、控制平面、管理平面相互分离的结构模型。\n锐捷万兆核心路由交换机 RG-S6800E 和面向 十万兆平台设计的 RG-S8600、RG-S9600 通过采\n用数据平面、控制平面、管理平面相互分离的结构模型高度保证了系统稳定性。\n\nhttp://www.ruijie.com.cn/special/wzwn/download/pdf/s.pdf","routePath":"/notes/05-Networking & Security/router/dataplane","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":156,"title":"router","content":"#\n\n\nCisco路由器组件#\n\n\n\nCPU – 执行操作系统的指令 执行操作系统的指令，中央处理器\n\n随机访问存储器（RAM）– RAM中存储的信息在设备断电后会丢失 当前运行中的操作系统镜像（CISCO IOS）\n\n当前运行的配置文件（Running-configuration）\n\nIP路由表（IP Routing-Table）\n\nARP表（ARP cache）\n\n数据包缓存区\n\n只读存储器（ROM） – 保存开机自检软件，存储路由器的启动引导程序 启动引导程序（BOOTSTRAP）\n\n基本的自检软件（POST）\n\nMini IOS（用于紧急恢复）\n\n非易失性存储器（NVRAM） – 存储启动配置，包括IP地址，路由协议，主机名 存储启动配置（Startup-configuration）\n\n闪存FLASH – 运行操作系统（Cisco IOS），类似硬盘的角色 CISCO IOS（CISCO网络设备的操作系统）\n\nInterfaces – 拥有多种物理接口用于连接网络接口类型","routePath":"/notes/05-Networking & Security/router/router","lang":"","toc":[{"text":"Cisco路由器组件","id":"cisco路由器组件","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":157,"title":"VPN","content":"#\n\n\nserver#\n\n\ninstall by docker#\n\ndocker pull hwdsl2/ipsec-vpn-server\n\nenv file:\n\n\n\n\n\nRef Ref 2\n\n\nclient#\n\nsudo apt install network-manager-l2tp-gnome \n\n 1.  Go to Settings -> Network -> VPN. Click the + button.\n 2.  Select Layer 2 Tunneling Protocol (L2TP).\n 3.  Enter anything you like in the Name field.\n 4.  Enter Your VPN Server IP for the Gateway.\n 5.  Enter Your VPN Username for the User name.\n 6.  Right-click the ? in the Password field, select Store the password only for\n     this user.\n 7.  Enter Your VPN Password for the Password.\n 8.  Leave the NT Domain field blank.\n 9.  Click the IPsec Settings... button.\n 10. Check the Enable IPsec tunnel to L2TP host checkbox.\n 11. Leave the Gateway ID field blank.\n 12. Enter Your VPN IPsec PSK for the Pre-shared key.\n 13. Expand the Advanced section.\n 14. Enter aes128-sha1-modp2048 for the Phase1 Algorithms.\n 15. Enter aes128-sha1 for the Phase2 Algorithms.\n 16. Click OK, then click Add to save the VPN connection information.\n 17. Turn the VPN switch ON.\n\nRef","routePath":"/notes/05-Networking & Security/vpn","lang":"","toc":[{"text":"server","id":"server","depth":2,"charIndex":3},{"text":"install by docker","id":"install-by-docker","depth":3,"charIndex":13},{"text":"client","id":"client","depth":2,"charIndex":97}],"domain":"","frontmatter":{},"version":""},{"id":158,"title":"get interface","content":"memo#\n\nexport LD_LIBRARY_PATH=/home/ddos/vpp/build-root/install-vpp-native/vpp/lib64\n\ncd /home/ddos/vpp/build-root/build-vpp-native/vpp/vpp-api/python/build/lib/\n\n\nget interface#\n\n","routePath":"/notes/05-Networking & Security/vpp/memo","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":159,"title":"","content":"How to create a new plugin#\n\nTo create a new plugin based on the sample plugin, copy and rename the sample\nplugin directory and automake config.\n\n\n\nAdd the following entry to the plugins section of src/configure.ac.\n\n\n\nAdd the following entry to the plugins section of src/plugins/Makefile.am\n\n\n\nNow (re)build VPP.\n\n\n\n\nConfiguration#\n\nTo enable the sample plugin\n\n\n\nTo disable the sample plugin\n\n\n\n\nRef#\n\n如何新建VPP插件 HOW TO DEVELOP VPP PLUGINS sdnlab","routePath":"/notes/05-Networking & Security/vpp/plugin","lang":"","toc":[{"text":"How to create a new plugin","id":"how-to-create-a-new-plugin","depth":2,"charIndex":-1},{"text":"Configuration","id":"configuration","depth":2,"charIndex":318},{"text":"Ref","id":"ref","depth":2,"charIndex":398}],"domain":"","frontmatter":{},"version":""},{"id":160,"title":"","content":"VPP概述汇总","routePath":"/notes/05-Networking & Security/vpp/ref","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":161,"title":"vector packet","content":"#\n\nFD.io VPP is developed using vector packet processing concepts, as opposed to\nscalar packet processing, these concepts are explained in the following\nsections. Vector packet processing is a common approach among high performance\nUserspace packet processing applications such as developed with FD.io VPP and\nDPDK. The scalar based aproach tends to be favoured by Operating System Kernel\nNetwork Stacks and Userspace stacks that don’t have strict performance\nrequirements.\n\n来自\nhttps://fdio-vpp.readthedocs.io/en/latest/overview/whatisvpp/what-is-vector-pack\net-processing.html","routePath":"/notes/05-Networking & Security/vpp/vector packet","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":162,"title":"debug process","content":"#\n\n\nbuild the filebing#\n\n\nstart to debug#\n\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/chiching/projects/wazuh/src","routePath":"/notes/05-Networking & Security/wazuh","lang":"","toc":[{"text":"build the filebing","id":"build-the-filebing","depth":2,"charIndex":3},{"text":"start to debug","id":"start-to-debug","depth":2,"charIndex":25}],"domain":"","frontmatter":{},"version":""},{"id":163,"title":"Data Warehouse","content":"#\n\n","routePath":"/notes/06-Big Data/datawarehouse","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":164,"title":"Hadoop","content":"#\n\n\nplan#\n\nNODE    HOSTNAME   IP               COMPONENTS\nnode1   nn.rm      10.230.168.208   namenode, datanode, resourcemanager, nodemanger\nnode2   dn.nm1     10.230.168.210   secondnamenanager, datanode, nodemanager\nnode3   dn.nm2     10.230.168.231   datanode，nodemanager\n\n\nhost#\n\n\n\n\njava#\n\ncopy jdk files to /opt/apps/jdk\n\n\n\n\nhadoop#\n\n\ninstall and config#\n\nfiles#\n\ncopy hadoop files to /opt/apps/hadoop\n\n\n\nconfig of hadoop-env.sh#\n\nadd the content to file /opt/apps/hadoop/etc/hadoop/hadoop-env.sh\n\n\n\nconfig of core-site.xml#\n\nadd the content to file /opt/apps/hadoop/etc/hadoop/core-site.xml\n\n\n\nconfig of hdfs-site.xml#\n\nadd the content to file /opt/apps/hadoop/etc/hadoop/hdfs-site.xml\n\n\n\nconfig of mapred-site.xml#\n\nadd the content to file /opt/apps/hadoop/etc/hadoop/mapred-site.xml\n\n\n\nconfig of yarn-site.xml#\n\nadd the content to file /opt/apps/hadoop/etc/hadoop/yarn-site.xml\n\n\n\nconfig of workers#\n\nadd the content to file /opt/apps/hadoop/etc/hadoop/workers\n\n\n\nformat#\n\nhdfs namenode -format\n\n\nstart up#\n\nstart commands#\n\n * hdfs hdfs --daemon start|stop namenode|datanode|secondarynamenode\n * yarn yarn --daemon start|stop resourcemanager|nodemanager\n\ncheck the porcess#\n\nrun jps to check roles on chech node.\n\nweb UI#\n\n * hdfs cluster http://nn.rm:9870\n * yarn cluster http://nn.rm:8088\n\ncheck files#\n\n * list file hadoop fs -ls /\n * mkdir hadoop fs -mkdir /test\n * upload file hadoop fs -put readme.md /test","routePath":"/notes/06-Big Data/hadoop","lang":"","toc":[{"text":"plan","id":"plan","depth":2,"charIndex":3},{"text":"host","id":"host","depth":2,"charIndex":277},{"text":"java","id":"java","depth":2,"charIndex":287},{"text":"hadoop","id":"hadoop-1","depth":2,"charIndex":-1},{"text":"install and config","id":"install-and-config","depth":3,"charIndex":340},{"text":"files","id":"files","depth":4,"charIndex":361},{"text":"config of hadoop-env.sh","id":"config-of-hadoop-envsh","depth":4,"charIndex":410},{"text":"config of core-site.xml","id":"config-of-core-sitexml","depth":4,"charIndex":505},{"text":"config of hdfs-site.xml","id":"config-of-hdfs-sitexml","depth":4,"charIndex":600},{"text":"config of mapred-site.xml","id":"config-of-mapred-sitexml","depth":4,"charIndex":695},{"text":"config of yarn-site.xml","id":"config-of-yarn-sitexml","depth":4,"charIndex":794},{"text":"config of workers","id":"config-of-workers","depth":4,"charIndex":889},{"text":"format","id":"format","depth":4,"charIndex":972},{"text":"start up","id":"start-up","depth":3,"charIndex":1005},{"text":"start commands","id":"start-commands","depth":4,"charIndex":1016},{"text":"check the porcess","id":"check-the-porcess","depth":4,"charIndex":1164},{"text":"web UI","id":"web-ui","depth":4,"charIndex":1223},{"text":"check files","id":"check-files","depth":4,"charIndex":1301}],"domain":"","frontmatter":{},"version":""},{"id":165,"title":"Hive","content":"#\n\n\ninstall and config#\n\n\nfiles#\n\ncopy hive files to /opt/apps/hive\n\n\nconfig of hive-env.sh#\n\n\n\n\nconfig of hive-site.sh#\n\nadd file vim hive/conf/hive-site.xml\n\n\n\n\nupload mysql driver#\n\nupload mysql driver mysql-connector-java-8.0.30.jar to\nhive/lib/mysql-connector-java-8.0.30.jar\n\n\ninit metastore#\n\n\n\nthe log located at cat /tmp/$USER/hive.log\n\n\nstart services#\n\n\nstart metastore svc#\n\nnohup /opt/apps/hive/bin/hive --service metastore > metastore.log 2>&1 &\n\ncheck svc by jps or ss -anp | grep 9083\n\n\nstart hiveserver2 svc#\n\nnohup /opt/apps/hive/bin/hive --service hiveserver2 > hiveserver2.log 2>&1 &\n\ncheck svc by jps or ss -anp | grep 10000\n\nerrors in /tmp/$USER/hive.log#\n\n * error Can't function without a valid hostname! fix it by sudo hostnamectl\n   set-hostname nn.rm\n\n\nconnect to hive#\n\n/opt/apps/hive/bin/beeline -u jdbc:hive2://nn.rm:10000 --verbose=true","routePath":"/notes/06-Big Data/hive","lang":"","toc":[{"text":"install and config","id":"install-and-config","depth":2,"charIndex":3},{"text":"files","id":"files","depth":3,"charIndex":25},{"text":"config of hive-env.sh","id":"config-of-hive-envsh","depth":3,"charIndex":69},{"text":"config of hive-site.sh","id":"config-of-hive-sitesh","depth":3,"charIndex":96},{"text":"upload mysql driver","id":"upload-mysql-driver","depth":3,"charIndex":162},{"text":"init metastore","id":"init-metastore","depth":2,"charIndex":282},{"text":"start services","id":"start-services","depth":2,"charIndex":346},{"text":"start metastore svc","id":"start-metastore-svc","depth":3,"charIndex":364},{"text":"start hiveserver2 svc","id":"start-hiveserver2-svc","depth":3,"charIndex":502},{"text":"errors in `/tmp/$USER/hive.log`","id":"errors-in-tmpuserhivelog","depth":4,"charIndex":-1},{"text":"connect to hive","id":"connect-to-hive","depth":2,"charIndex":779}],"domain":"","frontmatter":{},"version":""},{"id":166,"title":"【爱芯派 Pro 开发板试用体验】开箱报告","content":"#\n\n\n开发板介绍#\n\n收到了爱芯派 Pro (AXera-Pi Pro)开发板，一个高能效比智能视觉芯片\nAX650N，处理器是8核64位Cortex-A55架构，主频达1.7Ghz。内置高算力视频，图片处理能力，据说支持Transformer 模型和视觉大模型。\n\n一块板子，一个电源，一个螺帽没发现干嘛的。\n\n\n开机#\n\n插上鼠标键盘的USB线， 用HDMI线连上显示器，然后接上电源线就通了，就这么简单。 注意一下就是这里默认桌面输出是HDMI1，不确定是那个就重新插一下。\n桌面用的是xfce, 可能主要考虑是节约资源，比gnmoe肯定要好很多。\n\n\n查看系统信息#\n\n的确是8核，Cortex-A55\n\n内存好像只有6g，不是介绍说的标准配置8g，而且好像没有扩展口，有点遗憾。\n\n存储是32g的 eMMC，后面可以自己通过SATA或者m.2口去扩展，m.2口也是SATA协议，没有说支持NVMe。\n\n系统自带的是debian bookworm,\n非常新了。之前还以为会带一个很老的版本，想着自己怎么升级或者重装，看来现在不用折腾了，先用着，系统这块后面有时间了再慢慢玩。\n\n没有找到类似nvidia-smi查看GPU信息的命令，可以看看NPU的信息。\n\n\n简单配置#\n\n我现在简单配置一下，然后将板子放隔壁去，从这边链接，主要是配置网络。\n\n先配了个ip，用的0网口。里面具体的内容就根据自己的情况进行修改啦。\n\ndns也要配置一下，以便后面更新系统和安装其他应用需要。\n\n再运行root用户ssh进来，也可以新建一个额外的用户。\n\n然后就可以拿到有网的地方去插上网线了。\n\napt update 更新源。 apt full-upgrade 升级所有应用到最新版本。\n\n再装一个xrdp, 这样就可以把板子放在随便那个有网的地方，然后用window 通过mstsc远程过去啦。","routePath":"/notes/07-AI & Machine Learning/AXera-Pi Pro/open_box/open_box","lang":"","toc":[{"text":"开发板介绍","id":"开发板介绍","depth":2,"charIndex":3},{"text":"开机","id":"开机","depth":2,"charIndex":158},{"text":"查看系统信息","id":"查看系统信息","depth":2,"charIndex":280},{"text":"简单配置","id":"简单配置","depth":2,"charIndex":534}],"domain":"","frontmatter":{},"version":""},{"id":167,"title":"用rust写模型runner","content":"#\n\n之前学习用的都是官网写好的模型runner，这里尝试用rust自己写一个runner，主要是为了熟悉Axera的一些API以便后期扩展。这里主要用到AxEngi\nne，他是神经网络模型芯片侧推理计算库，能够完成模型加载到执行的全部推理任务。这次主要以获取版本为例，介绍一下如何用rust接入以及相关API，完整的runne\nr待后期完善，本例中仅仅涉及三个API，AX_ENGINE_Init，AX_ENGINE_Deinit和AX_ENGINE_GetVersion。\n\n模型runner主要API以及调用流程，请参考文档《51 - AX ENGINE API\n使用说明.pdf》，特别是调用流程，也可以参考一些C实现的example。主要用到了libax_engine.so动态库，提供的函数不多。\n\n主要参考代码如下：\n\n\n\n下面的截图是最后运行结果：\n\n","routePath":"/notes/07-AI & Machine Learning/AXera-Pi Pro/run_model/run_mode","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":168,"title":"用rust接视频输入输出","content":"#\n\n现在来了解一下视频输入输出的相关API，如何通过rust接Axera的视频输入输出，以便将内容读取，然后给模型做分析，后面做结果输出。\n\n主要API以及调用流程，请参考文档《24 - AX VO API 文档.pdf》和《16 - AX VIN\n开发参考.pdf》，主要用到了libax_proton.so，libax_vo.so和libax_ivps动态库，提供的函数具体参考文档。\n\n以下是部分参考代码：\n\n视频输入部分代码：\n\n\n\n视频输出部分代码，结构体和枚举定义内容会很多，这里贴一部分样例：\n\n\n\n以下是简单的测试，输入模块的初始化，创建设备，销毁设备，以及使能和禁止设备等简单操作的样例。\n\n","routePath":"/notes/07-AI & Machine Learning/AXera-Pi Pro/vin_vo/vin_vo","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":169,"title":"yolov8模型转换","content":"#\n\n尝试一下将最新的yolov8模型转换为爱芯派的模型。\n\n\n环境准备#\n\n\n准备Docker环境#\n\n首先自己在任意机器准备好docker环境。\n\nDocker 镜像文件\n\n\n准备 yolo8 模型，并转换为onnx格式。#\n\n下载yolov8n.pt\n\n将PyTorch模型格式转为onnx模型格式。yolo mode=export model=yolov8n.pt format=onnx\ndynamic=False。 这里需要有yolo的环境，自己安装 pip install ultralytics -i\nhttps://pypi.tuna.tsinghua.edu.cn/simple，有其他需要的依赖包，接着继续安装。\n\n\n\n转换完了之后，会生成一个yolov8n.onnx文件。\n\n\naxmodel模型转换#\n\n\n\n\n预先已使用 onnxsim 将 mobilenetv2.onnx 进行计算图优化#\n\n如果用docker 环境，可能会遇到以下错误\n\n\n\n\n\n主要是onnx和onnxruntime版本不对，更新一下就可以了\n\n\n\n然后再运行 onnxsim yolov8n.onnx yolov8nsim.onnx\n\n\n\n\naxmodel转换#\n\n准备好config.json文件，然后运行命令。pulsar2 build --input yolov8nsim.onnx --output_dir\noutput --config config.json, 将会得到output/compiled.axmodel文件。\n\n\n开发板上运行模型评测#\n\n通过开发板上预制的ax_run_model 工具，测试模型速度和精度。","routePath":"/notes/07-AI & Machine Learning/AXera-Pi Pro/yolo8/yolo8","lang":"","toc":[{"text":"环境准备","id":"环境准备","depth":2,"charIndex":31},{"text":"准备Docker环境","id":"准备docker环境","depth":3,"charIndex":39},{"text":"准备 yolo8 模型，并转换为onnx格式。","id":"准备-yolo8-模型并转换为onnx格式","depth":3,"charIndex":89},{"text":"axmodel模型转换","id":"axmodel模型转换","depth":2,"charIndex":350},{"text":"预先已使用 onnxsim 将 mobilenetv2.onnx 进行计算图优化","id":"预先已使用-onnxsim-将-mobilenetv2onnx-进行计算图优化","depth":3,"charIndex":367},{"text":"axmodel转换","id":"axmodel转换","depth":3,"charIndex":521},{"text":"开发板上运行模型评测","id":"开发板上运行模型评测","depth":2,"charIndex":670}],"domain":"","frontmatter":{},"version":""},{"id":170,"title":"CUDA","content":"#\n\n * nvcc --version see the （NVIDIA (R) Cuda compiler driver） version\n * cuDNN 安装 cuDNN 是基于cuda的加速器，可提升原有的gpu算力至1.5倍。\n * nvidia-smi查看显卡使用情况， \"cd C:\\Program Files\\NVIDIA Corporation\\NVSMI\",\n   nvidia-smi\n * Publish TVM\n   https://discuss.tvm.apache.org/t/tvm-opencv-compatibility-issue/2057/8","routePath":"/notes/07-AI & Machine Learning/cuda","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":171,"title":"driver","content":"#\n\nnvidia-bug-report.sh to get driver issue.\n\n\ndocker#\n\ninstall container-toolkit\n\n\nref#\n\n 1. CUDA","routePath":"/notes/07-AI & Machine Learning/nvidia-driver","lang":"","toc":[{"text":"docker","id":"docker","depth":2,"charIndex":46},{"text":"ref","id":"ref","depth":2,"charIndex":83}],"domain":"","frontmatter":{},"version":""},{"id":172,"title":"Kibana","content":"Wazuh#\n\n\nKibana#\n\n * git clone --depth 1 git@github.com:elastic/kibana.git\n * yarn kbn bootstrap to install the plugins and tools\n * ","routePath":"/notes/07-AI & Machine Learning/security","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":173,"title":"super resolution","content":"#\n\nREPO       预训练结果   训练模型\nResShift   效果差     代码错误\nStableSR   效果差     代码错误\nDiffPIR    效果差     代码错误\nDDNM       效果差     代码错误","routePath":"/notes/07-AI & Machine Learning/sr","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":174,"title":"","content":"docker compose file#\n\n\n\n\n\n","routePath":"/notes/07-AI & Machine Learning/sr_dockerfile","lang":"","toc":[{"text":"docker compose file","id":"docker-compose-file","depth":2,"charIndex":-1}],"domain":"","frontmatter":{},"version":""},{"id":175,"title":"","content":"CUDA_VISIBLE_DEVICES=7 PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 python\ninference_resshift.py -i input/beauty.png -o output --task realsrx4 --chop_size\n256\n\nCUDA_VISIBLE_DEVICES=7 torchrun --standalone --nproc_per_node=4 --nnodes=1\nmain.py --cfg_path configs/realsr_swinunet_realesrgan256.yaml --save_dir log\n--steps 15\n\n\nstableSR#\n\npython scripts/sr_val_ddpm_text_T_vqganfin_old.py --config\nconfigs/stableSRNew/v2-finetune_text_T_512.yaml --ckpt stablesr_000117.ckpt\n--vqgan_ckpt vqgan_cfw_00011.ckpt --init-img inputs/origin.png --outdir output\n--ddpm_steps 200 --dec_w 0.5 --colorfix_type adainnvi\n\nCUDA_VISIBLE_DEVICES=7 python main.py --train --base\nconfigs/stableSRNew/v2-finetune_text_T_512.yaml --gpus 7, --name --scale_lr\nFalse\n\nconda install pytorch cudatoolkit=11.7 -c pytorch\n\n\nDNNM#\n\npython main.py --ni --simplified --config celeba_hq.yml --path_y celeba_hq --eta\n0.85 --deg \"sr_averagepooling\" --deg_scale 4.0 --sigma_y 0 -i demo python\nmain.py --config confs/inet256.yml --path_y data/datasets/gts/inet256/323.png\n--class 323 --deg \"sr_averagepooling\" --scale 4 -i butterfly_sr\n\npython3 main.py --resize_y --config confs/inet256.yml --path_y\ndata/datasets/gts/inet256/origin.png --class 950 --deg \"sr_averagepooling\"\n--scale 4 -i origin","routePath":"/notes/07-AI & Machine Learning/temp","lang":"","toc":[{"text":"stableSR","id":"stablesr","depth":2,"charIndex":324},{"text":"DNNM","id":"dnnm","depth":2,"charIndex":792}],"domain":"","frontmatter":{},"version":""},{"id":176,"title":"webui","content":"#\n\n\ndockerfile#\n\n\n\n\ndocker compose#\n\n","routePath":"/notes/07-AI & Machine Learning/webui","lang":"","toc":[{"text":"dockerfile","id":"dockerfile","depth":2,"charIndex":3},{"text":"docker compose","id":"docker-compose","depth":2,"charIndex":19}],"domain":"","frontmatter":{},"version":""},{"id":177,"title":"model converting","content":"#\n\n\nyolov8 to onnx model#\n\nyolo mode=export model=yolov8n.pt format=onnx dynamic=False\n\n\n\n\ndocker#\n\n\n\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError]\n: 2 : INVALID_ARGUMENT : Failed to load model with error:\n/onnxruntime_src/onnxruntime/core/graph/model_load_utils.h:47 void\nonnxruntime::model_load_utils::ValidateOpsetForDomain(const std::unordered_map&,\nconst onnxruntime::logging::Logger&, bool, const string&, int) ONNX Runtime only\nguarantees support for models stamped with official released onnx opset\nversions. Opset 17 is under development and support for this is limited. The\noperator schemas and or other functionality may change before next ONNX release\nand in this case ONNX Runtime will not guarantee backward compatibility. Current\nofficial support for domain ai.onnx is till opset 16.\n\n\n\npip install onnx=1.15 -i https://pypi.tuna.tsinghua.edu.cn/simpl pip install\nonnxruntime=1.15 -i https://pypi.tuna.tsinghua.edu.cn/simpl\n\nonnxsim yolov8n.onnx yolov8nsim.onnx\n\npulsar2 build --input yolov8nsim.onnx --output_dir output --config config.json","routePath":"/notes/07-AI & Machine Learning/yolo/model_con","lang":"","toc":[{"text":"yolov8 to onnx model","id":"yolov8-to-onnx-model","depth":2,"charIndex":3},{"text":"docker","id":"docker","depth":2,"charIndex":90}],"domain":"","frontmatter":{},"version":""},{"id":178,"title":"Solana","content":"#\n\n\nInstall on linux#\n\nthe common tools such as git, nodejs and rust are all installed before.\n\n * download file from github\n * unzip the file tar -xjf solana-release-x86_64-unknown-linux-gnu.tar.bz2\n * copy file to /usr/local/bin/ cp solana-release/bin/solana /usr/local/bin/\n * check the version solana --version","routePath":"/notes/09-Blockchain/Solana","lang":"","toc":[{"text":"Install on linux","id":"install-on-linux","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":179,"title":"Notes","content":"#\n\nHere are some tech notes.","routePath":"/notes/","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":180,"title":"Knowledge Graph","content":"#\n\n\n云计算（Cloud Computing）#\n\n * 基础架构与服务类型：IaaS, PaaS, SaaS\n * 云平台与工具：AWS, Microsoft Azure, Google Cloud, Alibaba Cloud\n * 容器化与编排：Docker, Kubernetes\n * 操作系统相关：Linux 操作系统（云计算中的服务器主要运行在 Linux 上），虚拟化技术（如 VMware, Hyper-V）\n * 基础设施自动化：Terraform, Ansible\n * 无服务器架构：Lambda, Azure Functions\n\n\n软件开发（Software Development）#\n\n * 前端开发：HTML, CSS, JavaScript, React, Angular, Vue.js\n * 后端开发：Python, Golang, Java, Node.js, Django, Spring Boot\n * 操作系统相关：开发环境配置（Windows, macOS, Linux），版本管理工具（如 Git）\n * 开发工具与集成环境：VSCode, IntelliJ IDEA, Visual Studio\n * 软件架构：微服务架构、单体架构、SOA（面向服务架构）\n\n\n数据库与数据存储（Databases & Data Storage）#\n\n * 关系型数据库：MySQL, PostgreSQL, SQL Server, Oracle\n * NoSQL 数据库：MongoDB, Redis, Cassandra, CouchDB\n * 数据备份与恢复：备份工具（如 pg_dump, mysqldump），数据库故障排查\n * 操作系统相关：数据库服务器的操作系统优化（如 Linux 文件系统的选择）\n\n\nDevOps 与持续集成/持续交付（CI/CD & DevOps）#\n\n * 版本控制系统：Git, GitHub, GitLab\n * CI/CD 工具：Jenkins, CircleCI, Travis CI, GitLab CI\n * 配置管理：Ansible, Chef, Puppet\n * 操作系统相关：Linux 系统管理与脚本编写（如 Bash），系统监控工具（如 Nagios, Prometheus）\n * 日志与监控：ELK Stack（Elasticsearch, Logstash, Kibana），Grafana\n\n\n网络与安全（Networking & Security）#\n\n * 网络协议：TCP/IP, HTTP/HTTPS, DNS, WebSocket\n * 网络安全工具：Wireshark, Nmap, Metasploit\n * 加密技术与身份验证：SSL/TLS, OAuth, JWT\n * 操作系统相关：Linux 网络配置与防火墙（如 iptables, firewalld）\n * 安全管理与监控工具：Intrusion Detection System（IDS）, 防火墙, VPN\n\n\n大数据（Big Data）#\n\n * 数据存储与管理：Hadoop, HDFS, Amazon S3\n * 数据处理框架：Apache Spark, Apache Flink, MapReduce\n * 数据仓库与ETL工具：Hive, Kafka, Talend\n * 数据可视化：Tableau, Power BI, D3.js\n * 数据库相关：SQL, NoSQL（如 Cassandra, MongoDB）\n\n\n人工智能与机器学习（AI & Machine Learning）#\n\n * 机器学习算法：线性回归、决策树、神经网络、聚类算法\n * 深度学习：CNN, RNN, LSTM, Transformer\n * 编程语言与框架：Python, R, TensorFlow, PyTorch, Scikit-Learn\n * 自然语言处理（NLP）：ChatGPT, BERT, NLTK, spaCy\n * 操作系统相关：基于 GPU 加速的训练需要 Linux 支持（如 NVIDIA 驱动和 CUDA 工具）\n\n\n物联网（Internet of Things, IoT）#\n\n * 硬件设备与传感器：Arduino, Raspberry Pi, ESP8266\n * 通信协议：MQTT, CoAP, Zigbee, LoRaWAN\n * IoT 平台：Azure IoT Hub, AWS IoT Core, Google Cloud IoT\n * 边缘计算：Edge Computing 的操作系统，如 Ubuntu Core, Windows IoT Core\n * 实时操作系统（RTOS）：FreeRTOS, Zephyr\n\n\n区块链（Blockchain）#\n\n * 基础知识与协议：共识算法（PoW, PoS, DPoS）、哈希算法\n * 开发平台：Ethereum, Hyperledger Fabric, Bitcoin Core\n * 智能合约开发：Solidity, Web3.js\n * 操作系统相关：运行区块链节点的 Linux 服务器配置和优化\n\n\n软件工程与项目管理（Software Engineering & Project Management）#\n\n * 开发流程与方法论：Agile, Scrum, Waterfall\n * 项目管理工具：Jira, Trello, Asana\n * 文档管理与协作：Confluence, Notion, Microsoft Teams","routePath":"/notes/knowledge-graph","lang":"","toc":[{"text":"云计算（Cloud Computing）","id":"云计算cloud-computing","depth":2,"charIndex":3},{"text":"软件开发（Software Development）","id":"软件开发software-development","depth":2,"charIndex":280},{"text":"数据库与数据存储（Databases & Data Storage）","id":"数据库与数据存储databases--data-storage","depth":2,"charIndex":559},{"text":"DevOps 与持续集成/持续交付（CI/CD & DevOps）","id":"devops-与持续集成持续交付cicd--devops","depth":2,"charIndex":781},{"text":"网络与安全（Networking & Security）","id":"网络与安全networking--security","depth":2,"charIndex":1054},{"text":"大数据（Big Data）","id":"大数据big-data","depth":2,"charIndex":1304},{"text":"人工智能与机器学习（AI & Machine Learning）","id":"人工智能与机器学习ai--machine-learning","depth":2,"charIndex":1515},{"text":"物联网（Internet of Things, IoT）","id":"物联网internet-of-things-iot","depth":2,"charIndex":1771},{"text":"区块链（Blockchain）","id":"区块链blockchain","depth":2,"charIndex":2033},{"text":"软件工程与项目管理（Software Engineering & Project Management）","id":"软件工程与项目管理software-engineering--project-management","depth":2,"charIndex":2203}],"domain":"","frontmatter":{},"version":""}]